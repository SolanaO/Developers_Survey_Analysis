{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4ccb3d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general packages and libraries\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "# data manipulation packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# data visualizations packages\n",
    "import matplotlib.pyplot as plt\n",
    "# to render plots in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "# set a theme for seaborn\n",
    "sns.set_theme()\n",
    "\n",
    "# numerical, statistical and machine learning packages and libraries\n",
    "\n",
    "from sklearn.base import (\n",
    "    BaseEstimator, \n",
    "    TransformerMixin,\n",
    ")\n",
    "from sklearn.pipeline import (\n",
    "    make_pipeline,\n",
    "    Pipeline,\n",
    "    FeatureUnion,\n",
    ")\n",
    "from sklearn.impute import (\n",
    "    KNNImputer,\n",
    "    SimpleImputer,\n",
    ")\n",
    "from sklearn.preprocessing import (\n",
    "    OrdinalEncoder, \n",
    "    StandardScaler,\n",
    "    MultiLabelBinarizer,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    ")\n",
    "\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    ")\n",
    "    \n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3e31ddfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a string for the working directory\n",
    "mypath = '/home/silvia/Documents/udacityND/ml_dsnd/proj1_dsnd/'\n",
    "\n",
    "# add src folder to sys.path to use the local modules\n",
    "sys.path.insert(1, mypath + 'src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ff7ce878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import local modules \n",
    "import utils_functions as uf \n",
    "import utils_classes as uc\n",
    "import local_maps as lm      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aafdc933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-load the modules as needed\n",
    "import importlib\n",
    "importlib.reload(uf);\n",
    "importlib.reload(uc);\n",
    "importlib.reload(lm);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8949d295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload the datafile as pandas dataframe\n",
    "df = pd.read_csv(mypath+'/data/raw/survey20_results_public.csv', index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "53606395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy of the dataframe\n",
    "df1  = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8ae58ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess data: change types, columns, remove features\n",
    "df_proc = (df1.\n",
    "                pipe(uf.data_prep).\n",
    "                pipe(uf.parse_dev_type).\n",
    "                pipe(uf.remove_clean_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3de9f014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the predictors dataframe\n",
    "X = df_proc.drop(columns = 'JobSat')\n",
    "\n",
    "# create the labels\n",
    "y = df_proc['JobSat']\n",
    "\n",
    "# split the data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b4cd2c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance of the classifier, using the optimizing parameters\n",
    "RF_clf = RandomForestClassifier(max_depth=90, min_samples_split=5, \n",
    "                                n_estimators=1400, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a0dd82d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=90, min_samples_split=5, n_estimators=1400,\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# process the train data\n",
    "X_train_proc = uc.full_pipeline.fit_transform(X_train)\n",
    "\n",
    "# fit and transform the train data\n",
    "RF_clf.fit(X_train_proc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4b1fc0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process the test data\n",
    "X_test_proc = uc.full_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fe836842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict labels on test set\n",
    "y_pred = RF_clf.predict(X_test_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f2e4a9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate performance metrics on the train set\n",
    "perf_train_RF = pd.Series(uf.get_perf_metrics(RF_clf.fit(X_train_proc,y_train),\n",
    "                                              X_train_proc, y_train), \n",
    "                       index = lm.metrics_list)\n",
    "\n",
    "# evaluate performance metrics on the test set\n",
    "perf_test_RF = pd.Series(uf.get_perf_metrics(RF_clf.fit(X_train_proc,y_train),\n",
    "                                             X_test_proc, y_test), \n",
    "                         index = lm.metrics_list)\n",
    "\n",
    "# combine performance metrics for the baseline model\n",
    "perf_model_RF = pd.DataFrame.from_dict({'train': perf_train_RF,\n",
    "                                        'test': perf_test_RF}).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3721b073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance metrics comparison for RandomForestClassifier:\n",
      "            train   test\n",
      "accuracy   0.996  0.628\n",
      "precision  0.998  0.739\n",
      "recall     0.993  0.541\n",
      "f1         0.995  0.587\n",
      "\n",
      "RandomForestClassifier Confusion Matrix for Test Set:\n",
      "[[ 98  30   1  42  87]\n",
      " [  3 228   7 170  78]\n",
      " [  2  23 141 141  76]\n",
      " [  3  29   4 628 257]\n",
      " [  2  13   2 187 860]]\n",
      "\n",
      "RandomForestClassifier Classification Report for Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.91      0.38      0.54       258\n",
      "           2       0.71      0.47      0.56       486\n",
      "           3       0.91      0.37      0.52       383\n",
      "           4       0.54      0.68      0.60       921\n",
      "           5       0.63      0.81      0.71      1064\n",
      "\n",
      "    accuracy                           0.63      3112\n",
      "   macro avg       0.74      0.54      0.59      3112\n",
      "weighted avg       0.67      0.63      0.62      3112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print evaluation metrics and results\n",
    "\n",
    "print('Performance metrics comparison for RandomForestClassifier:\\n', perf_model_RF)\n",
    "\n",
    "result1_RF = confusion_matrix(y_test, y_pred)\n",
    "print('\\nRandomForestClassifier Confusion Matrix for Test Set:')\n",
    "print(result1_RF)\n",
    "\n",
    "result2_RF = classification_report(y_test, y_pred)\n",
    "print('\\nRandomForestClassifier Classification Report for Test Set:')\n",
    "print (result2_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d5953f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
