{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of StackOverflow Survey. Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general packages and libraries\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "# data manipulation packages\n",
    "import pandas as pd\n",
    "\n",
    "# data visualizations packages\n",
    "import matplotlib.pyplot as plt\n",
    "# to render plots in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "# set a theme for seaborn\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a string for the working directory\n",
    "mypath = '/home/silvia/Documents/udacityND/ml_dsnd/proj1_dsnd/'\n",
    "\n",
    "# add src folder to sys.path to use the local modules\n",
    "sys.path.insert(1, mypath + 'src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import local module containing the neccessary functions\n",
    "import utils_functions as uf\n",
    "\n",
    "# forces the interpreter to re-import the module\n",
    "importlib.reload(uf);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State the question \n",
    "\n",
    "We are addressing the second question in this notebook. How do the salaries of data coders compare with the salaries of the other coders? In particular, we shall determine if there is a statistically significant difference between the average converted compensation of data coders versus the average converted compensation of the other coders.\n",
    "\n",
    "We conduct a Z-test for independent means to compare the averages of the converted compensation, using the entries from the column 'imputedComp' obtained after imputing the missing values in 'ConvertedComp'. We will test the null hypothesis \n",
    "$$H_0: \\mu_c \\leq  \\mu_o $$\n",
    "that the mean converted compensation of the data coders ($\\mu_c$) is less than for the other coders ($\\mu_o$), against the alternative\n",
    "$$H_a: \\mu_c > \\mu_o $$\n",
    "\n",
    "I will work with a $1 \\%$ significance level so that $\\alpha = 0.01$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload the datafiles as pandas dataframes\n",
    "df1 = pd.read_csv(mypath+'data/interim/survey20_updated.csv')\n",
    "\n",
    "# check the uploaded data\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute data in ConvertedComp column\n",
    "\n",
    "We impute the missing data in `ConvertedComp` with the median value from each country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at the records statistics\n",
    "df1.ConvertedComp.describe().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are numerous extreme values and also almost half of values missing\n",
    "df1.ConvertedComp.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the extreme values\n",
    "df1[df1.ConvertedComp == 2000000].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute the ConvertedComp missing values with the median of the corresponding country\n",
    "# save the existing values and the imputed values in a new column\n",
    "df1['ImputedComp'] = df1['ConvertedComp'].fillna(df1.groupby('Country')['ConvertedComp'].transform('median'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many values are still missing\n",
    "df1.ImputedComp.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all rows that have NaN in ImputedComp column\n",
    "df1.dropna(subset = ['ImputedComp'], inplace=True)\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many values are 0\n",
    "df1[df1.ImputedComp == 0.0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop those values with 0 imputedCompensation\n",
    "df1.drop(df1[df1.ImputedComp == 0.0].index, inplace = True)\n",
    "\n",
    "# check for success\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe with the variables of interest only\n",
    "df2 = pd.DataFrame([df1.ImputedComp, df1.DevClass]).T\n",
    "df2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the attributes of the dataframe\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the Dtype of the imputedComp column\n",
    "df2['ImputedComp'] = pd.to_numeric(df2[\"ImputedComp\"])\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the records for the other coders\n",
    "df2_other = df2[df2.DevClass == 'other_coder']\n",
    "df2_other.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the records for the data coders\n",
    "df2_data = df2[df2.DevClass == 'data_coder']\n",
    "df2_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the figure sizecenter plot\n",
    "plt.figure(figsize = [20, 16])\n",
    "\n",
    "# left upper plot: histogram\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.histplot(data=df2_data, x='ImputedComp');\n",
    "plt.title('Compensation data coders', fontsize=14);\n",
    "\n",
    "\n",
    "# right upper plot: histogram\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.histplot(data=df2_data, x='ImputedComp',log_scale = True);\n",
    "plt.title('Compensation data coders - logscale', fontsize=14);\n",
    "\n",
    "# left lower plot: histogram\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.histplot(data=df2_other, x='ImputedComp');\n",
    "plt.title('Compensation other coders', fontsize=14);\n",
    "\n",
    "# right lower plot: histogram\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.histplot(data=df2_other, x='ImputedComp',log_scale = True );\n",
    "plt.title('Compensation other coders - logscale', fontsize=14);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the figure sizecenter plot\n",
    "plt.figure(figsize = [20, 6])\n",
    "\n",
    "# left upper plot: histogram\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(data=df2_data, x='ImputedComp');\n",
    "plt.title('Compensation data coders', fontsize=14);\n",
    "\n",
    "\n",
    "# right upper plot: histogram\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(data=df2_other, x='ImputedComp');\n",
    "plt.title('Compensation other coders', fontsize=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the two data arrays for the z-test\n",
    "x_data = df2_data.ImputedComp \n",
    "x_other = df2_other.ImputedComp  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the difference of averages\n",
    "x_data.mean() - x_other.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "statistic,pvalue = ttest_ind(x_data, x_other, equal_var=False, alternative='greater')\n",
    "print('The test statistic is %.3f and the p-value is %.5f'%(statistic,pvalue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comments regarding the Z-test:\n",
    "\n",
    "We are interested to see if the converted compensation of the tata coders is larger in average than the converted compensation of the other coders. We test the null hypothesis \n",
    "$$H_0: \\mu_c - \\mu_o  \\leq 0$$\n",
    "that the mean converted compensation of the data coders ($\\mu_c$) is smaller than for the other coders ($\\mu_o$), against the alternative\n",
    "$$H_a: \\mu_c - \\mu_o  > 0.$$\n",
    "\n",
    "We will work with a $1 \\%$ significance level so that $\\alpha = 0.01$.\n",
    "\n",
    "We perform a right - tailed test and a Z-test of two means, with known population standard deviations. \n",
    "\n",
    "For the significance level of $\\alpha = 0.01$ the critical value is $z_{\\scriptsize critical} = 2.33$  with rejection region $R = \\lbrace z: z > 2.33 \\rbrace$. \n",
    "\n",
    "We compute a z-statistic $z = 7.9 \\geq 2.33$ and we conclude that the null hypothesis is rejected. \n",
    "\n",
    "Using the p-value approach: since the p-value $p = 0 < 0.01$, we conclude that the null hypothesis is rejected.\n",
    "\n",
    "We found a difference in average converted compensation between data coders and other coders $18696 \\$$, with a p-value of $0.00$, consistent with our hypothesis that there is a difference in compensation between data coders and the other coders.\n",
    "\n",
    "A few comments about these conclusions:\n",
    "- about $46 \\%$ of the data is missing in the ConvComp column;\n",
    "- we imputed most of the values with the country medians and dropped the remaining zero and missing values;\n",
    "- there are numerous outliers in the data;\n",
    "- the compensation is converted, but we still have to keep in mind that the compensation levels differ substantially among countries;\n",
    "- another aspect not taken into account (an this is only one of the many) is that the developers have various levels of seniority, and we averaged over all experience levels.\n",
    "\n",
    "With all these observations in mind, our result is statistically significant but not necessarily a strong one. To obtain a more reliable outcome, we need to take into account other factors, some of them mentioned above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
