{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77e278e6",
   "metadata": {},
   "source": [
    "# Analysis of StackOverflow Survey. Part IV\n",
    "\n",
    "In this notebook we address the third question, and we build a model to predict job satisfaction for data coders.\n",
    "\n",
    "The steps of the process are: all steps with substeps\n",
    "1. \n",
    "2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "9302f019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general packages and libraries\n",
    "import os\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "15959c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data manipulation packages\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "8b486bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data visualizations packages\n",
    "import matplotlib.pyplot as plt\n",
    "# to render plots in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "# set a theme for seaborn\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "29bafd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical, statistical and machine learning packages and libraries\n",
    "import xgboost as xgb\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn import (\n",
    "    ensemble,\n",
    "    tree,\n",
    ")\n",
    "from sklearn.base import (\n",
    "    BaseEstimator, \n",
    "    TransformerMixin,\n",
    ")\n",
    "from sklearn.pipeline import (\n",
    "    make_pipeline,\n",
    "    FeatureUnion, \n",
    "    Pipeline,\n",
    ")\n",
    "from sklearn.feature_selection import (\n",
    "    SelectKBest, \n",
    "    chi2, \n",
    "    mutual_info_classif,\n",
    ")\n",
    "from sklearn.impute import (\n",
    "    KNNImputer,\n",
    "    SimpleImputer,\n",
    ")\n",
    "from sklearn.preprocessing import (\n",
    "    OneHotEncoder, \n",
    "    OrdinalEncoder, \n",
    "    LabelEncoder,\n",
    "    StandardScaler,\n",
    "    MultiLabelBinarizer,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    StratifiedKFold,\n",
    "    KFold,\n",
    "    cross_val_score,\n",
    ")\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import (RandomForestClassifier)\n",
    "\n",
    "from sklearn.linear_model import (\n",
    "    SGDClassifier,\n",
    "    LogisticRegression,\n",
    ") \n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    r2_score, \n",
    "    mean_squared_error,\n",
    "    auc,\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    ")\n",
    "from sklearn.metrics import log_loss, roc_auc_score, precision_score, recall_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "c403f1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import local modules \n",
    "import utils_functions as uf \n",
    "#import utils_classes as uc\n",
    "import local_maps as lm\n",
    "\n",
    "# forces the interpreter to re-load the module\n",
    "importlib.reload(uf);\n",
    "\n",
    "# create a path string\n",
    "mypath = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e11193",
   "metadata": {},
   "source": [
    "## Formulate the questions\n",
    "\n",
    "We separate the respondents of the 2020 StackOverflow Developer Survey into data developers\n",
    "(data scientist or machine learning specialist, data or business analyst, data engineer) and other developers. In what follows we restrict the dataset to the data developers and address the following questions:  \n",
    " - What can we tell about the job satisfaction of a data developer? \n",
    " - What factors do influence the job satisfaction? \n",
    " \n",
    "We build a predictive model for the job satisfaction for data developers. This is a multi-class classification question, where the satisfaction levels are: very dissatisfied, slightly dissatisfied, neither satisfied nor dissatisfied, slightly satisfied, very satisfied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5742328c",
   "metadata": {},
   "source": [
    "## Performance metrics - to review at the end\n",
    "\n",
    "The following performance measures will be used in this project:\n",
    "1. Cross validation via StratifiedKFold with 10 folds.\n",
    "2. Confusion matrix, in particular precision, recall and F1 score.\n",
    "3. The ROC curve and the related AUC score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e14fe65",
   "metadata": {},
   "source": [
    "# Gather and prepare the data\n",
    "\n",
    "Upload the data and keep the subset that contains those developers that work in data science related fields. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d46745",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "42d728ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64461, 61)"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# upload the datafile as pandas dataframe\n",
    "df = pd.read_csv(mypath+'/data/survey20_updated.csv', index_col=[0])\n",
    "# check for success\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6be69c",
   "metadata": {},
   "source": [
    "## Remove unnecessary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "8826cbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy of the data\n",
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a425fe00",
   "metadata": {},
   "source": [
    "### Keep the developers that work with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "fa17e5cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(172185, 61)"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the auxiliary column to retain the data developers only\n",
    "#df1 = df1[df1['DevClass']== 'data_coder']\n",
    "\n",
    "df1['DevType'] = df1['DevType'].str.split(';')\n",
    "# transform each element of a list-like to a row, replicating index values\n",
    "df1 = df1.explode('DevType')\n",
    "\n",
    "# check the outcome\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "5523bbe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11750, 61)"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retain only those rows that contain data coders\n",
    "df1 = df1.loc[df1.DevType.str.contains('Data ', na=False)]\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bc697a",
   "metadata": {},
   "source": [
    "### Retain the developers that are employed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "f3e9e854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Employed full-time                                      9236\n",
       "Independent contractor, freelancer, or self-employed    1481\n",
       "Not employed, but looking for work                       564\n",
       "Employed part-time                                       469\n",
       "Name: Employment, dtype: int64"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the employment types for data coders\n",
    "df1.Employment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "82aad2a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Employed full-time                                      9236\n",
       "Independent contractor, freelancer, or self-employed    1481\n",
       "Employed part-time                                       469\n",
       "Name: Employment, dtype: int64"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retain only the employed data developers\n",
    "df1 = df1[df1['Employment'] != 'Not employed, but looking for work']\n",
    "\n",
    "# check for success\n",
    "df1.Employment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0acc63a",
   "metadata": {},
   "source": [
    "### Retain only the respondents that code professionally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "a5c838e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I am a developer by profession                                                   8207\n",
       "I am not primarily a developer, but I write code sometimes as part of my work    2275\n",
       "I am a student who is learning to code                                            296\n",
       "I used to be a developer by profession, but no longer am                          203\n",
       "I code primarily as a hobby                                                       163\n",
       "Name: MainBranch, dtype: int64"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the professional status of the employed developers\n",
    "df1.MainBranch.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "121a5c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I am a developer by profession                                                   8207\n",
       "I am not primarily a developer, but I write code sometimes as part of my work    2275\n",
       "Name: MainBranch, dtype: int64"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a list of main branch choices\n",
    "main_choices = df1.MainBranch.value_counts().index.to_list()\n",
    "# retain those rows where MainBranch contains the respondents that work professionally with data\n",
    "df1 = df1[df1.MainBranch.isin(main_choices[:2])]\n",
    "\n",
    "# check the outcome\n",
    "df1.MainBranch.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb00e390",
   "metadata": {},
   "source": [
    "### Drop the rows with missing values in JobSat column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "e657e16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with missing JobSat\n",
    "df1.dropna(subset=['JobSat'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910799ff",
   "metadata": {},
   "source": [
    "### Remove irrelevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "0a943ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of columns to be removed\n",
    "cols_del = [\n",
    "    # personal, demographics  information\n",
    "    #'Respondent', \n",
    "    'MainBranch', 'Employment', 'Hobbyist', \n",
    "    'Country','Ethnicity', 'Age',\n",
    "    'Gender', 'Sexuality', 'Trans', \n",
    "    \n",
    "    # related to ConvertedComp\n",
    "    'CompFreq', 'CompTotal', 'CurrencyDesc', 'CurrencySymbol',\n",
    "    \n",
    "    # questions regarding future activities\n",
    "    'DatabaseDesireNextYear', 'MiscTechDesireNextYear',\n",
    "    'CollabToolsDesireNextYear', 'PlatformDesireNextYear',\n",
    "    'LanguageDesireNextYear', 'WebframeDesireNextYear',\n",
    "    \n",
    "    # questions regarding this survey\n",
    "    'SurveyEase', 'SurveyLength', 'WelcomeChange',\n",
    "    \n",
    "    # question regarding participation is StackOverflow\n",
    "    'SOSites', 'SOComm', 'SOPartFreq',\n",
    "    'SOVisitFreq', 'SOAccount',\n",
    "\n",
    "    # columns related to other columns\n",
    "    'Age1stCode', 'YearsCodePro', 'DevType', \n",
    "\n",
    "    # high cardinality, multiple choices columns, add noise \n",
    "    'MiscTechWorkedWith', 'DatabaseWorkedWith', #'CollabToolsWorkedWith',\n",
    "    'WebframeWorkedWith', 'LanguageWorkedWith',\n",
    "\n",
    "    # questions not relevant to our goal\n",
    "    #'JobHunt',\n",
    "    'JobHuntResearch', 'Stuck',\n",
    "    'PurchaseResearch', \n",
    "    #'PurchaseWhat', \n",
    "    'Stuck', 'PurpleLink',\n",
    "    'OffTopic', 'OtherComms',\n",
    "    'JobFactors', \n",
    "    #'JobSeek',\n",
    "\n",
    "    # auxiliary columns\n",
    "    'DevClass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "30fae562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10372, 19)"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop all the columns in the list\n",
    "df1.drop(columns=cols_del, inplace=True)\n",
    "\n",
    "# check the output\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c137f8b4",
   "metadata": {},
   "source": [
    "#### Comments on feature selection\n",
    "Since we are left with 16 features only, I will not perform additional feature selection. After experimenting with a couple of feature selection options, such as mutual_info_classif and SelectKBest, I observed that the model did not performe substantially better after applying feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2756f2e",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d0565c",
   "metadata": {},
   "source": [
    "### Replace JobSat categories with numerical code and drop missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "a216eb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding map for job satisfaction\n",
    "JobSat_dict =  {'Very dissatisfied': 1, 'Slightly dissatisfied': 2,\n",
    "               'Neither satisfied nor dissatisfied': 3, \n",
    "               'Slightly satisfied': 4, 'Very satisfied': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "f081bb5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    3582\n",
       "4    3079\n",
       "2    1623\n",
       "3    1242\n",
       "1     846\n",
       "Name: JobSat, dtype: int64"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the custom labelling \n",
    "df1['JobSat'] = df1['JobSat'].map(JobSat_dict)\n",
    "# check the outcome\n",
    "df1['JobSat'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9b0500",
   "metadata": {},
   "source": [
    "### Update YearsCode column entries and dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "b911d2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace strings with numerical entries\n",
    "replace_dict = {'Less than 1 year': '0', 'More than 50 years': '51'}\n",
    "df1.replace(replace_dict, inplace=True)\n",
    "\n",
    "# change dtype to numeric\n",
    "df1['YearsCode'] = pd.to_numeric(df1['YearsCode'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96766c9e",
   "metadata": {},
   "source": [
    "### Pre-process the multi levels columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "1fc9958a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the list of entries with sets, missing values with empy set\n",
    "df1['PlatformWorkedWith'] = df1['PlatformWorkedWith'].str.split(';').apply(lambda x: {} if \n",
    "                                                                           x is np.nan else set(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "ffd51462",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['CollabToolsWorkedWith'] = df1['CollabToolsWorkedWith'].str.split(';').apply(lambda x: {} if \n",
    "                                                                                 x is np.nan else set(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4b44a8",
   "metadata": {},
   "source": [
    "### Save a copy of the data to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "1209dea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save a copy of the preprocessed dataframe\n",
    "df1.to_csv(mypath + '/data/survey20_preprocessedex.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "459d3a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the pre-processed data\n",
    "dfp = pd.read_csv(mypath+'/data/survey20_preprocessedex.csv', index_col=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3192bc",
   "metadata": {},
   "source": [
    "## Refactor code\n",
    "\n",
    "Rewrite all of the steps for data pre-processing in a single function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "0c663f7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'CollabToolsWorkedWith'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'CollabToolsWorkedWith'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-400-e08f4bcb60cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# all data cleaning and preprocessing steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove_clean_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# check the outcome\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/udacityND/ml_dsnd/proj1_dsnd/utils_functions.py\u001b[0m in \u001b[0;36mremove_clean_data\u001b[0;34m(dft)\u001b[0m\n\u001b[1;32m    236\u001b[0m                                                    x is np.nan else set(x))\n\u001b[1;32m    237\u001b[0m     \u001b[0mdft\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CollabToolsWorkedWith'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m     dft['CollabToolsWorkedWith'].str.split(';').apply(lambda x: {} if\n\u001b[0m\u001b[1;32m    239\u001b[0m                                                    x is np.nan else set(x))\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3022\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3025\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3080\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'CollabToolsWorkedWith'"
     ]
    }
   ],
   "source": [
    "# create a fresh copy of the dataset\n",
    "dft=df.copy()\n",
    "\n",
    "# all data cleaning and preprocessing steps\n",
    "dft = uf.remove_clean_data(dft)\n",
    "\n",
    "# check the outcome\n",
    "dft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73aade3",
   "metadata": {},
   "source": [
    "### Review data types and data distribution in columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "a39098d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ConvertedComp', 'WorkWeekHrs', 'YearsCode']\n"
     ]
    }
   ],
   "source": [
    "# the list of numerical columns\n",
    "num_cols = df1.select_dtypes(include='float64').columns.to_list()\n",
    "print(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "d551b2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the list of discrete columns with many levels \n",
    "multi_cols = ['PlatformWorkedWith', 'CollabToolsWorkedWith']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "b27ae29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Overtime', 'OpSys', 'DevOps', 'OrgSize', 'UndergradMajor', 'DevOpsImpt', 'EdImpt', 'OnboardGood', 'EdLevel', 'Learn']\n"
     ]
    }
   ],
   "source": [
    "# the list of discrete columns with several levels\n",
    "cat_cols = df1.select_dtypes(include='object').columns.to_list()\n",
    "uni_cols = list(set(cat_cols) - set(multi_cols))\n",
    "print(uni_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b18e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each categorical column, print possible row values and their counts\n",
    "def list_answers(df, cat_cols):\n",
    "    for col in cat_cols:\n",
    "        print(col)\n",
    "        print(' ')\n",
    "        print(df1[col].value_counts())\n",
    "        print(' ')\n",
    "# print counts and values\n",
    "# list_answers(df1, cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180d1d99",
   "metadata": {},
   "source": [
    "## Sample data, create features and target datasets\n",
    "\n",
    "Create a dataframe X of features and a pandas series y that contains the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "ef2c2180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy of the pre-processed dataframe\n",
    "df2 = df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "f33fcada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10372, 18), 10372)"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the predictors dataframe\n",
    "X = df2.drop(columns = 'JobSat')\n",
    "\n",
    "# create the labels\n",
    "y = df2['JobSat']\n",
    "\n",
    "# check for success\n",
    "X.shape, len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75a23df",
   "metadata": {},
   "source": [
    "### Isolate a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "d63ed50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (7260, 18) (7260,)\n",
      "Test (3112, 18) (3112,)\n"
     ]
    }
   ],
   "source": [
    "# split the data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# summarize the data\n",
    "print('Train', X_train.shape, y_train.shape)\n",
    "print('Test', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013a3de2",
   "metadata": {},
   "source": [
    "## Encode the discrete variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36409176",
   "metadata": {},
   "source": [
    "### Encode the columns with many levels\n",
    "\n",
    "After data cleaning and pre-processing the columns with many levels are:\n",
    " - multi_cols = ['PlatformWorkedWith']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "22b23d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance of the encoder\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# fit the binarizer and encode the selected column\n",
    "mlb_model = mlb.fit(X_train['PlatformWorkedWith'])\n",
    "temp_col =  mlb.transform(X_train['PlatformWorkedWith'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "94f5eca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AWS</th>\n",
       "      <th>Android</th>\n",
       "      <th>Arduino</th>\n",
       "      <th>Docker</th>\n",
       "      <th>Google Cloud Platform</th>\n",
       "      <th>Heroku</th>\n",
       "      <th>IBM Cloud or Watson</th>\n",
       "      <th>Kubernetes</th>\n",
       "      <th>Linux</th>\n",
       "      <th>MacOS</th>\n",
       "      <th>Microsoft Azure</th>\n",
       "      <th>Raspberry Pi</th>\n",
       "      <th>Slack Apps and Integrations</th>\n",
       "      <th>Windows</th>\n",
       "      <th>WordPress</th>\n",
       "      <th>iOS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Respondent</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43724</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32280</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            AWS  Android  Arduino  Docker  Google Cloud Platform  Heroku  \\\n",
       "Respondent                                                                 \n",
       "43724         0        0        0       0                      0       0   \n",
       "32280         1        0        0       1                      1       0   \n",
       "\n",
       "            IBM Cloud or Watson  Kubernetes  Linux  MacOS  Microsoft Azure  \\\n",
       "Respondent                                                                   \n",
       "43724                         0           0      1      0                0   \n",
       "32280                         0           0      1      0                0   \n",
       "\n",
       "            Raspberry Pi  Slack Apps and Integrations  Windows  WordPress  iOS  \n",
       "Respondent                                                                      \n",
       "43724                  0                            0        0          0    0  \n",
       "32280                  0                            0        0          0    0  "
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# put the outcome in pandas dataframe form\n",
    "temp_df = pd.DataFrame(temp_col, columns=mlb.classes_, index=X_train.index)\n",
    "# check the outcome\n",
    "temp_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "c6b0975c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list the three most popular platforms\n",
    "platform_keep = list(temp_df.sum().sort_values(ascending=False).head(3).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "d9cce5ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7260, 16)"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine the two dataframes and drop the initial column\n",
    "X_train = pd.concat([X_train, temp_df[platform_keep]], axis=1).drop(columns = ['PlatformWorkedWith'])\n",
    "\n",
    "# check the outcome\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "d92367ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3112, 16)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply the same transformations to the test set\n",
    "temp_col_test =  mlb.transform(X_test['PlatformWorkedWith'])\n",
    "# put the outcome in pandas dataframe form\n",
    "temp_df_test = pd.DataFrame(temp_col_test, columns=mlb.classes_, index=X_test.index)\n",
    "# combine the two dataframes and drop the initial column\n",
    "X_test = pd.concat([X_test, temp_df_test[platform_keep]], axis=1).drop(columns = ['PlatformWorkedWith'])\n",
    "\n",
    "# check the outcome\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17af038d",
   "metadata": {},
   "source": [
    "#### Comments:\n",
    "\n",
    "There are several options to choose from when encoded the columns with high cardinality, that originate from multiple answers questions. If we use MultiLabelBinarizer, a column such PlatformWorkedWith will create 16 new columns, which doubles the number of features in the dataframe. In order to address this column explosion, we droped all the new columns but the 3 that correspond to the most popular choices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a38db99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18087b04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b10b394",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParseMultiColumns(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Custom transformer that that changes a list of strings to a set in a column of a dataframe, and assigns the empty set to missing entries.\n",
    "    \"\"\"\n",
    "    #class constructor method \n",
    "    def __init__(self, multi_cols=['PlatformWorkedWith']):\n",
    "            self.multi_cols = multi_cols\n",
    "            \n",
    "    # return self nothing else to do here\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        for col in self.multi_cols:\n",
    "            X[col] = X[col].str.split(';').apply(lambda x: {} if x is np.nan else set(x))\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3665c57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiColumnsEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Scikit-learn transformer to convert a feature column of a list in \n",
    "    to multiple binary feature columns\"\"\"\n",
    "    def __init__(self, feature_names=None):\n",
    "            self.feature_names = feature_names\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.encoder_dict_ = {}\n",
    "        \n",
    "        for col in self.feature_names:\n",
    "            mlb = MultiLabelBinarizer()\n",
    "            mlb.fit(X[col])\n",
    "            self.encoder_dict_[col] = mlb\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        for col in self.feature_names:\n",
    "            col_encoded = pd.DataFrame(\n",
    "                self.encoder_dict_[col].transform(X[col]),\n",
    "                columns=self.encoder_dict_[col].classes_,\n",
    "                index=X.index)\n",
    "            cols_keep = list(col_encoded.sum().sort_values(ascending=False).head(3).index)\n",
    "\n",
    "            X = pd.concat([X, col_encoded[cols_keep]], axis=1).drop(columns=[col])\n",
    "\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f02a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ac12bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_encoder = MultiColumnsEncoder(feature_names=multi_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d97a296",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = multi_encoder.fit_transform(X_train[multi_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0ea1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1052aa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    The constructor extracts and returns the pandas dataset \n",
    "    with only those columns whose names were passed to it \n",
    "    as an argument during its initialization. \n",
    "    It contains two methods: fit and transform.\n",
    "    \"\"\"\n",
    "    \n",
    "    # class constructor \n",
    "    def __init__(self, feature_names):\n",
    "        self._feature_names = feature_names \n",
    "    \n",
    "    # return self nothing else to do here    \n",
    "    def fit(self, X, y = None):\n",
    "        return self \n",
    "    \n",
    "    # method that describes what we need this transformer to do\n",
    "    def transform(self, X, y = None):\n",
    "        return X[ self._feature_names ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4208421",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsel = FeatureSelector(multi_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef421d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsel.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12674fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f07857",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633f54bb",
   "metadata": {},
   "source": [
    "## Impute the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5c9262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the numerical columns in the train dataset\n",
    "X_train_num = X_train[num_cols]\n",
    "# create an instance of the KNN imputer\n",
    "num_imputer = KNNImputer(n_neighbors=5)\n",
    "# fit_transform the imputer on the training set\n",
    "X_train_num_imp = pd.DataFrame(num_imputer.fit_transform(X_train_num), \n",
    "                               columns=X_train_num.columns)\n",
    "# separate the numerical columns in the test set\n",
    "X_test_num = X_test[num_cols]\n",
    "# transform the test set with the imputer that was fit on the training set\n",
    "X_test_num_imp = pd.DataFrame(num_imputer.transform(X_test_num), columns=X_test_num.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d4fe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance of the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# scale the numerical variables, fit and transform on the straining set\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train_num_imp), \n",
    "                                columns=X_train_num_imp.columns)\n",
    "# use the scaler fit on training set to transform the test set\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test_num_imp), columns=X_test_num_imp.columns)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf8a1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate all the categorical columns in the training set\n",
    "X_train_cat = X_train[cat_cols]\n",
    "# create an instance of the imputer\n",
    "cat_imputer = SimpleImputer(strategy='constant', fill_value='missing')\n",
    "# fit and transform the training data\n",
    "X_train_cat_imp = pd.DataFrame(cat_imputer.fit_transform(X_train_cat), \n",
    "                               columns=X_train_cat.columns)\n",
    "# separate the categorical columns in the test set\n",
    "X_test_cat = X_test[cat_cols]\n",
    "# transform the test data with the imputer fit on the training set\n",
    "X_test_cat_imp=pd.DataFrame(cat_imputer.transform(X_test_cat), columns=X_test_cat.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831f5020",
   "metadata": {},
   "source": [
    "## Encode the predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cab43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the low cardinality columns\n",
    "def ord_encode_predictors(X_train, X_test):\n",
    "    oe = OrdinalEncoder()\n",
    "    oe.fit(X_train)\n",
    "    X_train_enc = pd.DataFrame(oe.transform(X_train))\n",
    "    X_test_enc = pd.DataFrame(oe.transform(X_test))\n",
    "    return X_train_enc, X_test_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9a17c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the low cardinality encoded features\n",
    "X_train_uni_enc, X_test_uni_enc = ord_encode_predictors(X_train_cat_imp[uni_cols],\n",
    "                                                        X_test_cat_imp[uni_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ae83e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the high cardinality columns\n",
    "def encode_predictors(X_train, X_test):\n",
    "    enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    enc.fit(X_train)\n",
    "    X_train_enc = pd.DataFrame(enc.transform(X_train))\n",
    "    X_test_enc = pd.DataFrame(enc.transform(X_test))\n",
    "    return X_train_enc, X_test_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cc7f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the high cardinality encoded features\n",
    "X_train_multi_enc, X_test_multi_enc = encode_predictors(X_train_cat_imp[multi_cols], \n",
    "                                                        X_test_cat_imp[multi_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820a594e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the target variable \n",
    "def encode_target(y_train, y_test):\n",
    "\tle = LabelEncoder()\n",
    "\tle.fit(y_train)\n",
    "\ty_train_enc = le.transform(y_train)\n",
    "\ty_test_enc = le.transform(y_test)\n",
    "\treturn y_train_enc, y_test_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf311d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the target variable - not necessary\n",
    "# y_train_enc, y_test_enc = encode_targets(y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c43b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the  X frames \n",
    "X_train_cat_enc = pd.concat([X_train_multi_enc, X_train_uni_enc], axis=1)\n",
    "X_train_prep = pd.concat([X_train_cat_enc, X_train_scaled], axis=1)\n",
    "\n",
    "X_test_cat_enc = pd.concat([X_test_multi_enc, X_test_uni_enc], axis=1)\n",
    "X_test_prep = pd.concat([X_test_cat_enc, X_test_scaled], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7c1d91",
   "metadata": {},
   "source": [
    "### Create a profiling report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9798aa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this once to generate a profiling report and save it as html file\n",
    "\n",
    "#import pandas_profiling\n",
    "#profile = pandas_profiling.ProfileReport(X_train, minimal=False)\n",
    "#profile.to_file(output_file=\"data_train_report.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c8e8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cd2b0d",
   "metadata": {},
   "source": [
    "## Refactor the code: build processing data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "3e05378c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## refactor code: processing data\n",
    "\n",
    "# the steps in the categorical pipeline for columns of low cardinality\n",
    "uni_cat_pipeline = Pipeline( steps = [( 'unicat_selector', FeatureSelector(uni_cols) ),\n",
    "                                  ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "                                  ( 'ordinal_encoder', OrdinalEncoder() ) ] )\n",
    "\n",
    "# the steps in the categorical pipeline for columns of high cardinality\n",
    "multi_cat_pipeline = Pipeline( steps = [( 'multicat_selector', FeatureSelector(multi_cols) ),\n",
    "                                  ( 'multi_encoder', MultiColumnsEncoder(multi_cols) ) ] )\n",
    "\n",
    "# the steps in the numerical pipeline     \n",
    "num_pipeline = Pipeline( steps = [ ('num_selector', FeatureSelector(num_cols) ),\n",
    "                                  ('imputer', KNNImputer(n_neighbors=5) ),\n",
    "                                  ( 'std_scaler', StandardScaler() ) ] )\n",
    "\n",
    "# combine the numerical and the categorical pipelines\n",
    "full_pipeline = FeatureUnion( transformer_list = [ ( 'unicat_pipeline', uni_cat_pipeline ), \n",
    "                                                  ( 'multicat_pipeline', multi_cat_pipeline ) ,\n",
    "                                                 ( 'numerical_pipeline', num_pipeline )] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0827cd0f",
   "metadata": {},
   "source": [
    "# Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "22e506a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the full pipeline as a step in another pipeline with an estimator as the final step\n",
    "full_pipeline_m = Pipeline( steps = [ ( 'full_pipeline', full_pipeline),\n",
    "                                  ( 'model', KNeighborsClassifier(n_neighbors=5) ) ] )\n",
    "\n",
    "# call fit on it just like any other pipeline\n",
    "full_pipeline_m.fit( X_train, y_train )\n",
    "\n",
    "# predict with it like any other pipeline\n",
    "y_pred = full_pipeline_m.predict( X_test ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "145513fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 51  35  14  87  71]\n",
      " [ 36 128  46 153 123]\n",
      " [ 24  79  65 105 110]\n",
      " [ 56 160  73 382 250]\n",
      " [ 72 169  82 292 449]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.21      0.20      0.21       258\n",
      "           2       0.22      0.26      0.24       486\n",
      "           3       0.23      0.17      0.20       383\n",
      "           4       0.37      0.41      0.39       921\n",
      "           5       0.45      0.42      0.43      1064\n",
      "\n",
      "    accuracy                           0.35      3112\n",
      "   macro avg       0.30      0.29      0.29      3112\n",
      "weighted avg       0.35      0.35      0.34      3112\n",
      "\n",
      "Accuracy: 0.345\n"
     ]
    }
   ],
   "source": [
    "# print evaluation metrics and results\n",
    "\n",
    "result1 = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(result1)\n",
    "\n",
    "result2 = classification_report(y_test, y_pred)\n",
    "print('\\nClassification Report:')\n",
    "print (result2)\n",
    "\n",
    "result3 = accuracy_score(y_test,y_pred)  \n",
    "print('Accuracy: %.3f' %result3)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5a3efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline_m.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65797bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance(model, X, ground_y):\n",
    "    \"\"\"Calculate some importance metrics for model evaluation: roc_auc_ovr, accuracy, precision_macro, recall_macro,\n",
    "    confusion matrix\"\"\"\n",
    "    ground_y = np.squeeze(ground_y)\n",
    "\n",
    "    predict_y = model.predict(X)\n",
    "    predict_y_proba = model.predict_proba(X)\n",
    "\n",
    "    roc_auc_score_perf = roc_auc_score(ground_y, predict_y_proba, average='macro', multi_class='ovr')  # ROC-AUC\n",
    "    #logLoss_perf = log_loss(ground_y, predict_y_proba)\n",
    "\n",
    "    accuracy_perf = (predict_y == ground_y).sum() / len(predict_y)\n",
    "    precision_score_perf = precision_score(ground_y, predict_y, average='macro')\n",
    "    recall_score_perf = recall_score(ground_y, predict_y, average='macro')\n",
    "\n",
    "    # Confusion matrix:\n",
    "    # print(\"Confusion matrix [[TN, FP]\\n[FN, TP]]:\\n\", confusion_matrix(ground_y, predict_y))\n",
    "    conf_m = confusion_matrix(ground_y, predict_y)\n",
    "\n",
    "    return roc_auc_score_perf, accuracy_perf, precision_score_perf, recall_score_perf, conf_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccc314e",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score_perf_train, \\\n",
    "accuracy_perf_train, precision_score_perf_train, recall_score_perf_train, \\\n",
    "conf_m_train = get_performance(full_pipeline_m, X_train, y_train)\n",
    "\n",
    "train_performance = pd.Series([roc_auc_score_perf_trai, \\\n",
    "                               accuracy_perf_train, \n",
    "                               precision_score_perf_train, recall_score_perf_train], \n",
    "                              index=['roc-auc_macro', 'accuracy',\n",
    "                                     'precison_macro', 'recall_macro'])\n",
    "\n",
    "\n",
    "roc_auc_score_perf_test, \\\n",
    "accuracy_perf_test, precision_score_perf_test, recall_score_perf_test, \\\n",
    "conf_m_test = get_performance(full_pipeline_m, X_test, y_test)\n",
    "\n",
    "test_performance = pd.Series([roc_auc_score_perf_test, \\\n",
    "                               accuracy_perf_test, \n",
    "                               precision_score_perf_test, recall_score_perf_test], index=['roc-auc_macro', 'accuracy', 'precison_macro', 'recall_macro'])\n",
    "\n",
    "\n",
    "\n",
    "performance_check = pd.DataFrame.from_dict({'train': train_performance, 'test': test_performance})\n",
    "performance_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2a55c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "67ab4fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the full pipeline as a step in another pipeline with an estimator as the final step\n",
    "full_pipeline_xgb = Pipeline( steps = [ ( 'full_pipeline', full_pipeline),\n",
    "                                  ( 'model', xgb.XGBClassifier(objective = 'multi:softmax' )) ] )\n",
    "\n",
    "# call fit on it just like any other pipeline\n",
    "full_pipeline_xgb.fit( X_train, y_train )\n",
    "\n",
    "# predict with it like any other pipeline\n",
    "y_pred = full_pipeline_xgb.predict( X_test ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "32a77542",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 16  12   2  90 138]\n",
      " [  2  34   4 272 174]\n",
      " [  2  12  11 198 160]\n",
      " [  2  14   4 442 459]\n",
      " [  1   7   5 260 791]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.06      0.11       258\n",
      "           2       0.43      0.07      0.12       486\n",
      "           3       0.42      0.03      0.05       383\n",
      "           4       0.35      0.48      0.40       921\n",
      "           5       0.46      0.74      0.57      1064\n",
      "\n",
      "    accuracy                           0.42      3112\n",
      "   macro avg       0.47      0.28      0.25      3112\n",
      "weighted avg       0.44      0.42      0.35      3112\n",
      "\n",
      "Accuracy: 0.416\n"
     ]
    }
   ],
   "source": [
    "# print evaluation metrics and results\n",
    "\n",
    "result1 = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(result1)\n",
    "\n",
    "result2 = classification_report(y_test, y_pred)\n",
    "print('\\nClassification Report:')\n",
    "print (result2)\n",
    "\n",
    "result3 = accuracy_score(y_test,y_pred)  \n",
    "print('Accuracy: %.3f' %result3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "6bf87614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance(model, X, ground_y):\n",
    "    \"\"\"Calculate some importance metrics for model evaluation: roc_auc_ovr, accuracy, precision_macro, recall_macro,\n",
    "    confusion matrix\"\"\"\n",
    "    ground_y = np.squeeze(ground_y)\n",
    "\n",
    "    predict_y = model.predict(X)\n",
    "    predict_y_proba = model.predict_proba(X)\n",
    "\n",
    "    roc_auc_score_perf = roc_auc_score(ground_y, predict_y_proba, average='macro', multi_class='ovr')  # ROC-AUC\n",
    "    #logLoss_perf = log_loss(ground_y, predict_y_proba)\n",
    "\n",
    "    accuracy_perf = (predict_y == ground_y).sum() / len(predict_y)\n",
    "    precision_score_perf = precision_score(ground_y, predict_y, average='macro')\n",
    "    recall_score_perf = recall_score(ground_y, predict_y, average='macro')\n",
    "\n",
    "    # Confusion matrix:\n",
    "    # print(\"Confusion matrix [[TN, FP]\\n[FN, TP]]:\\n\", confusion_matrix(ground_y, predict_y))\n",
    "    conf_m = confusion_matrix(ground_y, predict_y)\n",
    "\n",
    "    return roc_auc_score_perf, accuracy_perf, precision_score_perf, recall_score_perf, conf_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "439fde43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "roc-auc_macro     1.000000\n",
       "accuracy          0.999862\n",
       "precison_macro    0.999907\n",
       "recall_macro      0.999921\n",
       "dtype: float64"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score_perf_train,\\\n",
    "accuracy_perf_train, precision_score_perf_train, recall_score_perf_train, \\\n",
    "conf_m_train = get_performance(full_pipeline_rf, X_train, y_train)\n",
    "\n",
    "train_performance = pd.Series([roc_auc_score_perf_train, \\\n",
    "                               accuracy_perf_train, \n",
    "                               precision_score_perf_train, recall_score_perf_train], index=['roc-auc_macro', 'accuracy', 'precison_macro', 'recall_macro'])\n",
    "\n",
    "train_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "0b74b776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "roc-auc_macro     0.817235\n",
       "accuracy          0.587404\n",
       "precison_macro    0.717367\n",
       "recall_macro      0.508818\n",
       "dtype: float64"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score_perf_test,\\\n",
    "accuracy_perf_test, precision_score_perf_test, recall_score_perf_test, \\\n",
    "conf_m_test = get_performance(full_pipeline_rf, X_test, y_test)\n",
    "\n",
    "test_performance = pd.Series([roc_auc_score_perf_test, \\\n",
    "                               accuracy_perf_test, \n",
    "                               precision_score_perf_test, recall_score_perf_test], index=['roc-auc_macro', 'accuracy', 'precison_macro', 'recall_macro'])\n",
    "\n",
    "test_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "31cd1838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the full pipeline as a step in another pipeline with an estimator as the final step\n",
    "full_pipeline_rf = Pipeline( steps = [ ( 'full_pipeline', full_pipeline),\n",
    "                                  ( 'model', RandomForestClassifier(n_estimators=200, max_depth=None) ) ] )\n",
    "\n",
    "# call fit on it just like any other pipeline\n",
    "full_pipeline_rf.fit( X_train, y_train )\n",
    "\n",
    "# predict with it like any other pipeline\n",
    "y_pred_rf = full_pipeline_rf.predict( X_test ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "b7561e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_p = full_pipeline_m.predict( X_train ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "b3869701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 99  11   2  56  90]\n",
      " [  0 189   6 174 117]\n",
      " [  1  20 144 120  98]\n",
      " [  3  34   8 572 304]\n",
      " [  1  23   5 211 824]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.95      0.38      0.55       258\n",
      "           2       0.68      0.39      0.50       486\n",
      "           3       0.87      0.38      0.53       383\n",
      "           4       0.50      0.62      0.56       921\n",
      "           5       0.58      0.77      0.66      1064\n",
      "\n",
      "    accuracy                           0.59      3112\n",
      "   macro avg       0.72      0.51      0.56      3112\n",
      "weighted avg       0.64      0.59      0.58      3112\n",
      "\n",
      "Accuracy: 0.587\n"
     ]
    }
   ],
   "source": [
    "# print evaluation metrics and results\n",
    "\n",
    "result1 = confusion_matrix(y_test, y_pred_rf)\n",
    "print('Confusion Matrix:')\n",
    "print(result1)\n",
    "\n",
    "result2 = classification_report(y_test, y_pred_rf)\n",
    "print('\\nClassification Report:')\n",
    "print (result2)\n",
    "\n",
    "result3 = accuracy_score(y_test,y_pred_rf)  \n",
    "print('Accuracy: %.3f' %result3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "e339e22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 99  11   5  57  86]\n",
      " [  1 190   4 176 115]\n",
      " [  2  20 143 121  97]\n",
      " [  2  37   5 565 312]\n",
      " [  1  24   4 213 822]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.94      0.38      0.55       258\n",
      "           2       0.67      0.39      0.49       486\n",
      "           3       0.89      0.37      0.53       383\n",
      "           4       0.50      0.61      0.55       921\n",
      "           5       0.57      0.77      0.66      1064\n",
      "\n",
      "    accuracy                           0.58      3112\n",
      "   macro avg       0.72      0.51      0.56      3112\n",
      "weighted avg       0.64      0.58      0.58      3112\n",
      "\n",
      "Accuracy: 0.585\n"
     ]
    }
   ],
   "source": [
    "# print evaluation metrics and results\n",
    "\n",
    "result1 = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(result1)\n",
    "\n",
    "result2 = classification_report(y_test, y_pred)\n",
    "print('\\nClassification Report:')\n",
    "print (result2)\n",
    "\n",
    "result3 = accuracy_score(y_test,y_pred)  \n",
    "print('Accuracy: %.3f' %result3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "2225a6d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_prep' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-409-fdc1e03eaf15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mkfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_prep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_prep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#result2 = classification_report(y_test, y_pred, zero_division=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_prep' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "for model in [DecisionTreeClassifier, KNeighborsClassifier, GaussianNB, SVC, \n",
    "              RandomForestClassifier, SGDClassifier]:\n",
    "    make_pipeline(model())\n",
    "    classifier = model()\n",
    "    kfold = model_selection.KFold(n_splits=5)\n",
    "    classifier.fit(X_train_prep, y_train)\n",
    "    s = model_selection.cross_val_score(classifier, X_test_prep,y_test, cv=kfold)\n",
    "    #result2 = classification_report(y_test, y_pred, zero_division=0)\n",
    "    #s = model_selection.cross_val_score(cls, X, y, cv=kfold)\n",
    "    print(f\"{model.__name__:22}  CV_Mean:\" f\"{s.mean():.3f} CV_STD: {s.std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a553596",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgb = RandomForestClassifier()\n",
    "param_dist = {'n_estimators': stats.randint(150, 1000),\n",
    "              'learning_rate': stats.uniform(0.01, 0.59),\n",
    "              'subsample': stats.uniform(0.3, 0.6),\n",
    "              'max_depth': [3, 4, 5, 6, 7, 8, 9],\n",
    "              'colsample_bytree': stats.uniform(0.5, 0.4),\n",
    "              'min_child_weight': [1, 2, 3, 4]\n",
    "             }\n",
    "\n",
    "numFolds = 5\n",
    "n = X_train_prep.shape[0]\n",
    "kfold_5 = KFold(n, True, 5)\n",
    "\n",
    "clf = RandomizedSearchCV(clf_xgb, \n",
    "                         param_distributions = param_dist,\n",
    "                         cv = kfold_5,  \n",
    "                         n_iter = 5, # you want 5 here not 25 if I understand you correctly \n",
    "                         scoring = 'roc_auc', \n",
    "                         error_score = 0, \n",
    "                         verbose = 3, \n",
    "                         n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4b9649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_tune(base_model, parameters, n_iter, kfold, X=X_train, y=y_train):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Arrange data into folds with approx equal proportion of classes within each fold\n",
    "    k = StratifiedKFold(n_splits=kfold, shuffle=False)\n",
    "    \n",
    "    optimal_model = RandomizedSearchCV(base_model,\n",
    "                            param_distributions=parameters,\n",
    "                            n_iter=n_iter,\n",
    "                            cv=k,\n",
    "                            n_jobs=-1,\n",
    "                            random_state=42)\n",
    "    optimal_model.fit(X, y)\n",
    "    \n",
    "    stop_time = time.time()\n",
    "\n",
    "    scores = cross_val_score(optimal_model, X, y, cv=k, scoring=\"accuracy\")\n",
    "    \n",
    "    print(\"Elapsed Time:\", time.strftime(\"%H:%M:%S\", time.gmtime(stop_time - start_time)))\n",
    "    print(\"====================\")\n",
    "    print(\"Cross Val Mean: {:.3f}, Cross Val Stdev: {:.3f}\".format(scores.mean(), scores.std()))\n",
    "    print(\"Best Score: {:.3f}\".format(optimal_model.best_score_))\n",
    "    print(\"Best Parameters: {}\".format(optimal_model.best_params_))\n",
    "    \n",
    "    return optimal_model.best_params_, optimal_model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0beff1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import randint\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", category=PendingDeprecationWarning)\n",
    "warnings.simplefilter(\"ignore\", category=DeprecationWarning)\n",
    "warnings.simplefilter(\"ignore\", category=FutureWarning)\n",
    "warnings.simplefilter(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78765369",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = RandomForestClassifier(n_jobs=-1,\n",
    "                                   random_state=42)\n",
    "\n",
    "lots_of_parameters = {\n",
    "    \"max_depth\": [3, 5, 10, None],\n",
    "    \"n_estimators\": [100, 200, 300, 400, 500],\n",
    "    \"max_features\": randint(1, 3),\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"bootstrap\": [True, False],\n",
    "    \"min_samples_leaf\": randint(1, 4)\n",
    "}\n",
    "\n",
    "parameters = {\n",
    "    \"max_depth\": [3, 5, 10, None],\n",
    "    \"n_estimators\": [100, 200, 300, 400, 500]\n",
    "}\n",
    "\n",
    "best_params, best_score = hyperparameter_tune(base_model, parameters, 10, 5, X_train_prep, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f91af56",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=200)\n",
    "rf.fit(X_train_prep, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8eb612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "explainer = shap.TreeExplainer(rf)\n",
    "shap_values = explainer.shap_values(X_test_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05163898",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_test_prep, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475139ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f_type = df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d038a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f_type = df_f_type.loc[~df_f_type.index.isin(['JobSat'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cf2f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_if_num = df_f_type.apply(lambda x: np.issubdtype(x, np.number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c41869",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_if_num.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0396fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_cat = cols_if_num[~cols_if_num].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2df68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_cat in cols_cat:\n",
    "        df_sample[col_cat] = df_sample[col_cat].fillna('missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ffe077",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_num = cols_if_num[cols_if_num].index.tolist()\n",
    "cols_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687e2374",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_num in cols_num:\n",
    "        df_sample[col_num] = df_sample[col_num].fillna(df[col_num].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17de2b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample[cols_num].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5e7dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OrdinalEncoder()\n",
    "df_sample[cols_cat] = enc.fit_transform(df_sample[cols_cat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9ccb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OrdinalEncoder()\n",
    "df_sample.loc[:, 'JobSat'] = enc.fit_transform(df_sample[['JobSat']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6379101c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample['JobSat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8689463",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "172.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
