{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77e278e6",
   "metadata": {},
   "source": [
    "# Analysis of StackOverflow Survey. Part IV\n",
    "\n",
    "In this notebook we address the third question, and we build a model to predict job satisfaction for data coders.\n",
    "\n",
    "The steps of the process are: all steps with substeps\n",
    "1. \n",
    "2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9302f019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general packages and libraries\n",
    "import os\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15959c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data manipulation packages\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b486bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data visualizations packages\n",
    "import matplotlib.pyplot as plt\n",
    "# to render plots in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "# set a theme for seaborn\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29bafd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical, statistical and machine learning packages and libraries\n",
    "import xgboost as xgb\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn import (\n",
    "    ensemble,\n",
    "    tree,\n",
    ")\n",
    "from sklearn.base import (\n",
    "    BaseEstimator, \n",
    "    TransformerMixin,\n",
    ")\n",
    "from sklearn.pipeline import (\n",
    "    make_pipeline,\n",
    "    FeatureUnion, \n",
    "    Pipeline,\n",
    ")\n",
    "from sklearn.feature_selection import (\n",
    "    SelectKBest, \n",
    "    chi2, \n",
    "    mutual_info_classif,\n",
    ")\n",
    "from sklearn.impute import (\n",
    "    KNNImputer,\n",
    "    SimpleImputer,\n",
    ")\n",
    "from sklearn.preprocessing import (\n",
    "    OneHotEncoder, \n",
    "    OrdinalEncoder, \n",
    "    LabelEncoder,\n",
    "    StandardScaler,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    StratifiedKFold,\n",
    "    KFold,\n",
    "    cross_val_score,\n",
    ")\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "#from sklearn.ensemble import (RandomForestClassifier)\n",
    "\n",
    "from sklearn.linear_model import (\n",
    "    SGDClassifier,\n",
    "    LogisticRegression,\n",
    ") \n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    r2_score, \n",
    "    mean_squared_error,\n",
    "    auc,\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c403f1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import local module containing the neccessary functions\n",
    "import utils_functions as uf\n",
    "#import encoder_module as encm\n",
    "\n",
    "# forces the interpreter to re-load the module\n",
    "importlib.reload(uf);\n",
    "\n",
    "# create a path string\n",
    "mypath = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e11193",
   "metadata": {},
   "source": [
    "## Formulate the questions\n",
    "\n",
    "We separate the respondents of the 2020 StackOverflow Developer Survey into data developers\n",
    "(data scientist or machine learning specialist, data or business analyst, data engineer) and other developers. In what follows we restrict the dataset to the data developers and address the following questions:  \n",
    " - What can we tell about the job satisfaction of a data developer? \n",
    " - What factors do influence the job satisfaction? \n",
    " \n",
    "We build a predictive model for the job satisfaction for data developers. This is a multi-class classification question, where the satisfaction levels are: very dissatisfied, slightly dissatisfied, neither satisfied nor dissatisfied, slightly satisfied, very satisfied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5742328c",
   "metadata": {},
   "source": [
    "## Performance metrics - to review at the end\n",
    "\n",
    "The following performance measures will be used in this project:\n",
    "1. Cross validation via StratifiedKFold with 10 folds.\n",
    "2. Confusion matrix, in particular precision, recall and F1 score.\n",
    "3. The ROC curve and the related AUC score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e14fe65",
   "metadata": {},
   "source": [
    "# Gather and prepare the data\n",
    "\n",
    "Upload the data and keep the subset that contains those developers that work in data science related fields. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d46745",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42d728ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64461, 61)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# upload the datafile as pandas dataframe\n",
    "df = pd.read_csv(mypath+'/data/survey20_updated.csv', index_col=[0])\n",
    "# check for success\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6be69c",
   "metadata": {},
   "source": [
    "## Remove unnecessary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8826cbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy of the data\n",
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a425fe00",
   "metadata": {},
   "source": [
    "### Keep the developers that work with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1706ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Respondent\n",
       "1    [Developer, desktop or enterprise applications...\n",
       "2           [Developer, full-stack, Developer, mobile]\n",
       "3                                                  NaN\n",
       "Name: DevType, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change each string in DevType column into a list of strings\n",
    "df1['DevType'] = df1['DevType'].str.split(';')\n",
    "\n",
    "# check the outcome\n",
    "df1.DevType.iloc[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13c04778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(172185, 61)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split a row with multiple choices strings in DevType into rows where\n",
    "# DevType contains only one choice, the index is replicated \n",
    "df1=df1.explode('DevType')\n",
    "\n",
    "# the new dataframe has many more rows now\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7034b86f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Respondent\n",
       "1    Developer, desktop or enterprise applications\n",
       "1                            Developer, full-stack\n",
       "2                            Developer, full-stack\n",
       "2                                Developer, mobile\n",
       "3                                              NaN\n",
       "Name: DevType, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the outcome\n",
    "df1.DevType.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa81db4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop the rows with missing values in DevType column\n",
    "df1.dropna(subset=['DevType'], inplace=True)\n",
    "\n",
    "# check the outcome\n",
    "df1.DevType.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5eb6d645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Respondent\n",
       "22                                    Data engineer\n",
       "25                                    Data engineer\n",
       "30                         Data or business analyst\n",
       "36                         Data or business analyst\n",
       "36    Data scientist or machine learning specialist\n",
       "Name: DevType, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retain only those rows that contain data coders\n",
    "df1 = df1[df1['DevType'].str.contains('Data ')]\n",
    "\n",
    "# check for success\n",
    "df1.DevType.iloc[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bc697a",
   "metadata": {},
   "source": [
    "### Retain the developers that are employed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3e9e854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Employed full-time                                      9236\n",
       "Independent contractor, freelancer, or self-employed    1481\n",
       "Not employed, but looking for work                       564\n",
       "Employed part-time                                       469\n",
       "Name: Employment, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the employment types for data coders\n",
    "df1.Employment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82aad2a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Employed full-time                                      9236\n",
       "Independent contractor, freelancer, or self-employed    1481\n",
       "Employed part-time                                       469\n",
       "Name: Employment, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retain only the employed data developers\n",
    "df1 = df1[df1['Employment'] != 'Not employed, but looking for work']\n",
    "\n",
    "# check for success\n",
    "df1.Employment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0acc63a",
   "metadata": {},
   "source": [
    "### Retain only the respondents that code professionally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5c838e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I am a developer by profession                                                   8207\n",
       "I am not primarily a developer, but I write code sometimes as part of my work    2275\n",
       "I am a student who is learning to code                                            296\n",
       "I used to be a developer by profession, but no longer am                          203\n",
       "I code primarily as a hobby                                                       163\n",
       "Name: MainBranch, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the professional status of the employed developers\n",
    "df1.MainBranch.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "121a5c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I am a developer by profession                                                   8207\n",
       "I am not primarily a developer, but I write code sometimes as part of my work    2275\n",
       "Name: MainBranch, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a list of main branch choices\n",
    "main_choices = df1.MainBranch.value_counts().index.to_list()\n",
    "# retain those rows where MainBranch contains the respondents that work professionally with data\n",
    "df1 = df1[df1.MainBranch.isin(main_choices[:2])]\n",
    "\n",
    "# check the outcome\n",
    "df1.MainBranch.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb00e390",
   "metadata": {},
   "source": [
    "### Drop the rows with missing values in JobSat column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e657e16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with missing JobSat\n",
    "df1.dropna(subset=['JobSat'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910799ff",
   "metadata": {},
   "source": [
    "### Remove unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a943ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of columns to be removed\n",
    "cols_del = [\n",
    "    # personal, demographics  information\n",
    "    #'Respondent', \n",
    "    'MainBranch', 'Employment', 'Hobbyist', \n",
    "    'Country','Ethnicity', 'Age',\n",
    "    'Gender', 'Sexuality', 'Trans', \n",
    "    \n",
    "    # related to ConvertedComp\n",
    "    'CompFreq', 'CompTotal', 'CurrencyDesc', 'CurrencySymbol',\n",
    "    \n",
    "    # questions regarding future activities\n",
    "    'DatabaseDesireNextYear', 'MiscTechDesireNextYear',\n",
    "    'CollabToolsDesireNextYear', 'PlatformDesireNextYear',\n",
    "    'LanguageDesireNextYear', 'WebframeDesireNextYear',\n",
    "    \n",
    "    # questions regarding this survey\n",
    "    'SurveyEase', 'SurveyLength', 'WelcomeChange',\n",
    "    \n",
    "    # question regarding participation is StackOverflow\n",
    "    'SOSites', 'SOComm', 'SOPartFreq',\n",
    "    'SOVisitFreq', 'SOAccount',\n",
    "\n",
    "    # columns related to other columns\n",
    "    'Age1stCode', 'YearsCodePro', 'DevClass', \n",
    "\n",
    "    # high cardinality, multiple choices columns, add noise \n",
    "    'MiscTechWorkedWith', 'DatabaseWorkedWith',\n",
    "    'WebframeWorkedWith', 'LanguageWorkedWith',\n",
    "\n",
    "    # questions not relevant to our goal\n",
    "    'JobHunt', 'JobHuntResearch', 'Stuck',\n",
    "    'PurchaseResearch', 'PurchaseWhat', \n",
    "    'Stuck', 'PurpleLink',\n",
    "    'OffTopic', 'OtherComms',\n",
    "    'JobFactors', 'JobSeek',\n",
    "\n",
    "    # auxiliary columns\n",
    "    'DevClass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30fae562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10482, 17)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop all the columns in the list\n",
    "df1.drop(columns=cols_del, inplace=True)\n",
    "\n",
    "# check the output\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c137f8b4",
   "metadata": {},
   "source": [
    "#### Comments on feature selection\n",
    "Since we are left with 16 features only, I will not perform additional feature selection. After experimenting with a couple of feature selection options, such as mutual_info_classif and SelectKBest, I observed that the model doesn't not performed substantially better after applying feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2756f2e",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d0565c",
   "metadata": {},
   "source": [
    "### Replace JobSat categories with numerical code and drop missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f081bb5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    60329\n",
       "4    44791\n",
       "2    23989\n",
       "3    21298\n",
       "1    13562\n",
       "Name: JobSat, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the custom labelling \n",
    "df1['JobSat'] = df1['JobSat'].map(uf.JobSat_dict)\n",
    "# check the outcome\n",
    "df1['JobSat'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9b0500",
   "metadata": {},
   "source": [
    "### Update YearsCode column entries and dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b911d2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace strings with numerical entries\n",
    "replace_dict = {'Less than 1 year': '0', 'More than 50 years': '51'}\n",
    "df1.replace(replace_dict, inplace=True)\n",
    "\n",
    "# change dtype to numeric\n",
    "df1['YearsCode'] = pd.to_numeric(df1['YearsCode'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e1b115",
   "metadata": {},
   "source": [
    "### Replace multiple choices strings with single choice rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "907057ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(163969, 17)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_cols = ['CollabToolsWorkedWith','PlatformWorkedWith']\n",
    "\n",
    "# explode the two columns\n",
    "for col in multi_cols:\n",
    "    df1 = uf.explode_col(df1, col)\n",
    "    \n",
    "# check the outcome\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73aade3",
   "metadata": {},
   "source": [
    "### Review data types and data distribution in columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a39098d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ConvertedComp', 'WorkWeekHrs', 'YearsCode']\n"
     ]
    }
   ],
   "source": [
    "# the list of numerical columns\n",
    "num_cols = df1.select_dtypes(include='float64').columns.to_list()\n",
    "print(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b27ae29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DevType', 'EdLevel', 'CollabToolsWorkedWith', 'DevOps', 'DevOpsImpt', 'EdImpt', 'Learn', 'OnboardGood', 'Overtime', 'OpSys', 'OrgSize', 'PlatformWorkedWith', 'UndergradMajor']\n"
     ]
    }
   ],
   "source": [
    "# the list of all categorical columns\n",
    "cat_cols = df1.select_dtypes(include='object').columns.to_list()\n",
    "print(cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d551b2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Overtime', 'DevOps', 'EdLevel', 'DevType', 'OpSys', 'Learn', 'OnboardGood', 'UndergradMajor', 'DevOpsImpt', 'EdImpt', 'OrgSize']\n"
     ]
    }
   ],
   "source": [
    "# further divide the categorical columns in\n",
    "multi_cols = ['CollabToolsWorkedWith', 'PlatformWorkedWith']\n",
    "uni_cols = list(set(cat_cols) - set(multi_cols))\n",
    "print(uni_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e9b18e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each categorical column, print possible row values and their counts\n",
    "def list_answers(df, cat_cols):\n",
    "    for col in cat_cols:\n",
    "        print(col)\n",
    "        print(' ')\n",
    "        print(df1[col].value_counts())\n",
    "        print(' ')\n",
    "# print counts and values\n",
    "#list_answers(df1, all_cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563412d5",
   "metadata": {},
   "source": [
    "Comments:  \n",
    "\n",
    "All the categorical columns have unique strings as entries. So, at this point we can use one of the encoding methods from sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae6658c",
   "metadata": {},
   "source": [
    "### Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "56b0a709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(163969, 17)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop duplicate rows, if any\n",
    "df1.drop_duplicates(subset=None, keep='first', inplace=True)\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0647a0a0",
   "metadata": {},
   "source": [
    "## Refactor code\n",
    "\n",
    "Rewrite all of the steps for data pre-processing in a single function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9241d305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a fresh copy of the dataset\n",
    "dft=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b1c5a91e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(163969, 17)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all data cleaning and preprocessing steps\n",
    "dft = uf.remove_clean_data(dft)\n",
    "# check the outcome\n",
    "dft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180d1d99",
   "metadata": {},
   "source": [
    "## Sample data, create features and target datasets\n",
    "\n",
    "Create a dataframe X of features and a pandas series y that contains the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ef2c2180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy of the pre-processed dataframe\n",
    "df2 = df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f33fcada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((163969, 16), 163969)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the predictors dataframe\n",
    "X = df2.drop(columns = 'JobSat')\n",
    "\n",
    "# create the labels\n",
    "y = df2['JobSat']\n",
    "\n",
    "# check for success\n",
    "X.shape, len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75a23df",
   "metadata": {},
   "source": [
    "### Isolate a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d63ed50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (114778, 16) (114778,)\n",
      "Test (49191, 16) (49191,)\n"
     ]
    }
   ],
   "source": [
    "# split the data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# summarize the data\n",
    "print('Train', X_train.shape, y_train.shape)\n",
    "print('Test', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633f54bb",
   "metadata": {},
   "source": [
    "## Impute the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0d5c9262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the numerical columns in the train dataset\n",
    "X_train_num = X_train[num_cols]\n",
    "# create an instance of the KNN imputer\n",
    "num_imputer = KNNImputer(n_neighbors=5)\n",
    "# fit_transform the imputer on the training set\n",
    "X_train_num_imp = pd.DataFrame(num_imputer.fit_transform(X_train_num), \n",
    "                               columns=X_train_num.columns)\n",
    "# separate the numerical columns in the test set\n",
    "X_test_num = X_test[num_cols]\n",
    "# transform the test set with the imputer that was fit on the training set\n",
    "X_test_num_imp = pd.DataFrame(num_imputer.transform(X_test_num), columns=X_test_num.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b3d4fe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance of the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# scale the numerical variables, fit and transform on the straining set\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train_num_imp), \n",
    "                                columns=X_train_num_imp.columns)\n",
    "# use the scaler fit on training set to transform the test set\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test_num_imp), columns=X_test_num_imp.columns)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fbf8a1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate all the categorical columns in the training set\n",
    "X_train_cat = X_train[cat_cols]\n",
    "# create an instance of the imputer\n",
    "cat_imputer = SimpleImputer(strategy='constant', fill_value='missing')\n",
    "# fit and transform the training data\n",
    "X_train_cat_imp = pd.DataFrame(cat_imputer.fit_transform(X_train_cat), \n",
    "                               columns=X_train_cat.columns)\n",
    "# separate the categorical columns in the test set\n",
    "X_test_cat = X_test[cat_cols]\n",
    "# transform the test data with the imputer fit on the training set\n",
    "X_test_cat_imp=pd.DataFrame(cat_imputer.transform(X_test_cat), columns=X_test_cat.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831f5020",
   "metadata": {},
   "source": [
    "## Encode the predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "09cab43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the low cardinality columns\n",
    "def ord_encode_predictors(X_train, X_test):\n",
    "    oe = OrdinalEncoder()\n",
    "    oe.fit(X_train)\n",
    "    X_train_enc = pd.DataFrame(oe.transform(X_train))\n",
    "    X_test_enc = pd.DataFrame(oe.transform(X_test))\n",
    "    return X_train_enc, X_test_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3f9a17c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the low cardinality encoded features\n",
    "X_train_uni_enc, X_test_uni_enc = ord_encode_predictors(X_train_cat_imp[uni_cols],\n",
    "                                                        X_test_cat_imp[uni_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "86ae83e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the high cardinality columns\n",
    "def encode_predictors(X_train, X_test):\n",
    "    enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    enc.fit(X_train)\n",
    "    X_train_enc = pd.DataFrame(enc.transform(X_train))\n",
    "    X_test_enc = pd.DataFrame(enc.transform(X_test))\n",
    "    return X_train_enc, X_test_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "74cc7f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the high cardinality encoded features\n",
    "X_train_multi_enc, X_test_multi_enc = encode_predictors(X_train_cat_imp[multi_cols], \n",
    "                                                        X_test_cat_imp[multi_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "820a594e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the target variable \n",
    "def encode_target(y_train, y_test):\n",
    "\tle = LabelEncoder()\n",
    "\tle.fit(y_train)\n",
    "\ty_train_enc = le.transform(y_train)\n",
    "\ty_test_enc = le.transform(y_test)\n",
    "\treturn y_train_enc, y_test_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bf311d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the target variable - not necessary\n",
    "# y_train_enc, y_test_enc = encode_targets(y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "17c43b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the  X frames \n",
    "X_train_cat_enc = pd.concat([X_train_multi_enc, X_train_uni_enc], axis=1)\n",
    "X_train_prep = pd.concat([X_train_cat_enc, X_train_scaled], axis=1)\n",
    "\n",
    "X_test_cat_enc = pd.concat([X_test_multi_enc, X_test_uni_enc], axis=1)\n",
    "X_test_prep = pd.concat([X_test_cat_enc, X_test_scaled], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7c1d91",
   "metadata": {},
   "source": [
    "### Create a profiling report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9798aa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this once to generate a profiling report and save it as html file\n",
    "\n",
    "#import pandas_profiling\n",
    "#profile = pandas_profiling.ProfileReport(X_train, minimal=False)\n",
    "#profile.to_file(output_file=\"data_train_report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cd2b0d",
   "metadata": {},
   "source": [
    "## Refactor the code: build processing data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3e05378c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## refactor code: processing data\n",
    "\n",
    "# the steps in the categorical pipeline for columns of low cardinality\n",
    "uni_cat_pipeline = Pipeline( steps = [( 'unicat_selector', uf.FeatureSelector(uni_cols) ),\n",
    "                                  ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "                                  ( 'ordinal_encoder', OrdinalEncoder() ) ] )\n",
    "\n",
    "# the steps in the categorical pipeline for columns of high cardinality\n",
    "multi_cat_pipeline = Pipeline( steps = [( 'multicat_selector', uf.FeatureSelector(multi_cols) ),\n",
    "                                  ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "                                  ( 'one_hot_encoder', OneHotEncoder(sparse=False) ) ] )\n",
    "    \n",
    "# the steps in the numerical pipeline     \n",
    "num_pipeline = Pipeline( steps = [ ('num_selector', uf.FeatureSelector(num_cols) ),\n",
    "                                  ('imputer', KNNImputer(n_neighbors=5) ),\n",
    "                                  ( 'std_scaler', StandardScaler() ) ] )\n",
    "\n",
    "# combine the numerical and the categorical pipelines\n",
    "full_pipeline = FeatureUnion( transformer_list = [ ( 'unicat_pipeline', uni_cat_pipeline ), \n",
    "                                                  ( 'multicat_pipeline', multi_cat_pipeline ) ,\n",
    "                                                 ( 'numerical_pipeline', num_pipeline )] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0827cd0f",
   "metadata": {},
   "source": [
    "# Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "22e506a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the full pipeline as a step in another pipeline with an estimator as the final step\n",
    "full_pipeline_m = Pipeline( steps = [ ( 'full_pipeline', full_pipeline),\n",
    "                                  ( 'model', KNeighborsClassifier(n_neighbors=5) ) ] )\n",
    "\n",
    "# call fit on it just like any other pipeline\n",
    "full_pipeline_m.fit( X_train, y_train )\n",
    "\n",
    "# predict with it like any other pipeline\n",
    "y_pred = full_pipeline_m.predict( X_test ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "145513fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 3980    15    11    35    49]\n",
      " [   18  7035    40    88    68]\n",
      " [   13    35  6167    55    41]\n",
      " [   20    69    73 13137   127]\n",
      " [   29    82    70   138 17796]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.98      0.97      0.98      4090\n",
      "           2       0.97      0.97      0.97      7249\n",
      "           3       0.97      0.98      0.97      6311\n",
      "           4       0.98      0.98      0.98     13426\n",
      "           5       0.98      0.98      0.98     18115\n",
      "\n",
      "    accuracy                           0.98     49191\n",
      "   macro avg       0.98      0.98      0.98     49191\n",
      "weighted avg       0.98      0.98      0.98     49191\n",
      "\n",
      "Accuracy: 0.978\n"
     ]
    }
   ],
   "source": [
    "# print evaluation metrics and results\n",
    "\n",
    "result1 = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(result1)\n",
    "\n",
    "result2 = classification_report(y_test, y_pred)\n",
    "print('\\nClassification Report:')\n",
    "print (result2)\n",
    "\n",
    "result3 = accuracy_score(y_test,y_pred)  \n",
    "print('Accuracy: %.3f' %result3)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ee5a3efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_pipeline_m.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "65797bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance(model, X, ground_y):\n",
    "    \"\"\"Calculate some importance metrics for model evaluation: roc_auc_ovr, accuracy, precision_macro, recall_macro,\n",
    "    confusion matrix\"\"\"\n",
    "    ground_y = np.squeeze(ground_y)\n",
    "\n",
    "    predict_y = model.predict(X)\n",
    "    predict_y_proba = model.predict_proba(X)\n",
    "\n",
    "    roc_auc_score_perf = roc_auc_score(ground_y, predict_y_proba, average='macro', multi_class='ovr')  # ROC-AUC\n",
    "    logLoss_perf = log_loss(ground_y, predict_y_proba)\n",
    "\n",
    "    accuracy_perf = (predict_y == ground_y).sum() / len(predict_y)\n",
    "    precision_score_perf = precision_score(ground_y, predict_y, average='macro')\n",
    "    recall_score_perf = recall_score(ground_y, predict_y, average='macro')\n",
    "\n",
    "    # Confusion matrix:\n",
    "    # print(\"Confusion matrix [[TN, FP]\\n[FN, TP]]:\\n\", confusion_matrix(ground_y, predict_y))\n",
    "    conf_m = confusion_matrix(ground_y, predict_y)\n",
    "\n",
    "    return roc_auc_score_perf, logLoss_perf, accuracy_perf, precision_score_perf, recall_score_perf, conf_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "eccc314e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'log_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-76b9e649da41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mroc_auc_score_perf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogLoss_perf_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0maccuracy_perf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision_score_perf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall_score_perf_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mconf_m_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_pipeline_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m train_performance = pd.Series([roc_auc_score_perf_train, logLoss_perf_train, \\\n",
      "\u001b[0;32m<ipython-input-96-688bb0bd2659>\u001b[0m in \u001b[0;36mget_performance\u001b[0;34m(model, X, ground_y)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mroc_auc_score_perf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mground_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_y_proba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'macro'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ovr'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# ROC-AUC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mlogLoss_perf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mground_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_y_proba\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0maccuracy_perf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredict_y\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mground_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'log_loss' is not defined"
     ]
    }
   ],
   "source": [
    "roc_auc_score_perf_train, logLoss_perf_train, \\\n",
    "accuracy_perf_train, precision_score_perf_train, recall_score_perf_train, \\\n",
    "conf_m_train = get_performance(full_pipeline_m, X_train, y_train)\n",
    "\n",
    "train_performance = pd.Series([roc_auc_score_perf_train, logLoss_perf_train, \\\n",
    "                               accuracy_perf_train, \n",
    "                               precision_score_perf_train, recall_score_perf_train], \n",
    "                              index=['roc-auc_macro', 'logloss', 'accuracy',\n",
    "                                     'precison_macro', 'recall_macro'])\n",
    "\n",
    "\n",
    "roc_auc_score_perf_test, logLoss_perf_test, \\\n",
    "accuracy_perf_test, precision_score_perf_test, recall_score_perf_test, \\\n",
    "conf_m_test = get_performance(full_pipeline_m, X_test, y_test)\n",
    "\n",
    "test_performance = pd.Series([roc_auc_score_perf_test, logLoss_perf_test, \\\n",
    "                               accuracy_perf_test, \n",
    "                               precision_score_perf_test, recall_score_perf_test], index=['roc-auc_macro', 'logloss', 'accuracy', 'precison_macro', 'recall_macro'])\n",
    "\n",
    "\n",
    "\n",
    "performance_check = pd.DataFrame.from_dict({'train': train_performance, 'test': test_performance})\n",
    "performance_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2a55c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "67ab4fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the full pipeline as a step in another pipeline with an estimator as the final step\n",
    "full_pipeline_xgb = Pipeline( steps = [ ( 'full_pipeline', full_pipeline),\n",
    "                                  ( 'model', xgb.XGBClassifier(objective = 'binary:logistic') ) ] )\n",
    "\n",
    "# call fit on it just like any other pipeline\n",
    "full_pipeline_m.fit( X_train, y_train )\n",
    "\n",
    "# predict with it like any other pipeline\n",
    "y_pred = full_pipeline_m.predict( X_test ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "32a77542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  87   26    9  280  511]\n",
      " [   5  217    8  661  703]\n",
      " [   1   42  176  528  632]\n",
      " [   1   71   12 1423 1649]\n",
      " [   1   68   16  619 3362]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.92      0.10      0.17       913\n",
      "           2       0.51      0.14      0.22      1594\n",
      "           3       0.80      0.13      0.22      1379\n",
      "           4       0.41      0.45      0.43      3156\n",
      "           5       0.49      0.83      0.62      4066\n",
      "\n",
      "    accuracy                           0.47     11108\n",
      "   macro avg       0.62      0.33      0.33     11108\n",
      "weighted avg       0.54      0.47      0.42     11108\n",
      "\n",
      "Accuracy: 0.474\n"
     ]
    }
   ],
   "source": [
    "# print evaluation metrics and results\n",
    "\n",
    "result1 = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(result1)\n",
    "\n",
    "result2 = classification_report(y_test, y_pred)\n",
    "print('\\nClassification Report:')\n",
    "print (result2)\n",
    "\n",
    "result3 = accuracy_score(y_test,y_pred)  \n",
    "print('Accuracy: %.3f' %result3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "31cd1838",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2225a6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier  CV_Mean:0.755 CV_STD: 0.00\n",
      "KNeighborsClassifier    CV_Mean:0.607 CV_STD: 0.00\n",
      "GaussianNB              CV_Mean:0.214 CV_STD: 0.03\n",
      "SVC                     CV_Mean:0.535 CV_STD: 0.01\n",
      "RandomForestClassifier  CV_Mean:0.818 CV_STD: 0.01\n",
      "SGDClassifier           CV_Mean:0.364 CV_STD: 0.01\n"
     ]
    }
   ],
   "source": [
    "for model in [DecisionTreeClassifier, KNeighborsClassifier, GaussianNB, SVC, \n",
    "              RandomForestClassifier, SGDClassifier]:\n",
    "    make_pipeline(model())\n",
    "    classifier = model()\n",
    "    kfold = model_selection.KFold(n_splits=5)\n",
    "    classifier.fit(X_train_prep, y_train)\n",
    "    s = model_selection.cross_val_score(classifier, X_test_prep,y_test, cv=kfold)\n",
    "    #result2 = classification_report(y_test, y_pred, zero_division=0)\n",
    "    #s = model_selection.cross_val_score(cls, X, y, cv=kfold)\n",
    "    print(f\"{model.__name__:22}  CV_Mean:\" f\"{s.mean():.3f} CV_STD: {s.std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1a553596",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgb = RandomForestClassifier()\n",
    "param_dist = {'n_estimators': stats.randint(150, 1000),\n",
    "              'learning_rate': stats.uniform(0.01, 0.59),\n",
    "              'subsample': stats.uniform(0.3, 0.6),\n",
    "              'max_depth': [3, 4, 5, 6, 7, 8, 9],\n",
    "              'colsample_bytree': stats.uniform(0.5, 0.4),\n",
    "              'min_child_weight': [1, 2, 3, 4]\n",
    "             }\n",
    "\n",
    "numFolds = 5\n",
    "n = X_train_prep.shape[0]\n",
    "kfold_5 = KFold(n, True, 5)\n",
    "\n",
    "clf = RandomizedSearchCV(clf_xgb, \n",
    "                         param_distributions = param_dist,\n",
    "                         cv = kfold_5,  \n",
    "                         n_iter = 5, # you want 5 here not 25 if I understand you correctly \n",
    "                         scoring = 'roc_auc', \n",
    "                         error_score = 0, \n",
    "                         verbose = 3, \n",
    "                         n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cb4b9649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_tune(base_model, parameters, n_iter, kfold, X=X_train, y=y_train):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Arrange data into folds with approx equal proportion of classes within each fold\n",
    "    k = StratifiedKFold(n_splits=kfold, shuffle=False)\n",
    "    \n",
    "    optimal_model = RandomizedSearchCV(base_model,\n",
    "                            param_distributions=parameters,\n",
    "                            n_iter=n_iter,\n",
    "                            cv=k,\n",
    "                            n_jobs=-1,\n",
    "                            random_state=42)\n",
    "    optimal_model.fit(X, y)\n",
    "    \n",
    "    stop_time = time.time()\n",
    "\n",
    "    scores = cross_val_score(optimal_model, X, y, cv=k, scoring=\"accuracy\")\n",
    "    \n",
    "    print(\"Elapsed Time:\", time.strftime(\"%H:%M:%S\", time.gmtime(stop_time - start_time)))\n",
    "    print(\"====================\")\n",
    "    print(\"Cross Val Mean: {:.3f}, Cross Val Stdev: {:.3f}\".format(scores.mean(), scores.std()))\n",
    "    print(\"Best Score: {:.3f}\".format(optimal_model.best_score_))\n",
    "    print(\"Best Parameters: {}\".format(optimal_model.best_params_))\n",
    "    \n",
    "    return optimal_model.best_params_, optimal_model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b0beff1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import randint\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", category=PendingDeprecationWarning)\n",
    "warnings.simplefilter(\"ignore\", category=DeprecationWarning)\n",
    "warnings.simplefilter(\"ignore\", category=FutureWarning)\n",
    "warnings.simplefilter(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "78765369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 00:00:38\n",
      "====================\n",
      "Cross Val Mean: 0.931, Cross Val Stdev: 0.005\n",
      "Best Score: 0.930\n",
      "Best Parameters: {'n_estimators': 200, 'max_depth': None}\n"
     ]
    }
   ],
   "source": [
    "base_model = RandomForestClassifier(n_jobs=-1,\n",
    "                                   random_state=42)\n",
    "\n",
    "lots_of_parameters = {\n",
    "    \"max_depth\": [3, 5, 10, None],\n",
    "    \"n_estimators\": [100, 200, 300, 400, 500],\n",
    "    \"max_features\": randint(1, 3),\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"bootstrap\": [True, False],\n",
    "    \"min_samples_leaf\": randint(1, 4)\n",
    "}\n",
    "\n",
    "parameters = {\n",
    "    \"max_depth\": [3, 5, 10, None],\n",
    "    \"n_estimators\": [100, 200, 300, 400, 500]\n",
    "}\n",
    "\n",
    "best_params, best_score = hyperparameter_tune(base_model, parameters, 10, 5, X_train_prep, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7f91af56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=200)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=200)\n",
    "rf.fit(X_train_prep, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8eb612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "explainer = shap.TreeExplainer(rf)\n",
    "shap_values = explainer.shap_values(X_test_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05163898",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_test_prep, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "475139ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f_type = df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a7d038a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f_type = df_f_type.loc[~df_f_type.index.isin(['JobSat'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "03cf2f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_if_num = df_f_type.apply(lambda x: np.issubdtype(x, np.number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "95c41869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_if_num.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d0396fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_cat = cols_if_num[~cols_if_num].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "eb2df68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_cat in cols_cat:\n",
    "        df_sample[col_cat] = df_sample[col_cat].fillna('missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "60ffe077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Age', 'CompTotal', 'ConvertedComp', 'WorkWeekHrs']"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_num = cols_if_num[cols_if_num].index.tolist()\n",
    "cols_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "687e2374",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_num in cols_num:\n",
    "        df_sample[col_num] = df_sample[col_num].fillna(df[col_num].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "17de2b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age              0\n",
       "CompTotal        0\n",
       "ConvertedComp    0\n",
       "WorkWeekHrs      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample[cols_num].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "9d5e7dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OrdinalEncoder()\n",
    "df_sample[cols_cat] = enc.fit_transform(df_sample[cols_cat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "2b9ccb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OrdinalEncoder()\n",
    "df_sample.loc[:, 'JobSat'] = enc.fit_transform(df_sample[['JobSat']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "6379101c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Respondent\n",
       "18657    0.0\n",
       "20529    0.0\n",
       "32963    0.0\n",
       "43959    0.0\n",
       "1912     0.0\n",
       "        ... \n",
       "32979    4.0\n",
       "47032    4.0\n",
       "5262     4.0\n",
       "37419    4.0\n",
       "6479     4.0\n",
       "Name: JobSat, Length: 13558, dtype: float64"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample['JobSat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8689463",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "172.594px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
