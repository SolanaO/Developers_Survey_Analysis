{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77e278e6",
   "metadata": {},
   "source": [
    "# Analysis of StackOverflow Survey. Part IV\n",
    "\n",
    "In this notebook we address the third question, and we build a model to predict job satisfaction for data coders.\n",
    "\n",
    "The steps of the process are: all steps with substeps\n",
    "1. \n",
    "2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9302f019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general packages and libraries\n",
    "import os\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15959c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data manipulation packages\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b486bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data visualizations packages\n",
    "import matplotlib.pyplot as plt\n",
    "# to render plots in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "# set a theme for seaborn\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29bafd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean this up in the end\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn import (\n",
    "    ensemble,\n",
    "    preprocessing,\n",
    "    tree,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    StratifiedKFold,\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    r2_score, \n",
    "    mean_squared_error,\n",
    "    auc,\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c403f1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import local module containing the neccessary functions\n",
    "import utils_functions as uf\n",
    "#import encoder_module as encm\n",
    "\n",
    "# forces the interpreter to re-load the module\n",
    "importlib.reload(uf);\n",
    "\n",
    "# create a path string\n",
    "mypath = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e11193",
   "metadata": {},
   "source": [
    "## Formulate the questions\n",
    "\n",
    "We separate the respondents of the 2020 StackOverflow Developer Survey into data developers\n",
    "(data scientist or machine learning specialist, data or business analyst, data engineer) and other developers. In what follows we restrict the dataset to the data developers and address the following questions:  \n",
    " - What can we tell about the job satisfaction of a data developer? \n",
    " - What factors do influence the job satisfaction? \n",
    " \n",
    " We build a predictive model for the job satisfaction for data developers. This is a multi-class classification question, where the satisfaction levels are: very dissatisfied, slightly dissatisfied, neither satisfied nor dissatisfied, slightly satisfied, very satisfied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5742328c",
   "metadata": {},
   "source": [
    "## Performance metrics - to review at the end\n",
    "\n",
    "The following performance measures will be used in this project:\n",
    "1. Cross validation via StratifiedKFold with 10 folds.\n",
    "2. Confusion matrix, in particular precision, recall and F1 score.\n",
    "3. The ROC curve and the related AUC score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e14fe65",
   "metadata": {},
   "source": [
    "# Gather and prepare the data\n",
    "\n",
    "Upload the data and keep the subset that contains those developers that work in data science related fields. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d46745",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42d728ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload the datafile as pandas dataframe\n",
    "df = pd.read_csv(mypath+'/data/survey20_updated.csv', index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b91b39c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64461, 61)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for success\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6be69c",
   "metadata": {},
   "source": [
    "## Remove unnecessary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8826cbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy of the data\n",
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a425fe00",
   "metadata": {},
   "source": [
    "### Keep the developers that work with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1706ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Respondent\n",
       "1    [Developer, desktop or enterprise applications...\n",
       "2           [Developer, full-stack, Developer, mobile]\n",
       "3                                                  NaN\n",
       "Name: DevType, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change each string in DevType column into a list of strings\n",
    "df1['DevType'] = df1['DevType'].str.split(';')\n",
    "\n",
    "# check the outcome\n",
    "df1.DevType.iloc[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13c04778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(172185, 61)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split a row with multiple choices strings in DevType into rows where\n",
    "# DevType contains only one choice, the index is replicated \n",
    "df1=df1.explode('DevType')\n",
    "\n",
    "# the new dataframe has many more rows now\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7034b86f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Respondent\n",
       "1    Developer, desktop or enterprise applications\n",
       "1                            Developer, full-stack\n",
       "2                            Developer, full-stack\n",
       "2                                Developer, mobile\n",
       "3                                              NaN\n",
       "Name: DevType, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the outcome\n",
    "df1.DevType.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa81db4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop the rows with missing values in DevType column\n",
    "df1.dropna(subset=['DevType'], inplace=True)\n",
    "\n",
    "# check the outcome\n",
    "df1.DevType.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5eb6d645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Respondent\n",
       "22                                    Data engineer\n",
       "25                                    Data engineer\n",
       "30                         Data or business analyst\n",
       "36                         Data or business analyst\n",
       "36    Data scientist or machine learning specialist\n",
       "Name: DevType, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retain only those rows that contain data coders\n",
    "df1 = df1[df1['DevType'].str.contains('Data ')]\n",
    "\n",
    "# check for success\n",
    "df1.DevType.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8711a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11750, 61)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the new dataframe \n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bc697a",
   "metadata": {},
   "source": [
    "### Retain the developers that are employed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3e9e854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Employed full-time                                      9236\n",
       "Independent contractor, freelancer, or self-employed    1481\n",
       "Not employed, but looking for work                       564\n",
       "Employed part-time                                       469\n",
       "Name: Employment, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the employment types for data coders\n",
    "df1.Employment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82aad2a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Employed full-time                                      9236\n",
       "Independent contractor, freelancer, or self-employed    1481\n",
       "Employed part-time                                       469\n",
       "Name: Employment, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retain only the employed data developers\n",
    "df1 = df1[df1['Employment'] != 'Not employed, but looking for work']\n",
    "\n",
    "# check for success\n",
    "df1.Employment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21acfc82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data or business analyst                         3832\n",
       "Data scientist or machine learning specialist    3761\n",
       "Data engineer                                    3593\n",
       "Name: DevType, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the data distribution on types \n",
    "# note: recall that many respondents choose more than one option\n",
    "df1.DevType.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0acc63a",
   "metadata": {},
   "source": [
    "### Retain only the respondents that code professionally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5c838e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I am a developer by profession                                                   8207\n",
       "I am not primarily a developer, but I write code sometimes as part of my work    2275\n",
       "I am a student who is learning to code                                            296\n",
       "I used to be a developer by profession, but no longer am                          203\n",
       "I code primarily as a hobby                                                       163\n",
       "Name: MainBranch, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the professional status of the employed developers\n",
    "df1.MainBranch.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "121a5c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I am a developer by profession                                                   8207\n",
       "I am not primarily a developer, but I write code sometimes as part of my work    2275\n",
       "Name: MainBranch, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a list of main branch choices\n",
    "main_choices = df1.MainBranch.value_counts().index.to_list()\n",
    "# retain those rows where MainBranch contains the respondents that work professionally with data\n",
    "df1 = df1[df1.MainBranch.isin(main_choices[:2])]\n",
    "\n",
    "# check the outcome\n",
    "df1.MainBranch.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910799ff",
   "metadata": {},
   "source": [
    "### Remove unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a943ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of columns to be removed\n",
    "cols_del = [\n",
    "    # personal, demographics  information\n",
    "    #'Respondent', \n",
    "    'MainBranch', 'Employment', 'Hobbyist', \n",
    "    'Country','Ethnicity', 'Age',\n",
    "    'Gender', 'Sexuality', 'Trans', \n",
    "    \n",
    "    # related to ConvertedComp\n",
    "    'CompFreq', 'CompTotal', 'CurrencyDesc', 'CurrencySymbol',\n",
    "    \n",
    "    # questions regarding future activities\n",
    "    'DatabaseDesireNextYear', 'MiscTechDesireNextYear',\n",
    "    'CollabToolsDesireNextYear', 'PlatformDesireNextYear',\n",
    "    'LanguageDesireNextYear', 'WebframeDesireNextYear',\n",
    "    \n",
    "    # questions regarding this survey\n",
    "    'SurveyEase', 'SurveyLength', 'WelcomeChange',\n",
    "    \n",
    "    # question regarding participation is StackOverflow\n",
    "    'SOSites', 'SOComm', 'SOPartFreq',\n",
    "    'SOVisitFreq', 'SOAccount',\n",
    "\n",
    "    # columns related to other columns\n",
    "    'Age1stCode', 'YearsCodePro', 'DevClass', \n",
    "\n",
    "    # high cardinality, multiple choices columns, add noise \n",
    "    'DatabaseWorkedWith','MiscTechWorkedWith',\n",
    "    'WebframeWorkedWith', 'LanguageWorkedWith',\n",
    "    'CollabToolsWorkedWith',\n",
    "\n",
    "    # questions not relevant to our goal\n",
    "    'JobHunt', 'JobHuntResearch', 'Stuck',\n",
    "    'PurchaseResearch', 'PurchaseWhat', \n",
    "    'Stuck', 'PurpleLink',\n",
    "    'OffTopic', 'OtherComms',\n",
    "    'JobFactors', 'JobSeek',\n",
    "\n",
    "    # auxiliary columns\n",
    "    'DevClass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30fae562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10482, 16)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop all the columns in the list\n",
    "df1.drop(columns=cols_del, inplace=True)\n",
    "\n",
    "# check the output\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2756f2e",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d0565c",
   "metadata": {},
   "source": [
    "### Replace JobSat categories with numerical code and drop missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "34d0dab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    3582\n",
      "4    3079\n",
      "2    1623\n",
      "3    1242\n",
      "1     846\n",
      "Name: JobSat, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# drop rows with missing JobSat\n",
    "df1.dropna(subset=['JobSat'], inplace=True)\n",
    "\n",
    "# the replacement codes in a dictionary\n",
    "replace_dict = {'Very dissatisfied': 1, 'Slightly dissatisfied': 2,\n",
    "               'Neither satisfied nor dissatisfied': 3, \n",
    "               'Slightly satisfied': 4, 'Very satisfied': 5}\n",
    "\n",
    "#  encode the 'JobSat' data to numerical values\n",
    "df1['JobSat'] = df1['JobSat'].replace(replace_dict)\n",
    "\n",
    "# check for success\n",
    "print(df1['JobSat'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9b0500",
   "metadata": {},
   "source": [
    "### Update YearsCode column entries and dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b911d2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace strings with numerical entries\n",
    "replace_dict = {'Less than 1 year': '0', 'More than 50 years': '51'}\n",
    "df1.replace(replace_dict, inplace=True)\n",
    "\n",
    "# change dtype to numeric\n",
    "df1['YearsCode'] = pd.to_numeric(df1['YearsCode'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e1b115",
   "metadata": {},
   "source": [
    "### Replace multiple choices strings with single choice rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37850b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37040, 16)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# expand the multiple strings to multiple rows\n",
    "df1 = uf.explode_col(df1, 'PlatformWorkedWith')\n",
    "\n",
    "# check for success\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73aade3",
   "metadata": {},
   "source": [
    "### Review data types and data distribution in columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "33a14727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get basic information on the dataframe\n",
    "#df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a39098d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ConvertedComp', 'WorkWeekHrs', 'YearsCode']\n"
     ]
    }
   ],
   "source": [
    "# the list of numerical columns\n",
    "num_cols = df1.select_dtypes(include='float64').columns.to_list()\n",
    "print(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b27ae29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DevType', 'EdLevel', 'DevOps', 'DevOpsImpt', 'EdImpt', 'Learn', 'OnboardGood', 'Overtime', 'OpSys', 'OrgSize', 'PlatformWorkedWith', 'UndergradMajor']\n"
     ]
    }
   ],
   "source": [
    "# the list of categorical columns\n",
    "cat_cols = df1.select_dtypes(include='object').columns.to_list()\n",
    "print(cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e9b18e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each categorical column, print possible row values and their counts\n",
    "def list_answers(df, cat_cols):\n",
    "    for col in cat_cols:\n",
    "        print(col)\n",
    "        print(' ')\n",
    "        print(df1[col].value_counts())\n",
    "        print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f112c9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_answers(df1, cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563412d5",
   "metadata": {},
   "source": [
    "Comments:  \n",
    "\n",
    "All the categorical columns have unique strings as entries. So, at this point we can use one of the encoding methods from sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae6658c",
   "metadata": {},
   "source": [
    "### Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "56b0a709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37025, 16)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop duplicate rows, if any\n",
    "df1.drop_duplicates(subset=None, keep='first', inplace=True)\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0647a0a0",
   "metadata": {},
   "source": [
    "## Refactor code\n",
    "\n",
    "Rewrite all of the steps for data pre-processing in a single function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9241d305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a fresh copy of the dataset\n",
    "dft=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b1c5a91e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37025, 16)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all data cleaning and preprocessing steps\n",
    "dft = uf.remove_clean_data(dft)\n",
    "# check the outcome\n",
    "dft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180d1d99",
   "metadata": {},
   "source": [
    "## Sample data, create features and target datasets\n",
    "\n",
    "Create a dataframe X of features and a pandas series y that contains the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ef2c2180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy of the pre-processed dataframe\n",
    "df2 = df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f33fcada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((37025, 15), 37025)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the predictors dataframe\n",
    "X = df2.drop(columns = 'JobSat')\n",
    "\n",
    "# create the labels\n",
    "y = df2['JobSat']\n",
    "\n",
    "# check for success\n",
    "X.shape, len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75a23df",
   "metadata": {},
   "source": [
    "### Isolate a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d63ed50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (25917, 15) (25917,)\n",
      "Test (11108, 15) (11108,)\n"
     ]
    }
   ],
   "source": [
    "# split the data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# summarize the data\n",
    "print('Train', X_train.shape, y_train.shape)\n",
    "print('Test', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633f54bb",
   "metadata": {},
   "source": [
    "## Analyze the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0d5c9262",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num = X_train[num_cols]\n",
    "num_imputer = KNNImputer(n_neighbors=5)\n",
    "X_train_num_imp = pd.DataFrame(num_imputer.fit_transform(X_train_num), columns=X_train_num.columns)\n",
    "X_test_num = X_test[num_cols]\n",
    "X_test_num_imp = pd.DataFrame(num_imputer.transform(X_test_num), columns=X_test_num.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b3d4fe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# scale the numerical variables\n",
    "X_trained_scaled = pd.DataFrame(scaler.fit_transform(X_train_num_imp), columns=X_train_num_imp.columns)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test_num_imp), columns=X_test_num_imp.columns)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fbf8a1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cat = X_train[cat_cols]\n",
    "cat_imputer = SimpleImputer(strategy='constant', fill_value='missing')\n",
    "X_train_cat_imp = pd.DataFrame(cat_imputer.fit_transform(X_train_cat), columns=X_train_cat.columns)\n",
    "X_test_cat = X_test[cat_cols]\n",
    "X_test_cat_imp=pd.DataFrame(cat_imputer.transform(X_test_cat), columns=X_test_cat.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "86ae83e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_predictors(X_train, X_test):\n",
    "    enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    enc.fit(X_train)\n",
    "    X_train_enc = pd.DataFrame(enc.transform(X_train))\n",
    "    X_test_enc = pd.DataFrame(enc.transform(X_test))\n",
    "    return X_train_enc, X_test_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bf311d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_enc, X_test_enc = encode_predictors(X_train_cat_imp, X_test_cat_imp)\n",
    "X_train_prep = pd.concat([X_trained_scaled, X_train_enc], axis=1)\n",
    "X_test_prep = pd.concat([X_test_scaled, X_test_enc], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6867c6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d7c1d91",
   "metadata": {},
   "source": [
    "### Create a profiling report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9798aa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this once to generate a profiling report and save it as html file\n",
    "\n",
    "#import pandas_profiling\n",
    "#profile = pandas_profiling.ProfileReport(X_train, minimal=False)\n",
    "#profile.to_file(output_file=\"data_train_report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746f84af",
   "metadata": {},
   "source": [
    "## Impute the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "97890a4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a copy of the train set\n",
    "Xt = X_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "73cbbe31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvertedComp    6173\n",
       "WorkWeekHrs      2418\n",
       "YearsCode         157\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the numerical columns subset\n",
    "Xt_num = Xt[num_cols]\n",
    "Xt_num.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "668592bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvertedComp    0\n",
       "WorkWeekHrs      0\n",
       "YearsCode        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an instance of the imputer\n",
    "num_imputer = KNNImputer(n_neighbors=5)\n",
    "# impute the missing numerical values\n",
    "Xt_num_imp= pd.DataFrame(num_imputer.fit_transform(Xt_num), columns=Xt_num.columns)\n",
    "\n",
    "# check the outcome\n",
    "Xt_num_imp.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "37ae5d87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DevType                  0\n",
       "EdLevel                374\n",
       "DevOps                1033\n",
       "DevOpsImpt            1372\n",
       "EdImpt                 467\n",
       "Learn                 1078\n",
       "OnboardGood           1064\n",
       "Overtime               842\n",
       "OpSys                  851\n",
       "OrgSize                537\n",
       "PlatformWorkedWith     701\n",
       "UndergradMajor        1915\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the categorical columns subset\n",
    "Xt_cat = Xt[cat_cols]\n",
    "Xt_cat.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e06302d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DevType               0\n",
       "EdLevel               0\n",
       "DevOps                0\n",
       "DevOpsImpt            0\n",
       "EdImpt                0\n",
       "Learn                 0\n",
       "OnboardGood           0\n",
       "Overtime              0\n",
       "OpSys                 0\n",
       "OrgSize               0\n",
       "PlatformWorkedWith    0\n",
       "UndergradMajor        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an instance of the imputer\n",
    "cat_imputer = SimpleImputer(strategy='constant', fill_value='missing')\n",
    "# impute the missing categorical values\n",
    "Xt_cat_imp = pd.DataFrame(cat_imputer.fit_transform(Xt_cat), columns=Xt_cat.columns)\n",
    "\n",
    "# check for success\n",
    "Xt_cat_imp.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db87e638",
   "metadata": {},
   "source": [
    "## Encode the categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "58242af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummies for the categorical variables\n",
    "\n",
    "def encode_predictors(X_train): #X_test\n",
    "\tenc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\tenc.fit(X_train)\n",
    "\tX_train_enc = pd.DataFrame(enc.transform(X_train))\n",
    "    #X_test_enc = enc.transform(X_test)\n",
    "\treturn X_train_enc#, X_test_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e2d9835d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt_enc = encode_predictors(Xt_cat_imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9b9b7c",
   "metadata": {},
   "source": [
    "## Scale the numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4475326b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ConvertedComp</th>\n",
       "      <th>WorkWeekHrs</th>\n",
       "      <th>YearsCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.404268</td>\n",
       "      <td>0.016779</td>\n",
       "      <td>-1.303475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.439017</td>\n",
       "      <td>-0.754697</td>\n",
       "      <td>0.255928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.441597</td>\n",
       "      <td>-0.161254</td>\n",
       "      <td>-0.523774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.350753</td>\n",
       "      <td>-0.161254</td>\n",
       "      <td>-0.718699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.276874</td>\n",
       "      <td>0.432189</td>\n",
       "      <td>-0.621236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ConvertedComp  WorkWeekHrs  YearsCode\n",
       "0       2.404268     0.016779  -1.303475\n",
       "1      -0.439017    -0.754697   0.255928\n",
       "2      -0.441597    -0.161254  -0.523774\n",
       "3      -0.350753    -0.161254  -0.718699\n",
       "4      -0.276874     0.432189  -0.621236"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an instance of the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# scale the numerical variables\n",
    "Xt_scaled = pd.DataFrame(scaler.fit_transform(Xt_num_imp), columns=Xt_num.columns)\n",
    "\n",
    "# check the outcome\n",
    "Xt_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4b9894a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ConvertedComp</th>\n",
       "      <th>WorkWeekHrs</th>\n",
       "      <th>YearsCode</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.404268</td>\n",
       "      <td>0.016779</td>\n",
       "      <td>-1.303475</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.439017</td>\n",
       "      <td>-0.754697</td>\n",
       "      <td>0.255928</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.441597</td>\n",
       "      <td>-0.161254</td>\n",
       "      <td>-0.523774</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.350753</td>\n",
       "      <td>-0.161254</td>\n",
       "      <td>-0.718699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.276874</td>\n",
       "      <td>0.432189</td>\n",
       "      <td>-0.621236</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ConvertedComp  WorkWeekHrs  YearsCode    0    1    2    3    4    5    6  \\\n",
       "0       2.404268     0.016779  -1.303475  0.0  1.0  0.0  0.0  1.0  0.0  0.0   \n",
       "1      -0.439017    -0.754697   0.255928  0.0  0.0  1.0  0.0  0.0  0.0  0.0   \n",
       "2      -0.441597    -0.161254  -0.523774  1.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3      -0.350753    -0.161254  -0.718699  0.0  1.0  0.0  0.0  0.0  0.0  1.0   \n",
       "4      -0.276874     0.432189  -0.621236  0.0  0.0  1.0  0.0  1.0  0.0  0.0   \n",
       "\n",
       "   ...   79   80   81   82   83   84   85   86   87   88  \n",
       "0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 92 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine the categorical and the numerical columns\n",
    "Xt_prep = pd.concat([Xt_scaled, Xt_enc], axis=1)\n",
    "\n",
    "# check the outcome\n",
    "Xt_prep.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cd2b0d",
   "metadata": {},
   "source": [
    "## Refactor the code: build processing data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3e05378c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## refactor code: processing data\n",
    "\n",
    "# the steps in the categorical pipeline\n",
    "cat_pipeline = Pipeline( steps = [( 'cat_selector', uf.FeatureSelector(cat_cols) ),\n",
    "                                  ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "                                  ( 'one_hot_encoder', OneHotEncoder(sparse=False) ) ] )\n",
    "    \n",
    "# defining the steps in the numerical pipeline     \n",
    "num_pipeline = Pipeline( steps = [ ( 'num_selector', uf.FeatureSelector(num_cols) ),\n",
    "                                  ('imputer', KNNImputer(n_neighbors=5) ),\n",
    "                                  ( 'std_scaler', StandardScaler() ) ] )\n",
    "\n",
    "# combine the numerical and the categorical pipelines\n",
    "full_pipeline = FeatureUnion( transformer_list = [ ( 'categorical_pipeline', cat_pipeline ), \n",
    "                                                  ( 'numerical_pipeline', num_pipeline ) ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0827cd0f",
   "metadata": {},
   "source": [
    "# Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "22e506a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the full pipeline as a step in another pipeline with an estimator as the final step\n",
    "full_pipeline_m = Pipeline( steps = [ ( 'full_pipeline', full_pipeline),\n",
    "                                  ( 'model', KNeighborsClassifier(n_neighbors=5) ) ] )\n",
    "\n",
    "# call fit on it just like any other pipeline\n",
    "full_pipeline_m.fit( X_train, y_train )\n",
    "\n",
    "# predict with it like any other pipeline\n",
    "y_pred = full_pipeline_m.predict( X_test ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "145513fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 728   24   30   51   80]\n",
      " [  20 1330   32  104  108]\n",
      " [  30   54 1120   86   89]\n",
      " [  46  135   94 2640  241]\n",
      " [  65  107   77  291 3526]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.80      0.81       913\n",
      "           2       0.81      0.83      0.82      1594\n",
      "           3       0.83      0.81      0.82      1379\n",
      "           4       0.83      0.84      0.83      3156\n",
      "           5       0.87      0.87      0.87      4066\n",
      "\n",
      "    accuracy                           0.84     11108\n",
      "   macro avg       0.83      0.83      0.83     11108\n",
      "weighted avg       0.84      0.84      0.84     11108\n",
      "\n",
      "Accuracy: 0.841\n"
     ]
    }
   ],
   "source": [
    "# print evaluation metrics and results\n",
    "\n",
    "result1 = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(result1)\n",
    "\n",
    "result2 = classification_report(y_test, y_pred)\n",
    "print('\\nClassification Report:')\n",
    "print (result2)\n",
    "\n",
    "result3 = accuracy_score(y_test,y_pred)  \n",
    "print('Accuracy: %.3f' %result3)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "67ab4fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the full pipeline as a step in another pipeline with an estimator as the final step\n",
    "full_pipeline_m = Pipeline( steps = [ ( 'full_pipeline', full_pipeline),\n",
    "                                  ( 'model', xgb.XGBClassifier(objective = 'binary:logistic') ) ] )\n",
    "\n",
    "# call fit on it just like any other pipeline\n",
    "full_pipeline_m.fit( X_train, y_train )\n",
    "\n",
    "# predict with it like any other pipeline\n",
    "y_pred = full_pipeline_m.predict( X_test ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "32a77542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  87   26    9  280  511]\n",
      " [   5  217    8  661  703]\n",
      " [   1   42  176  528  632]\n",
      " [   1   71   12 1423 1649]\n",
      " [   1   68   16  619 3362]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.92      0.10      0.17       913\n",
      "           2       0.51      0.14      0.22      1594\n",
      "           3       0.80      0.13      0.22      1379\n",
      "           4       0.41      0.45      0.43      3156\n",
      "           5       0.49      0.83      0.62      4066\n",
      "\n",
      "    accuracy                           0.47     11108\n",
      "   macro avg       0.62      0.33      0.33     11108\n",
      "weighted avg       0.54      0.47      0.42     11108\n",
      "\n",
      "Accuracy: 0.474\n"
     ]
    }
   ],
   "source": [
    "# print evaluation metrics and results\n",
    "\n",
    "result1 = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(result1)\n",
    "\n",
    "result2 = classification_report(y_test, y_pred)\n",
    "print('\\nClassification Report:')\n",
    "print (result2)\n",
    "\n",
    "result3 = accuracy_score(y_test,y_pred)  \n",
    "print('Accuracy: %.3f' %result3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "31cd1838",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import (LogisticRegression)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import (KNeighborsClassifier)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import (RandomForestClassifier)\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2225a6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier  CV_Mean:0.755 CV_STD: 0.00\n",
      "KNeighborsClassifier    CV_Mean:0.607 CV_STD: 0.00\n",
      "GaussianNB              CV_Mean:0.214 CV_STD: 0.03\n",
      "SVC                     CV_Mean:0.535 CV_STD: 0.01\n",
      "RandomForestClassifier  CV_Mean:0.818 CV_STD: 0.01\n",
      "SGDClassifier           CV_Mean:0.364 CV_STD: 0.01\n"
     ]
    }
   ],
   "source": [
    "for model in [DecisionTreeClassifier, KNeighborsClassifier, GaussianNB, SVC, \n",
    "              RandomForestClassifier, SGDClassifier]:\n",
    "    make_pipeline(model())\n",
    "    classifier = model()\n",
    "    kfold = model_selection.KFold(n_splits=5)\n",
    "    classifier.fit(X_train_prep, y_train)\n",
    "    s = model_selection.cross_val_score(classifier, X_test_prep,y_test, cv=kfold)\n",
    "    #result2 = classification_report(y_test, y_pred, zero_division=0)\n",
    "    #s = model_selection.cross_val_score(cls, X, y, cv=kfold)\n",
    "    print(f\"{model.__name__:22}  CV_Mean:\" f\"{s.mean():.3f} CV_STD: {s.std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1a553596",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgb = RandomForestClassifier()\n",
    "param_dist = {'n_estimators': stats.randint(150, 1000),\n",
    "              'learning_rate': stats.uniform(0.01, 0.59),\n",
    "              'subsample': stats.uniform(0.3, 0.6),\n",
    "              'max_depth': [3, 4, 5, 6, 7, 8, 9],\n",
    "              'colsample_bytree': stats.uniform(0.5, 0.4),\n",
    "              'min_child_weight': [1, 2, 3, 4]\n",
    "             }\n",
    "\n",
    "numFolds = 5\n",
    "n = X_train_prep.shape[0]\n",
    "kfold_5 = KFold(n, True, 5)\n",
    "\n",
    "clf = RandomizedSearchCV(clf_xgb, \n",
    "                         param_distributions = param_dist,\n",
    "                         cv = kfold_5,  \n",
    "                         n_iter = 5, # you want 5 here not 25 if I understand you correctly \n",
    "                         scoring = 'roc_auc', \n",
    "                         error_score = 0, \n",
    "                         verbose = 3, \n",
    "                         n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cb4b9649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_tune(base_model, parameters, n_iter, kfold, X=X_train, y=y_train):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Arrange data into folds with approx equal proportion of classes within each fold\n",
    "    k = StratifiedKFold(n_splits=kfold, shuffle=False)\n",
    "    \n",
    "    optimal_model = RandomizedSearchCV(base_model,\n",
    "                            param_distributions=parameters,\n",
    "                            n_iter=n_iter,\n",
    "                            cv=k,\n",
    "                            n_jobs=-1,\n",
    "                            random_state=42)\n",
    "    optimal_model.fit(X, y)\n",
    "    \n",
    "    stop_time = time.time()\n",
    "\n",
    "    scores = cross_val_score(optimal_model, X, y, cv=k, scoring=\"accuracy\")\n",
    "    \n",
    "    print(\"Elapsed Time:\", time.strftime(\"%H:%M:%S\", time.gmtime(stop_time - start_time)))\n",
    "    print(\"====================\")\n",
    "    print(\"Cross Val Mean: {:.3f}, Cross Val Stdev: {:.3f}\".format(scores.mean(), scores.std()))\n",
    "    print(\"Best Score: {:.3f}\".format(optimal_model.best_score_))\n",
    "    print(\"Best Parameters: {}\".format(optimal_model.best_params_))\n",
    "    \n",
    "    return optimal_model.best_params_, optimal_model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b0beff1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import randint\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", category=PendingDeprecationWarning)\n",
    "warnings.simplefilter(\"ignore\", category=DeprecationWarning)\n",
    "warnings.simplefilter(\"ignore\", category=FutureWarning)\n",
    "warnings.simplefilter(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "78765369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 00:00:38\n",
      "====================\n",
      "Cross Val Mean: 0.931, Cross Val Stdev: 0.005\n",
      "Best Score: 0.930\n",
      "Best Parameters: {'n_estimators': 200, 'max_depth': None}\n"
     ]
    }
   ],
   "source": [
    "base_model = RandomForestClassifier(n_jobs=-1,\n",
    "                                   random_state=42)\n",
    "\n",
    "lots_of_parameters = {\n",
    "    \"max_depth\": [3, 5, 10, None],\n",
    "    \"n_estimators\": [100, 200, 300, 400, 500],\n",
    "    \"max_features\": randint(1, 3),\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"bootstrap\": [True, False],\n",
    "    \"min_samples_leaf\": randint(1, 4)\n",
    "}\n",
    "\n",
    "parameters = {\n",
    "    \"max_depth\": [3, 5, 10, None],\n",
    "    \"n_estimators\": [100, 200, 300, 400, 500]\n",
    "}\n",
    "\n",
    "best_params, best_score = hyperparameter_tune(base_model, parameters, 10, 5, X_train_prep, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7f91af56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=200)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=200)\n",
    "rf.fit(X_train_prep, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8eb612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "explainer = shap.TreeExplainer(rf)\n",
    "shap_values = explainer.shap_values(X_test_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05163898",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_test_prep, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d038a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "172.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
