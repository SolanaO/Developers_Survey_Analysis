{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77e278e6",
   "metadata": {},
   "source": [
    "# Analysis of StackOverflow Survey. Part IV\n",
    "\n",
    "In this notebook we address the third question, and we build a model to predict job satisfaction for data coders.\n",
    "\n",
    "The steps of the process are: all steps with substeps\n",
    "1. \n",
    "2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9302f019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general packages and libraries\n",
    "import os\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15959c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data manipulation packages\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b486bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data visualizations packages\n",
    "import matplotlib.pyplot as plt\n",
    "# to render plots in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "# set a theme for seaborn\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29bafd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical, statistical and machine learning packages and libraries\n",
    "import xgboost as xgb\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn import (\n",
    "    ensemble,\n",
    "    tree,\n",
    ")\n",
    "from sklearn.base import (\n",
    "    BaseEstimator, \n",
    "    TransformerMixin,\n",
    ")\n",
    "from sklearn.pipeline import (\n",
    "    make_pipeline,\n",
    "    FeatureUnion, \n",
    "    Pipeline,\n",
    ")\n",
    "from sklearn.feature_selection import (\n",
    "    SelectKBest, \n",
    "    chi2, \n",
    "    mutual_info_classif,\n",
    ")\n",
    "from sklearn.impute import (\n",
    "    KNNImputer,\n",
    "    SimpleImputer,\n",
    ")\n",
    "from sklearn.preprocessing import (\n",
    "    OneHotEncoder, \n",
    "    OrdinalEncoder, \n",
    "    LabelEncoder,\n",
    "    StandardScaler,\n",
    "    MultiLabelBinarizer,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    StratifiedKFold,\n",
    "    KFold,\n",
    "    cross_val_score,\n",
    ")\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.linear_model import (\n",
    "    SGDClassifier,\n",
    "    LogisticRegression,\n",
    ") \n",
    "\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    r2_score, \n",
    "    mean_squared_error,\n",
    "    auc,\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    log_loss,\n",
    "    roc_auc_score\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c403f1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import local modules \n",
    "import utils_functions as uf \n",
    "#import utils_classes as uc\n",
    "import local_maps as lm\n",
    "\n",
    "# forces the interpreter to re-load the module\n",
    "importlib.reload(uf);\n",
    "\n",
    "# create a path string\n",
    "mypath = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e11193",
   "metadata": {},
   "source": [
    "## Formulate the questions\n",
    "\n",
    "We separate the respondents of the 2020 StackOverflow Developer Survey into data developers\n",
    "(data scientist or machine learning specialist, data or business analyst, data engineer) and other developers. In what follows we restrict the dataset to the data developers and address the following questions:  \n",
    " - What can we tell about the job satisfaction of a data developer? \n",
    " - What factors do influence the job satisfaction? \n",
    " \n",
    "We build a predictive model for the job satisfaction for data developers. This is a multi-class classification question, where the satisfaction levels are: very dissatisfied, slightly dissatisfied, neither satisfied nor dissatisfied, slightly satisfied, very satisfied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5742328c",
   "metadata": {},
   "source": [
    "## Performance metrics - to review at the end\n",
    "\n",
    "The following performance measures will be used in this project:\n",
    "1. Cross validation via StratifiedKFold with 10 folds.\n",
    "2. Confusion matrix, in particular precision, recall and F1 score.\n",
    "3. The ROC curve and the related AUC score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e14fe65",
   "metadata": {},
   "source": [
    "## Gather and prepare the data\n",
    "\n",
    "Upload the data and keep the subset that contains those developers that work in data science related fields. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d46745",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42d728ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64461, 61)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# upload the datafile as pandas dataframe\n",
    "df = pd.read_csv(mypath+'/data/survey20_updated.csv', index_col=[0])\n",
    "# check for success\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6be69c",
   "metadata": {},
   "source": [
    "## Remove unnecessary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8826cbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy of the data\n",
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a425fe00",
   "metadata": {},
   "source": [
    "### Retain only the developers that work with data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa17e5cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(172185, 61)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parse each list of strings entry \n",
    "df1['DevType'] = df1['DevType'].str.split(';')\n",
    "\n",
    "# transform each element of a list-like to a row, replicating index values\n",
    "df1 = df1.explode('DevType')\n",
    "\n",
    "# check the outcome\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5523bbe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11750, 61)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retain only those rows that contain data coders\n",
    "df1 = df1.loc[df1.DevType.str.contains('Data ', na=False)]\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bc697a",
   "metadata": {},
   "source": [
    "### Retain the developers that are employed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3e9e854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Employed full-time                                      9236\n",
       "Independent contractor, freelancer, or self-employed    1481\n",
       "Not employed, but looking for work                       564\n",
       "Employed part-time                                       469\n",
       "Name: Employment, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the employment types for data coders\n",
    "df1.Employment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82aad2a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Employed full-time                                      9236\n",
       "Independent contractor, freelancer, or self-employed    1481\n",
       "Employed part-time                                       469\n",
       "Name: Employment, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retain only the employed data developers\n",
    "df1 = df1[df1['Employment'] != 'Not employed, but looking for work']\n",
    "\n",
    "# check for success\n",
    "df1.Employment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0acc63a",
   "metadata": {},
   "source": [
    "### Retain only the respondents that code professionally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5c838e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I am a developer by profession                                                   8207\n",
       "I am not primarily a developer, but I write code sometimes as part of my work    2275\n",
       "I am a student who is learning to code                                            296\n",
       "I used to be a developer by profession, but no longer am                          203\n",
       "I code primarily as a hobby                                                       163\n",
       "Name: MainBranch, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the professional status of the employed developers\n",
    "df1.MainBranch.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "121a5c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I am a developer by profession                                                   8207\n",
       "I am not primarily a developer, but I write code sometimes as part of my work    2275\n",
       "Name: MainBranch, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a list of main branch choices\n",
    "main_choices = df1.MainBranch.value_counts().index.to_list()\n",
    "\n",
    "# retain only those rows where MainBranch contains data professionals\n",
    "df1 = df1[df1.MainBranch.isin(main_choices[:2])]\n",
    "\n",
    "# check the outcome\n",
    "df1.MainBranch.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb00e390",
   "metadata": {},
   "source": [
    "### Drop the rows with missing values in JobSat column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e657e16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with missing JobSat\n",
    "df1.dropna(subset=['JobSat'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910799ff",
   "metadata": {},
   "source": [
    "### Remove irrelevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a943ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of columns to be removed\n",
    "cols_del = [\n",
    "    # personal, demographics  information\n",
    "    #'Respondent', \n",
    "    'MainBranch', 'Employment', 'Hobbyist', \n",
    "    'Country','Ethnicity', 'Age',\n",
    "    'Gender', 'Sexuality', 'Trans', \n",
    "    \n",
    "    # related to ConvertedComp\n",
    "    'CompFreq', 'CompTotal', 'CurrencyDesc', 'CurrencySymbol',\n",
    "    \n",
    "    # questions regarding future activities\n",
    "    'DatabaseDesireNextYear', 'MiscTechDesireNextYear',\n",
    "    'CollabToolsDesireNextYear', 'PlatformDesireNextYear',\n",
    "    'LanguageDesireNextYear', 'WebframeDesireNextYear',\n",
    "    \n",
    "    # questions regarding this survey\n",
    "    'SurveyEase', 'SurveyLength', 'WelcomeChange',\n",
    "    \n",
    "    # question regarding participation is StackOverflow\n",
    "    'SOSites', 'SOComm', 'SOPartFreq',\n",
    "    'SOVisitFreq', 'SOAccount',\n",
    "\n",
    "    # columns related to other columns\n",
    "    'Age1stCode', 'YearsCodePro', 'DevType', \n",
    "\n",
    "    # high cardinality, multiple choices columns, add noise \n",
    "    'MiscTechWorkedWith', 'DatabaseWorkedWith', #'CollabToolsWorkedWith',\n",
    "    'WebframeWorkedWith', 'LanguageWorkedWith',\n",
    "\n",
    "    # other questions not directly related to our goal\n",
    "    #'JobHunt',\n",
    "    'JobHuntResearch', 'Stuck',\n",
    "    'PurchaseResearch', \n",
    "    #'PurchaseWhat', \n",
    "    'Stuck', 'PurpleLink',\n",
    "    'OffTopic', 'OtherComms',\n",
    "    'JobFactors', \n",
    "    #'JobSeek',\n",
    "\n",
    "    # auxiliary columns\n",
    "    'DevClass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30fae562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10372, 19)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop all the columns in the list\n",
    "df1.drop(columns=cols_del, inplace=True)\n",
    "\n",
    "# check the output\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c137f8b4",
   "metadata": {},
   "source": [
    "## On feature selection\n",
    "\n",
    "Since we are left with less than 20 features, I will not perform additional feature selection. After experimenting with a couple of feature selection options, such as `mutual_info_classif` and `SelectKBest`, I observed that working with the suggested 10-15 features did not significantly improved the performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2756f2e",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d0565c",
   "metadata": {},
   "source": [
    "### Numerically encode JobSat column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a216eb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding map for job satisfaction\n",
    "JobSat_dict =  {'Very dissatisfied': 1, 'Slightly dissatisfied': 2,\n",
    "               'Neither satisfied nor dissatisfied': 3, \n",
    "               'Slightly satisfied': 4, 'Very satisfied': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f081bb5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    3582\n",
       "4    3079\n",
       "2    1623\n",
       "3    1242\n",
       "1     846\n",
       "Name: JobSat, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the custom labelling \n",
    "df1['JobSat'] = df1['JobSat'].map(JobSat_dict)\n",
    "# check the outcome\n",
    "df1['JobSat'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9b0500",
   "metadata": {},
   "source": [
    "### Update YearsCode column entries and dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b911d2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace strings with numerical entries\n",
    "replace_dict = {'Less than 1 year': '0', 'More than 50 years': '51'}\n",
    "df1.replace(replace_dict, inplace=True)\n",
    "\n",
    "# change dtype to numeric\n",
    "df1['YearsCode'] = pd.to_numeric(df1['YearsCode'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96766c9e",
   "metadata": {},
   "source": [
    "### Pre-process the multi levels columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "230d94e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the list of columns with many levels \n",
    "multi_cols = ['PlatformWorkedWith', 'CollabToolsWorkedWith']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "035020cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the list of columns with many levels \n",
    "multi_cols = ['PlatformWorkedWith', 'CollabToolsWorkedWith']\n",
    "\n",
    "def parse_multi_columns(df, multi_cols):\n",
    "    \"\"\"\n",
    "    Replaces the list of entries with a set, missing values with the empty set.\n",
    "    INPUT: \n",
    "       df = dataframe\n",
    "       multi_cols = list of columns to be parsed\n",
    "    OUTPUT = transformed column\n",
    "    \"\"\"\n",
    "    for col in multi_cols:\n",
    "        df[col] = df[col].str.split(';').apply(lambda x: {} if\n",
    "                                               x is np.nan else set(x))\n",
    "    return df\n",
    "\n",
    "# apply the transformation to the two columns\n",
    "df1 = parse_multi_columns(df1, multi_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4b44a8",
   "metadata": {},
   "source": [
    "## Save the preprocessed data to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1209dea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save a copy of the preprocessed dataframe\n",
    "df1.to_csv(mypath + '/data/survey20_pprocessd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "459d3a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the pre-processed data\n",
    "#dfp = pd.read_csv(mypath+'/data/survey20_pprocessd.csv', index_col=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3192bc",
   "metadata": {},
   "source": [
    "## Refactor code\n",
    "\n",
    "Rewrite all of the steps for data pre-processing in a single function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0c663f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a fresh copy of the dataset\n",
    "#dfp = df.copy()\n",
    "\n",
    "# all data cleaning and preprocessing steps\n",
    "#dfp = uf.remove_clean_data(dft)\n",
    "\n",
    "# check the outcome\n",
    "#dfp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73aade3",
   "metadata": {},
   "source": [
    "### Group columns by data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a39098d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ConvertedComp', 'WorkWeekHrs', 'YearsCode']\n"
     ]
    }
   ],
   "source": [
    "# the list of numerical columns\n",
    "num_cols = df1.select_dtypes(include='float64').columns.to_list()\n",
    "print(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d551b2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the list of discrete columns with many levels \n",
    "multi_cols = ['PlatformWorkedWith', 'CollabToolsWorkedWith']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b27ae29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EdLevel', 'EdImpt', 'JobHunt', 'OnboardGood', 'JobSeek', 'Overtime', 'DevOps', 'Learn', 'UndergradMajor', 'OpSys', 'DevOpsImpt', 'OrgSize', 'PurchaseWhat']\n"
     ]
    }
   ],
   "source": [
    "# the list of discrete columns with several levels\n",
    "cat_cols = df1.select_dtypes(include='object').columns.to_list()\n",
    "uni_cols = list(set(cat_cols) - set(multi_cols))\n",
    "print(uni_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e9b18e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each categorical column, print possible row values and their counts\n",
    "def list_answers(df, cat_cols):\n",
    "    for col in cat_cols:\n",
    "        print(col)\n",
    "        print(' ')\n",
    "        print(df1[col].value_counts())\n",
    "        print(' ')\n",
    "#print counts and values\n",
    "# list_answers(df1, cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180d1d99",
   "metadata": {},
   "source": [
    "## Sample data, create features and target datasets\n",
    "\n",
    "Create a dataframe X of features and a pandas series y that contains the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ef2c2180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy of the pre-processed dataframe\n",
    "df2 = df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f33fcada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10372, 18), 10372)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the predictors dataframe\n",
    "X = df2.drop(columns = 'JobSat')\n",
    "\n",
    "# create the labels\n",
    "y = df2['JobSat']\n",
    "\n",
    "# check for success\n",
    "X.shape, len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75a23df",
   "metadata": {},
   "source": [
    "### Isolate a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d63ed50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (7260, 18) (7260,)\n",
      "Test (3112, 18) (3112,)\n"
     ]
    }
   ],
   "source": [
    "# split the data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# summarize the data\n",
    "print('Train', X_train.shape, y_train.shape)\n",
    "print('Test', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013a3de2",
   "metadata": {},
   "source": [
    "## Encode the discrete variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36409176",
   "metadata": {},
   "source": [
    "### Encode the columns with many levels\n",
    "\n",
    "After data cleaning and pre-processing the columns with many levels are grouped n the list: multi_cols. The steps are:\n",
    "- use the MultiLabelBinarizer to create boolean columns for each possible answer found in the pre-processed entries,\n",
    "- keep the columns that correspond to the most populous choices for each of he initial columns that are encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9c8d5ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance of the encoder\n",
    "mlb = MultiLabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "22b23d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the binarizer on the train set\n",
    "mlb_plat = mlb.fit(X_train['PlatformWorkedWith'])\n",
    "\n",
    "# transform the corresponding column in the train set\n",
    "mlb_plat_train =  mlb.transform(X_train['PlatformWorkedWith'])\n",
    "\n",
    "# put the outcome in pandas dataframe form\n",
    "temp_plat_train = pd.DataFrame(mlb_plat_train, columns = mlb_plat.classes_,\n",
    "                         index = X_train.index)\n",
    "\n",
    "# list the three most popular platforms to retain\n",
    "platform_keep = list(temp_plat_train.sum().sort_values(ascending=False).head(3).index)\n",
    "\n",
    "# combine the two dataframes and drop the initial column\n",
    "X_train = pd.concat([X_train, temp_plat_train[platform_keep]],\n",
    "                    axis=1).drop(columns = ['PlatformWorkedWith'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d92367ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the same transformations to the test set\n",
    "mlb_plat_test =  mlb.transform(X_test['PlatformWorkedWith'])\n",
    "\n",
    "# put the outcome in pandas dataframe form\n",
    "temp_plat_test = pd.DataFrame(mlb_plat_test, columns = mlb_plat.classes_,\n",
    "                              index = X_test.index)\n",
    "\n",
    "# combine the two dataframes and drop the initial column\n",
    "X_test = pd.concat([X_test, temp_plat_test[platform_keep]], \n",
    "                   axis=1).drop(columns = ['PlatformWorkedWith'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a6d8263b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance of the encoder\n",
    "mlb = MultiLabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "95c30fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the binarizer on the train set\n",
    "mlb_colab = mlb.fit(X_train['CollabToolsWorkedWith'])\n",
    "\n",
    "# transform the corresponding column in the train set\n",
    "mlb_colab_train =  mlb.transform(X_train['CollabToolsWorkedWith'])\n",
    "\n",
    "# put the outcome in pandas dataframe form\n",
    "temp_colab_train = pd.DataFrame(mlb_colab_train, columns = mlb_colab.classes_,\n",
    "                         index = X_train.index)\n",
    "\n",
    "# list the three most popular platforms to retain\n",
    "colab_keep = list(temp_colab_train.sum().sort_values(ascending=False).head(3).index)\n",
    "\n",
    "# combine the two dataframes and drop the initial column\n",
    "X_train = pd.concat([X_train, temp_colab_train[colab_keep]],\n",
    "                    axis=1).drop(columns = ['CollabToolsWorkedWith'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "da107bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the same transformations to the test set\n",
    "mlb_colab_test =  mlb.transform(X_test['CollabToolsWorkedWith'])\n",
    "\n",
    "# put the outcome in pandas dataframe form\n",
    "temp_colab_test = pd.DataFrame(mlb_colab_test, columns = mlb_colab.classes_,\n",
    "                              index = X_test.index)\n",
    "\n",
    "# combine the two dataframes and drop the initial column\n",
    "X_test = pd.concat([X_test, temp_colab_test[platform_keep]], \n",
    "                   axis=1).drop(columns = ['CollabToolsWorkedWith'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fdcf125d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7260, 19) (3112, 16)\n",
      "\n",
      "[]\n",
      "\n",
      "['Github', 'Slack', 'Jira']\n"
     ]
    }
   ],
   "source": [
    "# check the outcome\n",
    "print(X_train.shape, X_test.shape)\n",
    "print('')\n",
    "print(platform_keep)\n",
    "print('')\n",
    "print(colab_keep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabf3070",
   "metadata": {},
   "source": [
    "#### Comment:\n",
    "\n",
    "All the above steps will be included in a custom transformer for the processing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "94f5eca3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AWS</th>\n",
       "      <th>Android</th>\n",
       "      <th>Arduino</th>\n",
       "      <th>Docker</th>\n",
       "      <th>Google Cloud Platform</th>\n",
       "      <th>Heroku</th>\n",
       "      <th>IBM Cloud or Watson</th>\n",
       "      <th>Kubernetes</th>\n",
       "      <th>Linux</th>\n",
       "      <th>MacOS</th>\n",
       "      <th>Microsoft Azure</th>\n",
       "      <th>Raspberry Pi</th>\n",
       "      <th>Slack Apps and Integrations</th>\n",
       "      <th>Windows</th>\n",
       "      <th>WordPress</th>\n",
       "      <th>iOS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Respondent</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43724</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32280</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            AWS  Android  Arduino  Docker  Google Cloud Platform  Heroku  \\\n",
       "Respondent                                                                 \n",
       "43724         0        0        0       0                      0       0   \n",
       "32280         1        0        0       1                      1       0   \n",
       "\n",
       "            IBM Cloud or Watson  Kubernetes  Linux  MacOS  Microsoft Azure  \\\n",
       "Respondent                                                                   \n",
       "43724                         0           0      1      0                0   \n",
       "32280                         0           0      1      0                0   \n",
       "\n",
       "            Raspberry Pi  Slack Apps and Integrations  Windows  WordPress  iOS  \n",
       "Respondent                                                                      \n",
       "43724                  0                            0        0          0    0  \n",
       "32280                  0                            0        0          0    0  "
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# put the outcome in pandas dataframe form\n",
    "t#emp_df = pd.DataFrame(temp_col, columns=mlb.classes_, index=X_train.index)\n",
    "# check the outcome\n",
    "#temp_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "c6b0975c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list the three most popular platforms\n",
    "platform_keep = list(temp_df.sum().sort_values(ascending=False).head(3).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "d9cce5ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7260, 16)"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine the two dataframes and drop the initial column\n",
    "X_train = pd.concat([X_train, temp_df[platform_keep]], axis=1).drop(columns = ['PlatformWorkedWith'])\n",
    "\n",
    "# check the outcome\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17af038d",
   "metadata": {},
   "source": [
    "#### Comments:\n",
    "\n",
    "There are several options to choose from when encoded the columns with high cardinality, that originate from multiple answers questions. If we use MultiLabelBinarizer, a column such PlatformWorkedWith will create 16 new columns, which doubles the number of features in the dataframe. In order to address this column explosion, we droped all the new columns but the 3 that correspond to the most popular choices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a38db99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18087b04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b10b394",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParseMultiColumns(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Custom transformer that that changes a list of strings to a set in a column of a dataframe, and assigns the empty set to missing entries.\n",
    "    \"\"\"\n",
    "    #class constructor method \n",
    "    def __init__(self, multi_cols=['PlatformWorkedWith']):\n",
    "            self.multi_cols = multi_cols\n",
    "            \n",
    "    # return self nothing else to do here\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        for col in self.multi_cols:\n",
    "            X[col] = X[col].str.split(';').apply(lambda x: {} if x is np.nan else set(x))\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3665c57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiColumnsEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Scikit-learn transformer to convert a feature column of a list in \n",
    "    to multiple binary feature columns\"\"\"\n",
    "    def __init__(self, feature_names=None):\n",
    "            self.feature_names = feature_names\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.encoder_dict_ = {}\n",
    "        \n",
    "        for col in self.feature_names:\n",
    "            mlb = MultiLabelBinarizer()\n",
    "            mlb.fit(X[col])\n",
    "            self.encoder_dict_[col] = mlb\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        for col in self.feature_names:\n",
    "            col_encoded = pd.DataFrame(\n",
    "                self.encoder_dict_[col].transform(X[col]),\n",
    "                columns=self.encoder_dict_[col].classes_,\n",
    "                index=X.index)\n",
    "            cols_keep = list(col_encoded.sum().sort_values(ascending=False).head(3).index)\n",
    "\n",
    "            X = pd.concat([X, col_encoded[cols_keep]], axis=1).drop(columns=[col])\n",
    "\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f02a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ac12bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_encoder = MultiColumnsEncoder(feature_names=multi_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d97a296",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = multi_encoder.fit_transform(X_train[multi_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0ea1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1052aa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    The constructor extracts and returns the pandas dataset \n",
    "    with only those columns whose names were passed to it \n",
    "    as an argument during its initialization. \n",
    "    It contains two methods: fit and transform.\n",
    "    \"\"\"\n",
    "    \n",
    "    # class constructor \n",
    "    def __init__(self, feature_names):\n",
    "        self._feature_names = feature_names \n",
    "    \n",
    "    # return self nothing else to do here    \n",
    "    def fit(self, X, y = None):\n",
    "        return self \n",
    "    \n",
    "    # method that describes what we need this transformer to do\n",
    "    def transform(self, X, y = None):\n",
    "        return X[ self._feature_names ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4208421",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsel = FeatureSelector(multi_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef421d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsel.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12674fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f07857",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633f54bb",
   "metadata": {},
   "source": [
    "## Impute the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5c9262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the numerical columns in the train dataset\n",
    "X_train_num = X_train[num_cols]\n",
    "# create an instance of the KNN imputer\n",
    "num_imputer = KNNImputer(n_neighbors=5)\n",
    "# fit_transform the imputer on the training set\n",
    "X_train_num_imp = pd.DataFrame(num_imputer.fit_transform(X_train_num), \n",
    "                               columns=X_train_num.columns)\n",
    "# separate the numerical columns in the test set\n",
    "X_test_num = X_test[num_cols]\n",
    "# transform the test set with the imputer that was fit on the training set\n",
    "X_test_num_imp = pd.DataFrame(num_imputer.transform(X_test_num), columns=X_test_num.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d4fe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance of the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# scale the numerical variables, fit and transform on the straining set\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train_num_imp), \n",
    "                                columns=X_train_num_imp.columns)\n",
    "# use the scaler fit on training set to transform the test set\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test_num_imp), columns=X_test_num_imp.columns)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf8a1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate all the categorical columns in the training set\n",
    "X_train_cat = X_train[cat_cols]\n",
    "# create an instance of the imputer\n",
    "cat_imputer = SimpleImputer(strategy='constant', fill_value='missing')\n",
    "# fit and transform the training data\n",
    "X_train_cat_imp = pd.DataFrame(cat_imputer.fit_transform(X_train_cat), \n",
    "                               columns=X_train_cat.columns)\n",
    "# separate the categorical columns in the test set\n",
    "X_test_cat = X_test[cat_cols]\n",
    "# transform the test data with the imputer fit on the training set\n",
    "X_test_cat_imp=pd.DataFrame(cat_imputer.transform(X_test_cat), columns=X_test_cat.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831f5020",
   "metadata": {},
   "source": [
    "## Encode the predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cab43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the low cardinality columns\n",
    "def ord_encode_predictors(X_train, X_test):\n",
    "    oe = OrdinalEncoder()\n",
    "    oe.fit(X_train)\n",
    "    X_train_enc = pd.DataFrame(oe.transform(X_train))\n",
    "    X_test_enc = pd.DataFrame(oe.transform(X_test))\n",
    "    return X_train_enc, X_test_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9a17c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the low cardinality encoded features\n",
    "X_train_uni_enc, X_test_uni_enc = ord_encode_predictors(X_train_cat_imp[uni_cols],\n",
    "                                                        X_test_cat_imp[uni_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ae83e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the high cardinality columns\n",
    "def encode_predictors(X_train, X_test):\n",
    "    enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    enc.fit(X_train)\n",
    "    X_train_enc = pd.DataFrame(enc.transform(X_train))\n",
    "    X_test_enc = pd.DataFrame(enc.transform(X_test))\n",
    "    return X_train_enc, X_test_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cc7f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the high cardinality encoded features\n",
    "X_train_multi_enc, X_test_multi_enc = encode_predictors(X_train_cat_imp[multi_cols], \n",
    "                                                        X_test_cat_imp[multi_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820a594e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the target variable \n",
    "def encode_target(y_train, y_test):\n",
    "\tle = LabelEncoder()\n",
    "\tle.fit(y_train)\n",
    "\ty_train_enc = le.transform(y_train)\n",
    "\ty_test_enc = le.transform(y_test)\n",
    "\treturn y_train_enc, y_test_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf311d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the target variable - not necessary\n",
    "# y_train_enc, y_test_enc = encode_targets(y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c43b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the  X frames \n",
    "X_train_cat_enc = pd.concat([X_train_multi_enc, X_train_uni_enc], axis=1)\n",
    "X_train_prep = pd.concat([X_train_cat_enc, X_train_scaled], axis=1)\n",
    "\n",
    "X_test_cat_enc = pd.concat([X_test_multi_enc, X_test_uni_enc], axis=1)\n",
    "X_test_prep = pd.concat([X_test_cat_enc, X_test_scaled], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7c1d91",
   "metadata": {},
   "source": [
    "### Create a profiling report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9798aa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this once to generate a profiling report and save it as html file\n",
    "\n",
    "#import pandas_profiling\n",
    "#profile = pandas_profiling.ProfileReport(X_train, minimal=False)\n",
    "#profile.to_file(output_file=\"data_train_report.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c8e8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cd2b0d",
   "metadata": {},
   "source": [
    "## Refactor the code: build processing data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "3e05378c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## refactor code: processing data\n",
    "\n",
    "# the steps in the categorical pipeline for columns of low cardinality\n",
    "uni_cat_pipeline = Pipeline( steps = [( 'unicat_selector', FeatureSelector(uni_cols) ),\n",
    "                                  ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "                                  ( 'ordinal_encoder', OrdinalEncoder() ) ] )\n",
    "\n",
    "# the steps in the categorical pipeline for columns of high cardinality\n",
    "multi_cat_pipeline = Pipeline( steps = [( 'multicat_selector', FeatureSelector(multi_cols) ),\n",
    "                                  ( 'multi_encoder', MultiColumnsEncoder(multi_cols) ) ] )\n",
    "\n",
    "# the steps in the numerical pipeline     \n",
    "num_pipeline = Pipeline( steps = [ ('num_selector', FeatureSelector(num_cols) ),\n",
    "                                  ('imputer', KNNImputer(n_neighbors=5) ),\n",
    "                                  ( 'std_scaler', StandardScaler() ) ] )\n",
    "\n",
    "# combine the numerical and the categorical pipelines\n",
    "full_pipeline = FeatureUnion( transformer_list = [ ( 'unicat_pipeline', uni_cat_pipeline ), \n",
    "                                                  ( 'multicat_pipeline', multi_cat_pipeline ) ,\n",
    "                                                 ( 'numerical_pipeline', num_pipeline )] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0827cd0f",
   "metadata": {},
   "source": [
    "# Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "22e506a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the full pipeline as a step in another pipeline with an estimator as the final step\n",
    "full_pipeline_m = Pipeline( steps = [ ( 'full_pipeline', full_pipeline),\n",
    "                                  ( 'model', KNeighborsClassifier(n_neighbors=5) ) ] )\n",
    "\n",
    "# call fit on it just like any other pipeline\n",
    "full_pipeline_m.fit( X_train, y_train )\n",
    "\n",
    "# predict with it like any other pipeline\n",
    "y_pred = full_pipeline_m.predict( X_test ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "145513fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 51  35  14  87  71]\n",
      " [ 36 128  46 153 123]\n",
      " [ 24  79  65 105 110]\n",
      " [ 56 160  73 382 250]\n",
      " [ 72 169  82 292 449]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.21      0.20      0.21       258\n",
      "           2       0.22      0.26      0.24       486\n",
      "           3       0.23      0.17      0.20       383\n",
      "           4       0.37      0.41      0.39       921\n",
      "           5       0.45      0.42      0.43      1064\n",
      "\n",
      "    accuracy                           0.35      3112\n",
      "   macro avg       0.30      0.29      0.29      3112\n",
      "weighted avg       0.35      0.35      0.34      3112\n",
      "\n",
      "Accuracy: 0.345\n"
     ]
    }
   ],
   "source": [
    "# print evaluation metrics and results\n",
    "\n",
    "result1 = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(result1)\n",
    "\n",
    "result2 = classification_report(y_test, y_pred)\n",
    "print('\\nClassification Report:')\n",
    "print (result2)\n",
    "\n",
    "result3 = accuracy_score(y_test,y_pred)  \n",
    "print('Accuracy: %.3f' %result3)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5a3efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline_m.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65797bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance(model, X, ground_y):\n",
    "    \"\"\"Calculate some importance metrics for model evaluation: roc_auc_ovr, accuracy, precision_macro, recall_macro,\n",
    "    confusion matrix\"\"\"\n",
    "    ground_y = np.squeeze(ground_y)\n",
    "\n",
    "    predict_y = model.predict(X)\n",
    "    predict_y_proba = model.predict_proba(X)\n",
    "\n",
    "    roc_auc_score_perf = roc_auc_score(ground_y, predict_y_proba, average='macro', multi_class='ovr')  # ROC-AUC\n",
    "    #logLoss_perf = log_loss(ground_y, predict_y_proba)\n",
    "\n",
    "    accuracy_perf = (predict_y == ground_y).sum() / len(predict_y)\n",
    "    precision_score_perf = precision_score(ground_y, predict_y, average='macro')\n",
    "    recall_score_perf = recall_score(ground_y, predict_y, average='macro')\n",
    "\n",
    "    # Confusion matrix:\n",
    "    # print(\"Confusion matrix [[TN, FP]\\n[FN, TP]]:\\n\", confusion_matrix(ground_y, predict_y))\n",
    "    conf_m = confusion_matrix(ground_y, predict_y)\n",
    "\n",
    "    return roc_auc_score_perf, accuracy_perf, precision_score_perf, recall_score_perf, conf_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccc314e",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score_perf_train, \\\n",
    "accuracy_perf_train, precision_score_perf_train, recall_score_perf_train, \\\n",
    "conf_m_train = get_performance(full_pipeline_m, X_train, y_train)\n",
    "\n",
    "train_performance = pd.Series([roc_auc_score_perf_trai, \\\n",
    "                               accuracy_perf_train, \n",
    "                               precision_score_perf_train, recall_score_perf_train], \n",
    "                              index=['roc-auc_macro', 'accuracy',\n",
    "                                     'precison_macro', 'recall_macro'])\n",
    "\n",
    "\n",
    "roc_auc_score_perf_test, \\\n",
    "accuracy_perf_test, precision_score_perf_test, recall_score_perf_test, \\\n",
    "conf_m_test = get_performance(full_pipeline_m, X_test, y_test)\n",
    "\n",
    "test_performance = pd.Series([roc_auc_score_perf_test, \\\n",
    "                               accuracy_perf_test, \n",
    "                               precision_score_perf_test, recall_score_perf_test], index=['roc-auc_macro', 'accuracy', 'precison_macro', 'recall_macro'])\n",
    "\n",
    "\n",
    "\n",
    "performance_check = pd.DataFrame.from_dict({'train': train_performance, 'test': test_performance})\n",
    "performance_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2a55c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "67ab4fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the full pipeline as a step in another pipeline with an estimator as the final step\n",
    "full_pipeline_xgb = Pipeline( steps = [ ( 'full_pipeline', full_pipeline),\n",
    "                                  ( 'model', xgb.XGBClassifier(objective = 'multi:softmax' )) ] )\n",
    "\n",
    "# call fit on it just like any other pipeline\n",
    "full_pipeline_xgb.fit( X_train, y_train )\n",
    "\n",
    "# predict with it like any other pipeline\n",
    "y_pred = full_pipeline_xgb.predict( X_test ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "32a77542",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 16  12   2  90 138]\n",
      " [  2  34   4 272 174]\n",
      " [  2  12  11 198 160]\n",
      " [  2  14   4 442 459]\n",
      " [  1   7   5 260 791]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.06      0.11       258\n",
      "           2       0.43      0.07      0.12       486\n",
      "           3       0.42      0.03      0.05       383\n",
      "           4       0.35      0.48      0.40       921\n",
      "           5       0.46      0.74      0.57      1064\n",
      "\n",
      "    accuracy                           0.42      3112\n",
      "   macro avg       0.47      0.28      0.25      3112\n",
      "weighted avg       0.44      0.42      0.35      3112\n",
      "\n",
      "Accuracy: 0.416\n"
     ]
    }
   ],
   "source": [
    "# print evaluation metrics and results\n",
    "\n",
    "result1 = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(result1)\n",
    "\n",
    "result2 = classification_report(y_test, y_pred)\n",
    "print('\\nClassification Report:')\n",
    "print (result2)\n",
    "\n",
    "result3 = accuracy_score(y_test,y_pred)  \n",
    "print('Accuracy: %.3f' %result3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "6bf87614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance(model, X, ground_y):\n",
    "    \"\"\"Calculate some importance metrics for model evaluation: roc_auc_ovr, accuracy, precision_macro, recall_macro,\n",
    "    confusion matrix\"\"\"\n",
    "    ground_y = np.squeeze(ground_y)\n",
    "\n",
    "    predict_y = model.predict(X)\n",
    "    predict_y_proba = model.predict_proba(X)\n",
    "\n",
    "    roc_auc_score_perf = roc_auc_score(ground_y, predict_y_proba, average='macro', multi_class='ovr')  # ROC-AUC\n",
    "    #logLoss_perf = log_loss(ground_y, predict_y_proba)\n",
    "\n",
    "    accuracy_perf = (predict_y == ground_y).sum() / len(predict_y)\n",
    "    precision_score_perf = precision_score(ground_y, predict_y, average='macro')\n",
    "    recall_score_perf = recall_score(ground_y, predict_y, average='macro')\n",
    "\n",
    "    # Confusion matrix:\n",
    "    # print(\"Confusion matrix [[TN, FP]\\n[FN, TP]]:\\n\", confusion_matrix(ground_y, predict_y))\n",
    "    conf_m = confusion_matrix(ground_y, predict_y)\n",
    "\n",
    "    return roc_auc_score_perf, accuracy_perf, precision_score_perf, recall_score_perf, conf_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "439fde43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "roc-auc_macro     1.000000\n",
       "accuracy          0.999862\n",
       "precison_macro    0.999907\n",
       "recall_macro      0.999921\n",
       "dtype: float64"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score_perf_train,\\\n",
    "accuracy_perf_train, precision_score_perf_train, recall_score_perf_train, \\\n",
    "conf_m_train = get_performance(full_pipeline_rf, X_train, y_train)\n",
    "\n",
    "train_performance = pd.Series([roc_auc_score_perf_train, \\\n",
    "                               accuracy_perf_train, \n",
    "                               precision_score_perf_train, recall_score_perf_train], index=['roc-auc_macro', 'accuracy', 'precison_macro', 'recall_macro'])\n",
    "\n",
    "train_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "0b74b776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "roc-auc_macro     0.817235\n",
       "accuracy          0.587404\n",
       "precison_macro    0.717367\n",
       "recall_macro      0.508818\n",
       "dtype: float64"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score_perf_test,\\\n",
    "accuracy_perf_test, precision_score_perf_test, recall_score_perf_test, \\\n",
    "conf_m_test = get_performance(full_pipeline_rf, X_test, y_test)\n",
    "\n",
    "test_performance = pd.Series([roc_auc_score_perf_test, \\\n",
    "                               accuracy_perf_test, \n",
    "                               precision_score_perf_test, recall_score_perf_test], index=['roc-auc_macro', 'accuracy', 'precison_macro', 'recall_macro'])\n",
    "\n",
    "test_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "31cd1838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the full pipeline as a step in another pipeline with an estimator as the final step\n",
    "full_pipeline_rf = Pipeline( steps = [ ( 'full_pipeline', full_pipeline),\n",
    "                                  ( 'model', RandomForestClassifier(n_estimators=200, max_depth=None) ) ] )\n",
    "\n",
    "# call fit on it just like any other pipeline\n",
    "full_pipeline_rf.fit( X_train, y_train )\n",
    "\n",
    "# predict with it like any other pipeline\n",
    "y_pred_rf = full_pipeline_rf.predict( X_test ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "b7561e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_p = full_pipeline_m.predict( X_train ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "b3869701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 99  11   2  56  90]\n",
      " [  0 189   6 174 117]\n",
      " [  1  20 144 120  98]\n",
      " [  3  34   8 572 304]\n",
      " [  1  23   5 211 824]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.95      0.38      0.55       258\n",
      "           2       0.68      0.39      0.50       486\n",
      "           3       0.87      0.38      0.53       383\n",
      "           4       0.50      0.62      0.56       921\n",
      "           5       0.58      0.77      0.66      1064\n",
      "\n",
      "    accuracy                           0.59      3112\n",
      "   macro avg       0.72      0.51      0.56      3112\n",
      "weighted avg       0.64      0.59      0.58      3112\n",
      "\n",
      "Accuracy: 0.587\n"
     ]
    }
   ],
   "source": [
    "# print evaluation metrics and results\n",
    "\n",
    "result1 = confusion_matrix(y_test, y_pred_rf)\n",
    "print('Confusion Matrix:')\n",
    "print(result1)\n",
    "\n",
    "result2 = classification_report(y_test, y_pred_rf)\n",
    "print('\\nClassification Report:')\n",
    "print (result2)\n",
    "\n",
    "result3 = accuracy_score(y_test,y_pred_rf)  \n",
    "print('Accuracy: %.3f' %result3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "e339e22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 99  11   5  57  86]\n",
      " [  1 190   4 176 115]\n",
      " [  2  20 143 121  97]\n",
      " [  2  37   5 565 312]\n",
      " [  1  24   4 213 822]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.94      0.38      0.55       258\n",
      "           2       0.67      0.39      0.49       486\n",
      "           3       0.89      0.37      0.53       383\n",
      "           4       0.50      0.61      0.55       921\n",
      "           5       0.57      0.77      0.66      1064\n",
      "\n",
      "    accuracy                           0.58      3112\n",
      "   macro avg       0.72      0.51      0.56      3112\n",
      "weighted avg       0.64      0.58      0.58      3112\n",
      "\n",
      "Accuracy: 0.585\n"
     ]
    }
   ],
   "source": [
    "# print evaluation metrics and results\n",
    "\n",
    "result1 = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(result1)\n",
    "\n",
    "result2 = classification_report(y_test, y_pred)\n",
    "print('\\nClassification Report:')\n",
    "print (result2)\n",
    "\n",
    "result3 = accuracy_score(y_test,y_pred)  \n",
    "print('Accuracy: %.3f' %result3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "2225a6d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_prep' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-409-fdc1e03eaf15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mkfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_prep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_prep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#result2 = classification_report(y_test, y_pred, zero_division=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_prep' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "for model in [DecisionTreeClassifier, KNeighborsClassifier, GaussianNB, SVC, \n",
    "              RandomForestClassifier, SGDClassifier]:\n",
    "    make_pipeline(model())\n",
    "    classifier = model()\n",
    "    kfold = model_selection.KFold(n_splits=5)\n",
    "    classifier.fit(X_train_prep, y_train)\n",
    "    s = model_selection.cross_val_score(classifier, X_test_prep,y_test, cv=kfold)\n",
    "    #result2 = classification_report(y_test, y_pred, zero_division=0)\n",
    "    #s = model_selection.cross_val_score(cls, X, y, cv=kfold)\n",
    "    print(f\"{model.__name__:22}  CV_Mean:\" f\"{s.mean():.3f} CV_STD: {s.std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a553596",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgb = RandomForestClassifier()\n",
    "param_dist = {'n_estimators': stats.randint(150, 1000),\n",
    "              'learning_rate': stats.uniform(0.01, 0.59),\n",
    "              'subsample': stats.uniform(0.3, 0.6),\n",
    "              'max_depth': [3, 4, 5, 6, 7, 8, 9],\n",
    "              'colsample_bytree': stats.uniform(0.5, 0.4),\n",
    "              'min_child_weight': [1, 2, 3, 4]\n",
    "             }\n",
    "\n",
    "numFolds = 5\n",
    "n = X_train_prep.shape[0]\n",
    "kfold_5 = KFold(n, True, 5)\n",
    "\n",
    "clf = RandomizedSearchCV(clf_xgb, \n",
    "                         param_distributions = param_dist,\n",
    "                         cv = kfold_5,  \n",
    "                         n_iter = 5, # you want 5 here not 25 if I understand you correctly \n",
    "                         scoring = 'roc_auc', \n",
    "                         error_score = 0, \n",
    "                         verbose = 3, \n",
    "                         n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4b9649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_tune(base_model, parameters, n_iter, kfold, X=X_train, y=y_train):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Arrange data into folds with approx equal proportion of classes within each fold\n",
    "    k = StratifiedKFold(n_splits=kfold, shuffle=False)\n",
    "    \n",
    "    optimal_model = RandomizedSearchCV(base_model,\n",
    "                            param_distributions=parameters,\n",
    "                            n_iter=n_iter,\n",
    "                            cv=k,\n",
    "                            n_jobs=-1,\n",
    "                            random_state=42)\n",
    "    optimal_model.fit(X, y)\n",
    "    \n",
    "    stop_time = time.time()\n",
    "\n",
    "    scores = cross_val_score(optimal_model, X, y, cv=k, scoring=\"accuracy\")\n",
    "    \n",
    "    print(\"Elapsed Time:\", time.strftime(\"%H:%M:%S\", time.gmtime(stop_time - start_time)))\n",
    "    print(\"====================\")\n",
    "    print(\"Cross Val Mean: {:.3f}, Cross Val Stdev: {:.3f}\".format(scores.mean(), scores.std()))\n",
    "    print(\"Best Score: {:.3f}\".format(optimal_model.best_score_))\n",
    "    print(\"Best Parameters: {}\".format(optimal_model.best_params_))\n",
    "    \n",
    "    return optimal_model.best_params_, optimal_model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0beff1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import randint\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", category=PendingDeprecationWarning)\n",
    "warnings.simplefilter(\"ignore\", category=DeprecationWarning)\n",
    "warnings.simplefilter(\"ignore\", category=FutureWarning)\n",
    "warnings.simplefilter(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78765369",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = RandomForestClassifier(n_jobs=-1,\n",
    "                                   random_state=42)\n",
    "\n",
    "lots_of_parameters = {\n",
    "    \"max_depth\": [3, 5, 10, None],\n",
    "    \"n_estimators\": [100, 200, 300, 400, 500],\n",
    "    \"max_features\": randint(1, 3),\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"bootstrap\": [True, False],\n",
    "    \"min_samples_leaf\": randint(1, 4)\n",
    "}\n",
    "\n",
    "parameters = {\n",
    "    \"max_depth\": [3, 5, 10, None],\n",
    "    \"n_estimators\": [100, 200, 300, 400, 500]\n",
    "}\n",
    "\n",
    "best_params, best_score = hyperparameter_tune(base_model, parameters, 10, 5, X_train_prep, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f91af56",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=200)\n",
    "rf.fit(X_train_prep, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8eb612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "explainer = shap.TreeExplainer(rf)\n",
    "shap_values = explainer.shap_values(X_test_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05163898",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_test_prep, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475139ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f_type = df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d038a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f_type = df_f_type.loc[~df_f_type.index.isin(['JobSat'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cf2f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_if_num = df_f_type.apply(lambda x: np.issubdtype(x, np.number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c41869",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_if_num.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0396fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_cat = cols_if_num[~cols_if_num].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2df68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_cat in cols_cat:\n",
    "        df_sample[col_cat] = df_sample[col_cat].fillna('missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ffe077",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_num = cols_if_num[cols_if_num].index.tolist()\n",
    "cols_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687e2374",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_num in cols_num:\n",
    "        df_sample[col_num] = df_sample[col_num].fillna(df[col_num].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17de2b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample[cols_num].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5e7dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OrdinalEncoder()\n",
    "df_sample[cols_cat] = enc.fit_transform(df_sample[cols_cat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9ccb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OrdinalEncoder()\n",
    "df_sample.loc[:, 'JobSat'] = enc.fit_transform(df_sample[['JobSat']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6379101c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample['JobSat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8689463",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "172.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
