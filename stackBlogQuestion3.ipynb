{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7993e6b6",
   "metadata": {},
   "source": [
    "# Analysis of StackOverflow Survey. Part IV \n",
    "\n",
    "In this notebook we build a predictiv model for job satisfaction. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc49bb0",
   "metadata": {},
   "source": [
    "## State the question\n",
    "I am addressing the third question in this notebook. What can we tell about the job satisfaction of a data coder? What factors do influence it? Also, predict the job satisfaction for a developer who works with big data. \n",
    "\n",
    "This is a classification question, we are predicting a satisfaction level for a data developer, which includes: data scientist or machine learning specialist, data or business analyst and data engineer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcfad12",
   "metadata": {},
   "source": [
    "## Performance metrics - to review at the end\n",
    "\n",
    "The following performance measures will be used in this project:\n",
    "1. Cross validation via StratifiedKFold with 10 folds.\n",
    "2. Confusion matrix, in particular precision, recall and F1 score.\n",
    "3. The ROC curve and the related AUC score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452d2a27",
   "metadata": {},
   "source": [
    "## Gather and prepare the data\n",
    "\n",
    "Upload the data and keep the subset that contains those developers that work in data science related fields. \n",
    "\n",
    "Manually inspect (using the profiling html file, for example) the remaining columns and drop the following columns: \n",
    " - DevClass, Country both introduce noise in the model,\n",
    " - JobFactors, Stuck, PlatformWorkedWith they consist of numerous string combinations, as a result of multiple options and choices, the columns have high cardinality and many missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9ad29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a path string\n",
    "mypath = os.getcwd()\n",
    "\n",
    "# upload the datafiles as pandas dataframes\n",
    "df1 = pd.read_csv(mypath+'/data/survey20_updated.csv', index_col=[0])\n",
    "\n",
    "# check the uploaded data\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8354b521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data frame that contains the data developers only\n",
    "df1 = df1[df1.DevClass == 'data_coder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af85dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the columns mentioned above\n",
    "df1.drop(columns=['DevClass', 'Country', 'JobFactors', 'Stuck', 'PlatformWorkedWith'], inplace=True)\n",
    "\n",
    "# check for success\n",
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00aebee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of columns to be used in this analysis\n",
    "#list_cols = ['MainBranch', 'ConvertedComp', 'EdLevel', 'Employment', 'JobSat', 'EdImpt',\n",
    "       #'Learn', 'Overtime', 'OpSys', 'OrgSize','UndergradMajor', 'WorkWeekHrs']\n",
    "\n",
    "    # the dataset that contains only the listed columns\n",
    "#df1 = df1[list_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccdce8e",
   "metadata": {},
   "source": [
    "## Data profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a33e150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this once to generate a profiling report and save it as html file\n",
    "\n",
    "#import pandas_profiling\n",
    "#profile = pandas_profiling.ProfileReport(df, minimal=False)\n",
    "#profile.to_file(output_file=\"data_coders_report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6c4287",
   "metadata": {},
   "source": [
    "## Data preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e8cb62",
   "metadata": {},
   "source": [
    "### Drop rows based on the Employment column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd26a1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check possible Employment choices\n",
    "employment = df1.Employment.value_counts().index.to_list()\n",
    "employment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f83350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retain only the employed data davelopers\n",
    "df1 = df1[df1['Employment'] != 'Not employed, but looking for work']\n",
    "\n",
    "# check for success\n",
    "df1.Employment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badc8282",
   "metadata": {},
   "source": [
    "### Create bins for the WorkWeekHrs column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38e9f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the labels\n",
    "cut_labels = ['less-10', '10-20', '20-30', '30-40', '40-50', 'more-50']\n",
    "\n",
    "# define the bins \n",
    "m = df1.WorkWeekHrs.max()\n",
    "cut_bins = [0, 10, 20, 30, 40, 50, m]\n",
    "\n",
    "# create a new column which contains the new labels\n",
    "df1['WorkWeek_Bins'] = pd.cut(df1['WorkWeekHrs'], bins=cut_bins, labels=cut_labels)\n",
    "\n",
    "# check for success\n",
    "df1['WorkWeek_Bins'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfe3260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the type of the newly created column\n",
    "df1['WorkWeek_Bins'] = df1['WorkWeek_Bins'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622851d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the WorkWeekHrs column\n",
    "df1.drop(columns = 'WorkWeekHrs', inplace=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7360c337",
   "metadata": {},
   "source": [
    "### Create bins for the ConvertedComp column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06f88ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we could use quantile, however I prefer custom bins here\n",
    "cut_labels = ['less-10K', '10K-30K', '30K-50K', '50K-100K', '100K-200K', 'more-200K']\n",
    "\n",
    "# define the bins \n",
    "m = df1.ConvertedComp.max()\n",
    "cut_bins = [0, 10000, 30000, 50000, 100000, 200000, m]\n",
    "\n",
    "# create a new column which contains the new labels\n",
    "df1['Comp_Bins'] = pd.cut(df1['ConvertedComp'], bins=cut_bins, labels=cut_labels)\n",
    "\n",
    "# change the type of the newly created column\n",
    "df1['Comp_Bins'] = df1['Comp_Bins'].astype('object')\n",
    "\n",
    "# drop the WorkWeekHrs column\n",
    "df1.drop(columns = 'ConvertedComp', inplace=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f30ade",
   "metadata": {},
   "source": [
    "### Create bins for the Age column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6297d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the bin edges\n",
    "cut_labels = ['<20', '20-30', '30-40', '40-50', '50-60', '60-70', '70-80', '>80']\n",
    "\n",
    "# define the bins \n",
    "m = df1.Age.max()\n",
    "cut_bins = [0, 20, 30, 40, 50, 60, 70, 80, m]\n",
    "\n",
    "# create a new column which contains the new labels\n",
    "df1['Age_Bins'] = pd.cut(df1['Age'], bins=cut_bins, labels=cut_labels)\n",
    "\n",
    "# change the type of the newly created column\n",
    "df1['Age_Bins'] = df1['Age_Bins'].astype('object')\n",
    "\n",
    "# drop the WorkWeekHrs column\n",
    "df1.drop(columns = 'Age', inplace=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff817994",
   "metadata": {},
   "source": [
    "### Remove the rows that contain mostly missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e323f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only the rows with at least 10 non-NA values\n",
    "df1.dropna(thresh=10)\n",
    "\n",
    "# check the result\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6243357a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.JobSat.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6c1915",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dropna( how='any', subset=['JobSat'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9685410",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.JobSat.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad0c14a",
   "metadata": {},
   "source": [
    "### Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c883ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicate rows, if any\n",
    "df1.drop_duplicates(subset=None, keep='first', inplace=True)\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7b99f9",
   "metadata": {},
   "source": [
    "## Create features and target\n",
    "\n",
    "Create a dataframe (X) with the features and a pandas series (y) that contains the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b40b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy of the pre-processed dataframe\n",
    "df2 = df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf816df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the predictors dataframe\n",
    "X = df2.drop(columns = 'JobSat')\n",
    "\n",
    "# create the labels\n",
    "y = df2['JobSat']\n",
    "\n",
    "# check for success\n",
    "X.info(), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c049e8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# format all the fields as strings in the feature matrix\n",
    "X = X.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a45ce76",
   "metadata": {},
   "source": [
    "## Sample data\n",
    "\n",
    "We will use $30 \\%$ data for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0d97b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data in train and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# summarize the data\n",
    "print('Train', X_train.shape, y_train.shape)\n",
    "print('Test', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a115bc",
   "metadata": {},
   "source": [
    "## Impute missing values\n",
    "\n",
    "Now that we have test and train data, we can impute missing values on the training set, and use the trained imputer to fill in the test dataset. I will use the KNN imputer from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4945f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance of the imputer\n",
    "#imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "# fit the imputer on the dataset\n",
    "#X_train_trans = pd.DataFrame(imputer.fit_transform(X_train), columns = X_train.columns)\n",
    "\n",
    "# check for success\n",
    "#X_train_trans.isna().any()\n",
    "from sklearn.impute import SimpleImputer\n",
    "def impute_predictors(X_train, X_test):\n",
    "    imputer = SimpleImputer(strategy='constant', fill_value='missing')\n",
    "    imputer.fit(X_train)\n",
    "    X_train_trans = pd.DataFrame(imputer.transform(X_train), columns=X_train.columns)\n",
    "    X_test_trans = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)\n",
    "    return X_train_trans, X_test_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483501ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_trans, X_test_trans = impute_predictors(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4962e5b1",
   "metadata": {},
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, [0])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c2de48",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_trans.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa411ff",
   "metadata": {},
   "source": [
    "## Encode the data\n",
    "\n",
    "The best practice when encoding variables is to fit the encoding on the training dataset, then apply it to the train and test datasets.\n",
    "\n",
    "The function below named prepare_inputs() takes the input data for the train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16463bad",
   "metadata": {},
   "outputs": [],
   "source": [
    " # prepare input data\n",
    "def encode_predictors(X_train, X_test):\n",
    "\tenc = OneHotEncoder(handle_unknown='ignore')\n",
    "\tenc.fit(X_train)\n",
    "\tX_train_enc = enc.transform(X_train)\n",
    "\tX_test_enc = enc.transform(X_test)\n",
    "\treturn X_train_enc, X_test_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96179add",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_enc, X_test_enc = encode_predictors(X_train_trans, X_test_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d614018",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19108de7",
   "metadata": {},
   "source": [
    "Regarding the output data, the target, since it is already encoded as an integer with values from 0 to 5, no other encoding steps are needed at this point.\n",
    "\n",
    "Alternative would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c6ae2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare target\n",
    "#def encode_targets(y_train, y_test):\n",
    "\t#le = LabelEncoder()\n",
    "\t#le.fit(y_train)\n",
    "\t#y_train_enc = le.transform(y_train)\n",
    "\t#y_test_enc = le.transform(y_test)\n",
    "\t#return y_train_enc, y_test_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfbb331",
   "metadata": {},
   "source": [
    "### Perform feature selection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0224ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection\n",
    "def select_features(X_train, y_train, X_test):\n",
    "\tfs = SelectKBest(score_func=mutual_info_classif, k=20)\n",
    "\tfs.fit(X_train, y_train)\n",
    "\tX_train_fs = fs.transform(X_train)\n",
    "\tX_test_fs = fs.transform(X_test)\n",
    "\treturn X_train_fs, X_test_fs, fs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96000d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fs, X_test_fs, fs = select_features(X_train_enc, y_train, X_test_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870cb0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are scores for the features\n",
    "#for i in range(len(fs.scores_)):\n",
    "\t#print('Feature %d: %f' % (i, fs.scores_[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64aab928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the scores\n",
    "plt.bar([i for i in range(len(fs.scores_))], fs.scores_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8821360f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi = pd.Series(fs.scores_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97eb6d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0bd6ebe",
   "metadata": {},
   "source": [
    "## Refactor code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17aef62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c06092e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a path string\n",
    "mypath = os.getcwd()\n",
    "\n",
    "# read the data from the file\n",
    "df = pd.read_csv(mypath+'/data/survey20_updated.csv')\n",
    "# preprocess, split and process data\n",
    "preproc_df = uf.preprocess_data(df)\n",
    "X_train, y_train, X_test, y_test = uf.process_data(preproc_df, 'JobSat')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d47cc4",
   "metadata": {},
   "source": [
    "## Baseline model: K NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9934c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance of the classifier\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# fit the classifier\n",
    "knn_clf.fit(X_train_fs, y_train)\n",
    "\n",
    "# predict output values\n",
    "y_pred = knn_clf.predict(X_test_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c3bf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print evaluation metrics and results\n",
    "\n",
    "result1 = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(result1)\n",
    "\n",
    "result2 = classification_report(y_test, y_pred)\n",
    "print('\\nClassification Report:')\n",
    "print (result2)\n",
    "\n",
    "result3 = accuracy_score(y_test,y_pred)  \n",
    "print('Accuracy: %.3f' %result3)\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8cd09a",
   "metadata": {},
   "source": [
    "## Several other algorithms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f664a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# create classifier instance\n",
    "svm_clf = SVC(gamma=\"auto\", random_state=42)\n",
    "# fit the model\n",
    "svm_clf.fit(X_train_fs, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0f5392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on the test set\n",
    "y_pred = svm_clf.predict(X_test_fs)\n",
    "\n",
    "# test one value\n",
    "y_test.iloc[20],  y_pred[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae437bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_digit_scores = svm_clf.decision_function(X_test_fs)\n",
    "some_digit_scores[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd7f7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(some_digit_scores[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acae03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376bba3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173c0f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(svm_clf, X_test_fs, y_test, cv=10, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0d8b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print evaluation metrics and results\n",
    "\n",
    "result1 = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(result1)\n",
    "\n",
    "result2 = classification_report(y_test, y_pred, zero_division=0)\n",
    "print('\\nClassification Report:')\n",
    "print (result2)\n",
    "\n",
    "result3 = accuracy_score(y_test,y_pred)  \n",
    "print('Accuracy: %.3f' %result3)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b45d132",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "ovr_clf = OneVsRestClassifier(SVC(gamma=\"auto\", random_state=42))\n",
    "ovr_clf.fit(X_train_fs, y_train)\n",
    "y_pred = ovr_clf.predict(X_test_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac945a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(result1)\n",
    "\n",
    "result2 = classification_report(y_test, y_pred, zero_division=0)\n",
    "print('\\nClassification Report:')\n",
    "print (result2)\n",
    "\n",
    "result3 = accuracy_score(y_test,y_pred)  \n",
    "print('Accuracy: %.3f' %result3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f0b71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Always scale the input. The most convenient way is to use a pipeline.\n",
    "sgd_clf = make_pipeline(StandardScaler(with_mean=False),SGDClassifier(max_iter=1000, tol=1e-3))\n",
    "sgd_clf.fit(X_train_fs, y_train)\n",
    "y_pred = sgd_clf.predict(X_test_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3033a0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(result1)\n",
    "\n",
    "result2 = classification_report(y_test, y_pred, zero_division=0)\n",
    "print('\\nClassification Report:')\n",
    "print (result2)\n",
    "\n",
    "result3 = accuracy_score(y_test,y_pred)  \n",
    "print('Accuracy: %.3f' %result3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed95eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X_train_fs, X_test_fs])\n",
    "y = pd.concat([y_train, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23bdba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import (LogisticRegression)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import (KNeighborsClassifier)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import (RandomForestClassifier)\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d44922",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [DecisionTreeClassifier, KNeighborsClassifier, GaussianNB, SVC, \n",
    "              RandomForestClassifier, SGDClassifier]:\n",
    "    make_pipeline(StandardScaler(),model())\n",
    "    classifier = model()\n",
    "    kfold = model_selection.KFold(n_splits=10)\n",
    "    classifier.fit(X_train_fs.toarray(), y_train)\n",
    "    s = model_selection.cross_val_score(classifier, X_test_fs.toarray(),y_test, cv=kfold)\n",
    "    #result2 = classification_report(y_test, y_pred, zero_division=0)\n",
    "    #s = model_selection.cross_val_score(cls, X, y, cv=kfold)\n",
    "    print(f\"{model.__name__:22}  CV_Mean:\" f\"{s.mean():.3f} CV_STD: {s.std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91249c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(objective=\"multi:softprob\", random_state=42)\n",
    "xgb_model.fit(X_train_fs, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e1ab8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb_model.predict(X_test_fs)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ba9767",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6423fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer, load_diabetes, load_wine\n",
    "from sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold, RandomizedSearchCV, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633392f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(objective=\"multi:softprob\", random_state=42)\n",
    "\n",
    "params = {\n",
    "    \"colsample_bytree\": uniform(0.7, 0.3),\n",
    "    \"gamma\": uniform(0, 0.5),\n",
    "    \"learning_rate\": uniform(0.03, 0.3), # default 0.1 \n",
    "    \"max_depth\": randint(2, 6), # default 3\n",
    "    \"n_estimators\": randint(100, 150), # default 100\n",
    "    \"subsample\": uniform(0.6, 0.4)\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(xgb_model, param_distributions=params, random_state=42, \n",
    "                            n_iter=200, cv=3, verbose=1, n_jobs=1, return_train_score=True)\n",
    "\n",
    "search.fit(X_train_fs, y_train)\n",
    "\n",
    "#report_best_scores(search.cv_results_, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e065f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "search.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5400b90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60865dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from stack\n",
    "clf_xgb = xgb.XGBClassifier(objective = 'binary:logistic')\n",
    "param_dist = {'n_estimators': stats.randint(150, 1000),\n",
    "              'learning_rate': stats.uniform(0.01, 0.59),\n",
    "              'subsample': stats.uniform(0.3, 0.6),\n",
    "              'max_depth': [3, 4, 5, 6, 7, 8, 9],\n",
    "              'colsample_bytree': stats.uniform(0.5, 0.4),\n",
    "              'min_child_weight': [1, 2, 3, 4]\n",
    "             }\n",
    "\n",
    "numFolds = 5\n",
    "kfold_5 = cross_validation.KFold(n = len(X), shuffle = True, n_folds = numFolds)\n",
    "\n",
    "clf = RandomizedSearchCV(clf_xgb, \n",
    "                         param_distributions = param_dist,\n",
    "                         cv = kfold_5,  \n",
    "                         n_iter = 5, # you want 5 here not 25 if I understand you correctly \n",
    "                         scoring = 'roc_auc', \n",
    "                         error_score = 0, \n",
    "                         verbose = 3, \n",
    "                         n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbdc5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "scores = []\n",
    "\n",
    "for train_index, test_index in kfold.split(X_train_fs):   \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    xgb_model = xgb.XGBClassifier(objective=\"multi:softprob\", random_state=42)\n",
    "    xgb_model.fit(X_train_fs, y_train)\n",
    "    \n",
    "    y_pred = xgb_model.predict(X_test_fs)\n",
    "    \n",
    "    scores.append(mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "display_scores(np.sqrt(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9856f647",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = RandomForestClassifier()\n",
    "kfold = model_selection.KFold(n_splits=10)\n",
    "s = model_selection.cross_val_score(cls, X,y, cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575e4e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_rf = RandomForestClassifier()\n",
    "kfold = model_selection.KFold(n_splits=10)\n",
    "cls_rf.fit(X_train, y_train)\n",
    "y_pred = cls_rf.predict(X_test)\n",
    "s = model_selection.cross_val_score(cls_rf, X_test,y_test, cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07becbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056881af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(mypath+'/data/survey20_updated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8fd5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900b0112",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[df1['JobSat'] !=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76c9a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6435fa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.JobSat.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b842412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data from the file\n",
    "#df = pd.read_csv(mypath+'/data/survey20_updated.csv')\n",
    "# preprocess, split and process data\n",
    "preproc_df1 = uf.preprocess_data(df1)\n",
    "X1_train, y1_train, X1_test, y1_test = uf.process_data(preproc_df1, 'JobSat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4736c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Always scale the input. The most convenient way is to use a pipeline.\n",
    "sgd_clf = make_pipeline(StandardScaler(),SGDClassifier(max_iter=1000, tol=1e-3))\n",
    "sgd_clf.fit(X1_train, y1_train)\n",
    "y1_pred = sgd_clf.predict(X1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ab63bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = confusion_matrix(y1_test, y1_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(result1)\n",
    "\n",
    "result2 = classification_report(y1_test, y1_pred, zero_division=0)\n",
    "print('\\nClassification Report:')\n",
    "print (result2)\n",
    "\n",
    "result3 = accuracy_score(y1_test,y1_pred)  \n",
    "print('Accuracy: %.3f' %result3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93da4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a path string\n",
    "mypath = os.getcwd()\n",
    "\n",
    "df2 = pd.read_csv(mypath+'/data/survey20_updated.csv')\n",
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482491d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess, split and process data\n",
    "#preproc_df2 = uf.preprocess_data(df2)\n",
    "X2_train, y2_train, X2_test, y2_test = uf.process_data(preproc_df2, 'JobSat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18f87c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = pd.concat([X2_train, X2_test])\n",
    "y2 = pd.concat([y2_train, y2_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30eb1928",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c864feb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [DecisionTreeClassifier, KNeighborsClassifier, GaussianNB, SVC, \n",
    "              RandomForestClassifier, SGDClassifier]:\n",
    "    make_pipeline(StandardScaler(),model())\n",
    "    classifier = model()\n",
    "    kfold = model_selection.KFold(n_splits=10)\n",
    "    classifier.fit(X2, y2)\n",
    "    s = model_selection.cross_val_score(classifier, X2,y2, cv=kfold)\n",
    "    #result2 = classification_report(y_test, y_pred, zero_division=0)\n",
    "    #s = model_selection.cross_val_score(cls, X, y, cv=kfold)\n",
    "    print(f\"{model.__name__:22}  CV_Mean:\" f\"{s.mean():.3f} CV_STD: {s.std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec7cd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Always scale the input. The most convenient way is to use a pipeline.\n",
    "sgd_clf = make_pipeline(StandardScaler(),SGDClassifier(max_iter=1000, tol=1e-3))\n",
    "sgd_clf.fit(X2_train, y2_train)\n",
    "y2_pred = sgd_clf.predict(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c07d63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = confusion_matrix(y2_test, y2_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(result1)\n",
    "\n",
    "result2 = classification_report(y2_test, y2_pred, zero_division=0)\n",
    "print('\\nClassification Report:')\n",
    "print (result2)\n",
    "\n",
    "result3 = accuracy_score(y2_test,y2_pred)  \n",
    "print('Accuracy: %.3f' %result3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805a3165",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
