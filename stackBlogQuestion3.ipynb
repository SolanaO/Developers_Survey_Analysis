{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7993e6b6",
   "metadata": {},
   "source": [
    "# Analysis of StackOverflow Survey. Part IV \n",
    "\n",
    "In this notebook we build a predictiv model for job satisfaction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "837206f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import neccessary packages and libraries\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# to render plots in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "# set a theme for seaborn\n",
    "sns.set_theme()\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn import (\n",
    "    ensemble,\n",
    "    preprocessing,\n",
    "    tree,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    StratifiedKFold,\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    r2_score, \n",
    "    mean_squared_error,\n",
    "    auc,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed1cca52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import local module containing the neccessary functions\n",
    "import utils_functions as uf\n",
    "\n",
    "# forces the interpreter to re-import the module\n",
    "import importlib\n",
    "importlib.reload(uf);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc49bb0",
   "metadata": {},
   "source": [
    "## State the question\n",
    "I am addressing the third question in this notebook. What can we tell about the job satisfaction of a data coder? What factors do influence it? Also, predict the job satisfaction for a developer who works with big data. \n",
    "\n",
    "This is a classification question, we are predicting a satisfaction level for a data developer, which includes: data scientist or machine learning specialist, data or business analyst and data engineer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcfad12",
   "metadata": {},
   "source": [
    "## Performance metrics - to review at the end\n",
    "\n",
    "The following performance measures will be used in this project:\n",
    "1. Cross validation via StratifiedKFold with 10 folds.\n",
    "2. Confusion matrix, in particular precision, recall and F1 score.\n",
    "3. The ROC curve and the related AUC score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452d2a27",
   "metadata": {},
   "source": [
    "## Gather the data\n",
    "\n",
    "Upload the data and keep the subset that contains those developers that work in data science related fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fb9ad29e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64461, 25)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a path string\n",
    "mypath = os.getcwd()\n",
    "\n",
    "# upload the datafiles as pandas dataframes\n",
    "df1 = pd.read_csv(mypath+'/data/survey20_updated.csv')\n",
    "\n",
    "# check the uploaded data\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8354b521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8726, 25)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the data frame that contains the data developers only\n",
    "df1 = df1[df1.DevClass == 'data_coder']\n",
    "\n",
    "# check the size of the data\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "00aebee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of columns to be used in this analysis\n",
    "list_cols = ['MainBranch', 'ConvertedComp', 'Country',\n",
    "       'EdLevel', 'Employment',\n",
    "       'JobSat', 'EdImpt',\n",
    "       'Learn', 'Overtime', 'OpSys', 'OrgSize', \n",
    "       'UndergradMajor', 'WorkWeekHrs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c81c52d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8726, 13)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the dataset that contains only the listed columns\n",
    "df1 = df1[list_cols]\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "065ec945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the index \n",
    "df1.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "61bed308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8726 entries, 0 to 8725\n",
      "Data columns (total 13 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   MainBranch      8699 non-null   object \n",
      " 1   ConvertedComp   5810 non-null   float64\n",
      " 2   Country         8726 non-null   object \n",
      " 3   EdLevel         8581 non-null   object \n",
      " 4   Employment      8726 non-null   object \n",
      " 5   JobSat          8726 non-null   int64  \n",
      " 6   EdImpt          8206 non-null   object \n",
      " 7   Learn           7979 non-null   object \n",
      " 8   Overtime        7424 non-null   object \n",
      " 9   OpSys           8120 non-null   object \n",
      " 10  OrgSize         7590 non-null   object \n",
      " 11  UndergradMajor  8053 non-null   object \n",
      " 12  WorkWeekHrs     6995 non-null   float64\n",
      "dtypes: float64(2), int64(1), object(10)\n",
      "memory usage: 886.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# gather information on dtypes and missing values\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccdce8e",
   "metadata": {},
   "source": [
    "## Data profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6a33e150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this once to generate a profiling report and save it as html file\n",
    "\n",
    "#import pandas_profiling\n",
    "#profile = pandas_profiling.ProfileReport(df, minimal=False)\n",
    "#profile.to_file(output_file=\"data_coders_report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6c4287",
   "metadata": {},
   "source": [
    "## Data preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad0c14a",
   "metadata": {},
   "source": [
    "### Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6c883ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8687, 13)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop duplicate rows, if any\n",
    "df1.drop_duplicates(subset=None, keep='first', inplace=True)\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badc8282",
   "metadata": {},
   "source": [
    "### Create bins for the WorkWeekHrs column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f38e9f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30-40    3844\n",
       "40-50    1836\n",
       ">50       610\n",
       "<10       284\n",
       "20-30     276\n",
       "10-20     140\n",
       "Name: WorkWeek_Bins, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the labels\n",
    "cut_labels = ['<10', '10-20', '20-30', '30-40', '40-50', '>50']\n",
    "\n",
    "# define the bins \n",
    "m = df1.WorkWeekHrs.max()\n",
    "cut_bins = [0, 10, 20, 30, 40, 50, m]\n",
    "\n",
    "# create a new column which contains the new labels\n",
    "df1['WorkWeek_Bins'] = pd.cut(df1['WorkWeekHrs'], bins=cut_bins, labels=cut_labels)\n",
    "\n",
    "# check for success\n",
    "df1['WorkWeek_Bins'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2d4bde5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1697"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the missing values in the new column\n",
    "df1['WorkWeek_Bins'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1dfe3260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the type of the newly created column\n",
    "df1['WorkWeek_Bins'] = df1['WorkWeek_Bins'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "622851d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the WorkWeekHrs column\n",
    "df1.drop(columns = 'WorkWeekHrs', inplace=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7360c337",
   "metadata": {},
   "source": [
    "### Create bins for the ConvertedComp column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f06f88ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we could use quantile, however I prefer custom bins here\n",
    "cut_labels = ['<10K', '10K-30K', '30K-50K', '50K-100K', '100K-200K', '>200K']\n",
    "\n",
    "# define the bins \n",
    "m = X_train.ConvertedComp.max()\n",
    "cut_bins = [0, 10000, 30000, 50000, 100000, 200000, m]\n",
    "\n",
    "# create a new column which contains the new labels\n",
    "df1['Comp_Bins'] = pd.cut(df1['ConvertedComp'], bins=cut_bins, labels=cut_labels)\n",
    "\n",
    "# change the type of the newly created column\n",
    "df1['Comp_Bins'] = df1['Comp_Bins'].astype('object')\n",
    "\n",
    "# drop the WorkWeekHrs column\n",
    "df1.drop(columns = 'ConvertedComp', inplace=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7b99f9",
   "metadata": {},
   "source": [
    "## Create features and target\n",
    "\n",
    "Create a dataframe (X) with the features and a pandas series (y) that contains the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "59b40b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy of the pre-processed dataframe\n",
    "df2 = df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "fdf816df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8687 entries, 0 to 8725\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   MainBranch      8660 non-null   object\n",
      " 1   Country         8687 non-null   object\n",
      " 2   EdLevel         8542 non-null   object\n",
      " 3   Employment      8687 non-null   object\n",
      " 4   EdImpt          8194 non-null   object\n",
      " 5   Learn           7944 non-null   object\n",
      " 6   Overtime        7419 non-null   object\n",
      " 7   OpSys           8083 non-null   object\n",
      " 8   OrgSize         7584 non-null   object\n",
      " 9   UndergradMajor  8016 non-null   object\n",
      " 10  WorkWeek_Bins   6990 non-null   object\n",
      " 11  Comp_Bins       5783 non-null   object\n",
      "dtypes: object(12)\n",
      "memory usage: 882.3+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 8687)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the predictors dataframe\n",
    "X = df2.drop(columns = 'JobSat')\n",
    "\n",
    "# create the labels\n",
    "y = df2['JobSat']\n",
    "\n",
    "# check for success\n",
    "X.info(), len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a45ce76",
   "metadata": {},
   "source": [
    "## Sample data\n",
    "\n",
    "We will use $30 \\%$ data for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "bf0d97b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data in train and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4f75610f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6080, 12), 6080, (2607, 12), 2607)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for success\n",
    "X_train.shape, len(y_train), X_test.shape, len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127e0839",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3a115bc",
   "metadata": {},
   "source": [
    "## Impute missing values in ConvertedCompensation column\n",
    "\n",
    "Now that we have test and train data, we can impute missing values on the training set, and use the trained imputers to fill in the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaae0199",
   "metadata": {},
   "source": [
    "## Transform categorical data "
   ]
  },
  {
   "cell_type": "raw",
   "id": "47eb4b47",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4945f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the dtypes and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f6a0caa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of categorical features\n",
    "cat_cols = df.select_dtypes(include=['object']).copy().columns\n",
    "non_cat = ['ConvertedComp', 'WorkWeekHrs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7a4c1627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the categorical variablesas dummy, drop the first column for each feature\n",
    "df = pd.get_dummies(df, columns=cat_cols, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "733823e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8722, 419)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
