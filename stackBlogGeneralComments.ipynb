{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9449fd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general packages and libraries\n",
    "import os\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "import importlib\n",
    "\n",
    "# data manipulation packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# data visualizations packages\n",
    "import matplotlib.pyplot as plt\n",
    "# to render plots in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "# set a theme for seaborn\n",
    "sns.set_theme()\n",
    "\n",
    "# numerical, statistical and machine learning packages and libraries\n",
    "import xgboost as xgb\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn import (\n",
    "    ensemble,\n",
    "    tree,\n",
    ")\n",
    "from sklearn.base import (\n",
    "    BaseEstimator, \n",
    "    TransformerMixin,\n",
    ")\n",
    "from sklearn.pipeline import (\n",
    "    make_pipeline,\n",
    "    FeatureUnion, \n",
    "    Pipeline,\n",
    ")\n",
    "from sklearn.feature_selection import (\n",
    "    SelectKBest, \n",
    "    chi2, \n",
    "    mutual_info_classif,\n",
    "    f_classif,\n",
    ")\n",
    "from sklearn.impute import (\n",
    "    KNNImputer,\n",
    "    SimpleImputer,\n",
    ")\n",
    "from sklearn.preprocessing import (\n",
    "    OneHotEncoder, \n",
    "    OrdinalEncoder, \n",
    "    LabelEncoder,\n",
    "    StandardScaler,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    StratifiedKFold,\n",
    "    KFold,\n",
    "    cross_val_score,\n",
    ")\n",
    "\n",
    "#from sklearn.dummy import DummyClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.linear_model import (\n",
    "    SGDClassifier,\n",
    "    LogisticRegression,\n",
    ") \n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    r2_score, \n",
    "    mean_squared_error,\n",
    "    auc,\n",
    "    confusion_matrix, precision_score,\n",
    "    accuracy_score, recall_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve, f1_score,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7993e6b6",
   "metadata": {},
   "source": [
    "# Analysis of StackOverflow Survey\n",
    "\n",
    "This notebook contains notes, alternate solutions and references for the project StackOverflow Developers' Survey 2020. It mainly concerns the modeling part which builds a multi-class classifier for the job satisfaction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e7c6ce",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb9ad29e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64461, 61)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a path string\n",
    "mypath = os.getcwd()\n",
    "\n",
    "# upload the datafiles as pandas dataframes\n",
    "df = pd.read_csv(mypath+'/data/survey20_updated.csv', index_col=[0])\n",
    "\n",
    "# check the uploaded data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a65127c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy of the data\n",
    "dft = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7ca967",
   "metadata": {},
   "source": [
    "## Remove unecessary data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cd96da",
   "metadata": {},
   "source": [
    "### Keep the developers that work with data\n",
    "\n",
    "- The column DevType is a multiple strings column.\n",
    "- In the analysis we differentiate between data developers and other developers only.\n",
    "- Data developers are: data scientist or machine learning specialist, data or business analyst, data engineer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b3a27c",
   "metadata": {},
   "source": [
    "#### Method 1: create an auxiliary column DevClass\n",
    "\n",
    "- Create a new column that marks if the developer works with data or not.\n",
    "- Keep only those data points that correspond to data developers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bbd166f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these steps were performed in the initial stage of data preprocessing\n",
    "\n",
    "# rename the data engineer string in the full dataset\n",
    "#df['DevType'] = df['DevType'].str.replace('Engineer, data', 'Data engineer')\n",
    "\n",
    "# respondents choose more than one answer as we can see below\n",
    "# DevType_counts = df.DevType.value_counts().reset_index()\n",
    "\n",
    "# create a list of the individual answers that can be marked by a user\n",
    "#dev_choice = list(DevType_counts.devChoice.str.split(';', expand=True)[0].unique())\n",
    "\n",
    "# the list of types of developers working with data\n",
    "#data_dev = [x for x in dev_choice if 'Data ' in x]\n",
    "\n",
    "# use np.where(condition, value if condition is true, value if condition is false)\n",
    "# create column DevClass, entry data_coder or other_coder, based on DevType contains data or not\n",
    "#df1['DevClass'] = np.where(df1[\"DevType\"].str.contains(\"Data \", na = False), 'data_coder', 'other_coder')\n",
    "\n",
    "# the subset of developers that checked at least one data related profession\n",
    "#data_coders = df1[df1[\"DevClass\"] == 'data_coder']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0230acc6",
   "metadata": {},
   "source": [
    "#### Method 2: split the strings and use pandas explode\n",
    "\n",
    "- This creates rows duplicates, one for each choice of developer type.\n",
    "- I suspect this method induces data leakage and eventually overfitting. \n",
    "- This method splits the developers in three categories, as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11b19bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change each string in DevType column into a list of strings\n",
    "# this is necessary for pd.explode to work\n",
    "#df1['DevType'] = df1['DevType'].str.split(';')\n",
    "\n",
    "# split a row with multiple choices strings in DevType into rows where\n",
    "# DevType contains only one choice, the index is replicated \n",
    "#df1=df1.explode('DevType')\n",
    "\n",
    "# drop the rows with missing values in DevType column\n",
    "# necessary for the string search in the next step to work\n",
    "#df1.dropna(subset=['DevType'], inplace=True)\n",
    "\n",
    "# retain only those rows that contain data coders\n",
    "#df1 = df1[df1['DevType'].str.contains('Data ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14848633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the developers that work with data, use the custom function\n",
    "\n",
    "# rewrite entries in 'DevType' column as strings to replicate rows\n",
    "dft = uf.explode_col(dft, 'DevType')\n",
    "\n",
    "# retain only those rows that contain data coders\n",
    "dft = dft.loc[dft.DevType.str.contains('Data ', na=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14be3ec",
   "metadata": {},
   "source": [
    "#### Method 3: split the strings in DevType and create corresponding columns\n",
    "\n",
    "- Split each string in the entries of DevType.\n",
    "- Create sparse column for each developer type.\n",
    "- Retain only those data points that correspond to one of the data developers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40227f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://github.com/adrianhasse/job-satisfaction\n",
    "\n",
    "def handle_multi_string_columns(df, column, single_strings):\n",
    "    '''\n",
    "    Replaces column whose fields contain several strings with new columns. Each\n",
    "    new column will then represent a single string\n",
    "    \n",
    "    INPUT:\n",
    "    df - the pandas dataframe you want to search\n",
    "    column - the column name you want to look through\n",
    "    single_strings - a list of strings you want to search for in each row of df[col]\n",
    "\n",
    "    OUTPUT:\n",
    "    new_df - The dataframe without the multi-string column but with the newly created columns\n",
    "    col_dict - Dictionary translating names of the new columns to their corresponding string\n",
    "    '''\n",
    "    \n",
    "    #collects new columns of indicating if a certain index refers to a string \n",
    "    new_columns = dict()\n",
    "    \n",
    "    #dict column name -> string name\n",
    "    col_dict = dict()\n",
    "    \n",
    "    #loop through list of strings\n",
    "    counter = 0\n",
    "    for string in single_strings:\n",
    "        bool_list = []\n",
    "        #loop through rows\n",
    "        for idx in range(df.shape[0]):\n",
    "            #if the ed type is in the row set to True\n",
    "            if string in str(df[column][idx]):\n",
    "                bool_list.append(1)\n",
    "            else:\n",
    "                bool_list.append(0)\n",
    "        col_name = column + \"_\" + str(counter)\n",
    "        new_columns[col_name] = bool_list\n",
    "        col_dict[col_name] = string\n",
    "        counter = counter + 1\n",
    "    \n",
    "    new_df = df.drop(column,axis=1)\n",
    "    \n",
    "    new_df = pd.concat([new_df, pd.DataFrame(data=new_columns, index = df.index, dtype=int)], axis=1)\n",
    "    \n",
    "    return new_df, col_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "378287a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StringtoSetTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Scikit-learn transformer to convert the feature which is a string with fields separated by comma into a column\n",
    "    of a list\"\"\"\n",
    "    def __init__(self, variables=None):\n",
    "        if not isinstance(variables, list):\n",
    "            self.variables = [variables]\n",
    "        else:\n",
    "            self.variables = variables\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for feature in self.variables:\n",
    "            # if nan, create an empty set instead of imputation\n",
    "            X[feature] = X[feature].str.split(';').apply(lambda x: {} if\n",
    "                                                         x is np.nan else set(x))\n",
    "        return X\n",
    "    \n",
    "\n",
    "class ListColumnsEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Scikit-learn transformer to convert a feature column of a list in \n",
    "    to multiple binary feature columns\"\"\"\n",
    "    def __init__(self, variables=None):\n",
    "        \n",
    "        if not isinstance(variables, list):\n",
    "            self.variables = [variables]\n",
    "        else:\n",
    "            self.variables = variables\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # persist mode in a dictionary\n",
    "        self.encoder_dict_ = {}\n",
    "        \n",
    "        for feature in self.variables:\n",
    "            _ = MultiLabelBinarizer()\n",
    "            _.fit(X[feature])\n",
    "            self.encoder_dict_[feature] = _\n",
    "\n",
    "    def transform(self, X):\n",
    "\n",
    "        X = X.copy()\n",
    "        for feature in self.variables:\n",
    "            f_encoded = pd.DataFrame(\n",
    "                self.encoder_dict_[feature].transform(X[feature]),\n",
    "                columns=self.encoder_dict_[feature].classes_,\n",
    "                index=X.index)\n",
    "\n",
    "            X = pd.concat([X, f_encoded], axis=1).drop(columns=[feature])\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce1783a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MY APPROACH WITHOUT CLASSES\n",
    "\n",
    "# replace the list of entries with sets, missing values with empy set\n",
    "df1['PlatformWorkedWith'] = df1['PlatformWorkedWith'].str.split(';').apply(lambda x: {} if\n",
    "\n",
    "# check the outcome                                                                      x is np.nan else set(x))\n",
    "df1['PlatformWorkedWith'][:6]\n",
    "\n",
    "# create an instance of the encoder\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# fit the binarizer and encode the selected column\n",
    "temp_col = mlb.fit_transform(df1['PlatformWorkedWith'])\n",
    "\n",
    "# put the outcome in pandas dataframe form\n",
    "temp_df = pd.DataFrame(temp_col, columns=mlb.classes_, index=df1.index)\n",
    "\n",
    "# combine the two dataframes and drop the initial column\n",
    "df1 = pd.concat([df1, temp_df], axis=1).drop(columns = ['PlatformWorkedWith'])\n",
    "\n",
    "# check the outcome\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cf7b63",
   "metadata": {},
   "source": [
    "## Feature selection\n",
    "\n",
    "Various ways to perform feature selection. Not included in the final approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a6125b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/Chancylin/StackOverflow_Survey/blob/main/code/data_process.py\n",
    "\n",
    "def cal_mutual_info(df, target_var=None, disc_features_only=True):\n",
    "    \"\"\"Calculate mutual information for feature selection, based on mutual_info_classif from sklearn.feature_selection.\n",
    "    :param df: Pandas dataframe\n",
    "    :param target_var: target variable\n",
    "    :param disc_features_only: boolean, calculate mutual information for discrete feature only\n",
    "    :return:\n",
    "        a Pandas dataframe with mutual information for features\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    df_f_type = df.dtypes\n",
    "    df_f_type = df_f_type.loc[~df_f_type.index.isin([target_var])].copy()\n",
    "    cols_if_num = df_f_type.apply(lambda x: np.issubdtype(x, np.number))\n",
    "    discrete_f = ~cols_if_num\n",
    "    # get all categorical features\n",
    "    cols_num = cols_if_num[cols_if_num].index.tolist()\n",
    "    cols_cat = cols_if_num[~cols_if_num].index.tolist()\n",
    "\n",
    "    for col_cat in cols_cat:\n",
    "        df[col_cat] = df[col_cat].fillna('Missing')\n",
    "\n",
    "    for col_num in cols_num:\n",
    "        df[col_num] = df[col_num].fillna(df[col_num].mean())\n",
    "        \n",
    "    enc = OrdinalEncoder()\n",
    "    df[cols_cat] = enc.fit_transform(df[cols_cat])\n",
    "    enc = OrdinalEncoder()\n",
    "    df.loc[:, target_var] = enc.fit_transform(df[[target_var]])\n",
    "\n",
    "    if not disc_features_only:\n",
    "        all_features = df_f_type.index.tolist()\n",
    "        mutual_info = mutual_info_classif(df[all_features], df[target_var].values,\n",
    "                                          discrete_features=discrete_f,\n",
    "                                          n_neighbors=20,\n",
    "                                          random_state=123)\n",
    "        df_mutual_info = pd.DataFrame(data=zip(all_features, mutual_info),\n",
    "                                      columns=['columns', 'mutual_info'])\n",
    "        return df_mutual_info\n",
    "    else:\n",
    "\n",
    "        mutual_info = mutual_info_classif(df[cols_cat], df[target_var].values,\n",
    "                                          discrete_features=True)\n",
    "        df_mutual_info = pd.DataFrame(data=zip(cols_cat, mutual_info),\n",
    "                                      columns=['columns', 'mutual_info'])\n",
    "        return df_mutual_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4af4a0",
   "metadata": {},
   "source": [
    "### My approach: step_by_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "719e41b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Age', 'CompTotal', 'ConvertedComp', 'WorkWeekHrs']\n"
     ]
    }
   ],
   "source": [
    "# the list of numerical columns\n",
    "num_cols = df1.select_dtypes(include='float64').columns.to_list()\n",
    "print(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55f91054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MainBranch', 'Hobbyist', 'Age1stCode', 'CompFreq', 'Country', 'CurrencyDesc', 'CurrencySymbol', 'DatabaseDesireNextYear', 'DatabaseWorkedWith', 'DevType', 'EdLevel', 'Employment', 'Ethnicity', 'Gender', 'JobFactors', 'JobSat', 'JobSeek', 'LanguageDesireNextYear', 'LanguageWorkedWith', 'MiscTechDesireNextYear', 'MiscTechWorkedWith', 'CollabToolsDesireNextYear', 'CollabToolsWorkedWith', 'DevOps', 'DevOpsImpt', 'EdImpt', 'JobHunt', 'JobHuntResearch', 'Learn', 'OffTopic', 'OnboardGood', 'OtherComms', 'Overtime', 'PurchaseResearch', 'PurpleLink', 'SOSites', 'Stuck', 'OpSys', 'OrgSize', 'PlatformDesireNextYear', 'PlatformWorkedWith', 'PurchaseWhat', 'Sexuality', 'SOAccount', 'SOComm', 'SOPartFreq', 'SOVisitFreq', 'SurveyEase', 'SurveyLength', 'Trans', 'UndergradMajor', 'WebframeDesireNextYear', 'WebframeWorkedWith', 'WelcomeChange', 'YearsCode', 'YearsCodePro', 'DevClass']\n"
     ]
    }
   ],
   "source": [
    "# the list of categorical columns, drop the target 'JobSat'\n",
    "cat_cols = df1.select_dtypes(include='object').columns.to_list()\n",
    "print(cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cca2664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the list of columns with high cardinality - will get a high selection score\n",
    "multiple = ['DatabaseDesireNextYear', 'DatabaseWorkedWith', \n",
    "           'LanguageDesireNextYear', 'LanguageWorkedWith',\n",
    "            'MiscTechDesireNextYear', 'MiscTechWorkedWith', \n",
    "            'CollabToolsDesireNextYear', 'CollabToolsWorkedWith', \n",
    "            'PlatformDesireNextYear', 'PlatformWorkedWith', \n",
    "            'WebframeDesireNextYear', 'WebframeWorkedWith']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad532941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OnboardGood', 'WelcomeChange', 'Ethnicity', 'JobHunt', 'OffTopic', 'SOPartFreq', 'Country', 'SOComm', 'MainBranch', 'SurveyLength', 'CompFreq', 'YearsCode', 'DevClass', 'Gender', 'JobHuntResearch', 'DevOps', 'Overtime', 'OtherComms', 'Age1stCode', 'EdImpt', 'YearsCodePro', 'SOVisitFreq', 'Trans', 'Learn', 'DevType', 'SOSites', 'Sexuality', 'PurpleLink', 'CurrencyDesc', 'SurveyEase', 'PurchaseResearch', 'JobFactors', 'Employment', 'Stuck', 'CurrencySymbol', 'OpSys', 'Hobbyist', 'OrgSize', 'UndergradMajor', 'SOAccount', 'EdLevel', 'JobSeek', 'PurchaseWhat', 'DevOpsImpt']\n"
     ]
    }
   ],
   "source": [
    "# remove target 'JobSat' and the multiple columns from cat_cols\n",
    "cat_cols = list(set(cat_cols) - set(multiple))\n",
    "cat_cols.remove('JobSat')\n",
    "print(cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8354b521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop all missing entries in 'JobSat'\n",
    "df1.dropna(subset=['JobSat'], inplace=True)\n",
    "# check output\n",
    "df1['JobSat'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3af85dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MainBranch          0\n",
       "Hobbyist            0\n",
       "Age              8839\n",
       "Age1stCode          0\n",
       "CompFreq            0\n",
       "                 ... \n",
       "WelcomeChange       0\n",
       "WorkWeekHrs      4137\n",
       "YearsCode           0\n",
       "YearsCodePro        0\n",
       "DevClass            0\n",
       "Length: 61, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fill in 'missing' in all categorical columns in the list\n",
    "for col in cat_cols:\n",
    "        df1[col] = df1[col].fillna('missing')\n",
    "# check outcome\n",
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00aebee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age              0\n",
       "CompTotal        0\n",
       "ConvertedComp    0\n",
       "WorkWeekHrs      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fill in 'median' in all numerical columns in the list\n",
    "for col in num_cols:\n",
    "        df1[col] = df1[col].fillna(df1[col].median())\n",
    "# check outcome\n",
    "df1[num_cols].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "128e8053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the numerical columns\n",
    "\n",
    "# create an instance of the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# scale the numerical variables, fit and transform on the straining set\n",
    "df1[num_cols] = pd.DataFrame(scaler.fit_transform(df1[num_cols]), \n",
    "                                columns=df1[num_cols].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6234f9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the categorical variables\n",
    "enc = OrdinalEncoder()\n",
    "df1[cat_cols] = enc.fit_transform(df1[cat_cols])\n",
    "enc = OrdinalEncoder()\n",
    "df1.loc[:, 'JobSat'] = enc.fit_transform(df1[['JobSat']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d21265f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection function, to be rewritten as a custom transformer class\n",
    "def select_features(X_train, y_train, score_function, kval, no_cols):# add X_test\n",
    "    \"\"\"\n",
    "    Function for feature selection for (discrete) variables.\n",
    "    INPUT: X_train - input dataframe, must have only discrete or only continuous features, \n",
    "                     pre-processed by removing/imputing missing values and encoded\n",
    "           y_train - target pd.series, pre-processed\n",
    "           score_function - can be any of the score functions supported by SelectKBest\n",
    "           kval = the number of best features to return, can be 'all'\n",
    "           no_cols = number of columns to print\n",
    "    OUTPUT: dataframe with two columns, one for the column names in X_train, \n",
    "            the second for the scores computed, sorted in decreasing order of the scores\n",
    "            #variant: if transform of X_test set is performed, \n",
    "                      it also returns the transformed dataframe\n",
    "    \"\"\"\n",
    "    # create an instance of the selector\n",
    "    fs = SelectKBest(score_func=score_function, k=kval)\n",
    "    # fit the selector on the train set and the train target values\n",
    "    fs.fit(X_train, y_train)\n",
    "    # transform the train set, it will have only the kbest columns\n",
    "    X_train_r = fs.transform(X_train) \n",
    "    # transform the test set, it will have only the kbest columns\n",
    "    #X_test_r = fs.transform(X_test) \n",
    "    # get column names for kbest columns\n",
    "    cols_info = fs.get_support(indices=True)\n",
    "    cols = X_train.iloc[:,cols_info].columns\n",
    "    # put columns and their scores together in a dataframe\n",
    "    frame_best = pd.DataFrame(data=zip(cols,fs.scores_), columns = ['cat_columns', 'kbest_scores'])\n",
    "    return frame_best.sort_values(by='kbest_scores', ascending=False).head(no_cols)\n",
    "    return X_r, frame_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40007dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat_columns</th>\n",
       "      <th>kbest_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>JobSeek</td>\n",
       "      <td>0.101638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OnboardGood</td>\n",
       "      <td>0.030806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JobHunt</td>\n",
       "      <td>0.030312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Country</td>\n",
       "      <td>0.026406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>CurrencyDesc</td>\n",
       "      <td>0.016943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>CurrencySymbol</td>\n",
       "      <td>0.015994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>PurchaseWhat</td>\n",
       "      <td>0.013272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ethnicity</td>\n",
       "      <td>0.009715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Age1stCode</td>\n",
       "      <td>0.009144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>OtherComms</td>\n",
       "      <td>0.008300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CompFreq</td>\n",
       "      <td>0.007640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Stuck</td>\n",
       "      <td>0.007559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>DevType</td>\n",
       "      <td>0.007554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DevOps</td>\n",
       "      <td>0.006551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>SOSites</td>\n",
       "      <td>0.006465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cat_columns  kbest_scores\n",
       "41         JobSeek      0.101638\n",
       "0      OnboardGood      0.030806\n",
       "3          JobHunt      0.030312\n",
       "6          Country      0.026406\n",
       "28    CurrencyDesc      0.016943\n",
       "34  CurrencySymbol      0.015994\n",
       "42    PurchaseWhat      0.013272\n",
       "2        Ethnicity      0.009715\n",
       "18      Age1stCode      0.009144\n",
       "17      OtherComms      0.008300\n",
       "10        CompFreq      0.007640\n",
       "33           Stuck      0.007559\n",
       "24         DevType      0.007554\n",
       "15          DevOps      0.006551\n",
       "25         SOSites      0.006465"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the above function - done without X_test\n",
    "select_features(df1[cat_cols], df1['JobSat'], mutual_info_classif, 'all', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbeadca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternate approach to feature selection, using mutual_info_classif\n",
    "mutual_info = mutual_info_classif(df1[cat_cols], df1['JobSat'],\n",
    "                                          discrete_features='auto',\n",
    "                                          n_neighbors=3,\n",
    "                                          copy=True,\n",
    "                                          random_state=42)\n",
    "df_mutual_info = pd.DataFrame(data=zip(cat_cols, mutual_info), columns=['columns', 'mutual_info'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "038822d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>columns</th>\n",
       "      <th>mutual_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>JobSeek</td>\n",
       "      <td>0.100693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JobHunt</td>\n",
       "      <td>0.031575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OnboardGood</td>\n",
       "      <td>0.030981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>CurrencyDesc</td>\n",
       "      <td>0.020989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>CurrencySymbol</td>\n",
       "      <td>0.020525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Country</td>\n",
       "      <td>0.016402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>JobFactors</td>\n",
       "      <td>0.010464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>PurchaseResearch</td>\n",
       "      <td>0.010394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ethnicity</td>\n",
       "      <td>0.010051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>PurchaseWhat</td>\n",
       "      <td>0.008045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>JobHuntResearch</td>\n",
       "      <td>0.007736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CompFreq</td>\n",
       "      <td>0.007328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>DevOpsImpt</td>\n",
       "      <td>0.006611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Overtime</td>\n",
       "      <td>0.006337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>YearsCodePro</td>\n",
       "      <td>0.006122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             columns  mutual_info\n",
       "41           JobSeek     0.100693\n",
       "3            JobHunt     0.031575\n",
       "0        OnboardGood     0.030981\n",
       "28      CurrencyDesc     0.020989\n",
       "34    CurrencySymbol     0.020525\n",
       "6            Country     0.016402\n",
       "31        JobFactors     0.010464\n",
       "30  PurchaseResearch     0.010394\n",
       "2          Ethnicity     0.010051\n",
       "42      PurchaseWhat     0.008045\n",
       "14   JobHuntResearch     0.007736\n",
       "10          CompFreq     0.007328\n",
       "43        DevOpsImpt     0.006611\n",
       "16          Overtime     0.006337\n",
       "20      YearsCodePro     0.006122"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mutual_info.sort_values(by='mutual_info', ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96aeab0e",
   "metadata": {},
   "source": [
    "## Binning continuous variables\n",
    "\n",
    "Tried in the first version. The accuracy scores of the models are very low. Did not include in the final approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badc8282",
   "metadata": {},
   "source": [
    "### Create bins for the WorkWeekHrs column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38e9f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy of the data\n",
    "df1 = df.copy()\n",
    "\n",
    "# create the labels\n",
    "cut_labels = ['less-10', '10-20', '20-30', '30-40', '40-50', 'more-50']\n",
    "\n",
    "# define the bins \n",
    "m = df1.WorkWeekHrs.max()\n",
    "cut_bins = [0, 10, 20, 30, 40, 50, m]\n",
    "\n",
    "# create a new column which contains the new labels\n",
    "df1['WorkWeek_Bins'] = pd.cut(df1['WorkWeekHrs'], bins=cut_bins, labels=cut_labels)\n",
    "\n",
    "# check for success\n",
    "df1['WorkWeek_Bins'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfe3260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the type of the newly created column\n",
    "df1['WorkWeek_Bins'] = df1['WorkWeek_Bins'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622851d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the WorkWeekHrs column\n",
    "df1.drop(columns = 'WorkWeekHrs', inplace=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7360c337",
   "metadata": {},
   "source": [
    "### Create bins for the ConvertedComp column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06f88ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we could use quantile, however I prefer custom bins here\n",
    "cut_labels = ['less-10K', '10K-30K', '30K-50K', '50K-100K', '100K-200K', 'more-200K']\n",
    "\n",
    "# define the bins \n",
    "m = df1.ConvertedComp.max()\n",
    "cut_bins = [0, 10000, 30000, 50000, 100000, 200000, m]\n",
    "\n",
    "# create a new column which contains the new labels\n",
    "df1['Comp_Bins'] = pd.cut(df1['ConvertedComp'], bins=cut_bins, labels=cut_labels)\n",
    "\n",
    "# change the type of the newly created column\n",
    "df1['Comp_Bins'] = df1['Comp_Bins'].astype('object')\n",
    "\n",
    "# drop the WorkWeekHrs column\n",
    "df1.drop(columns = 'ConvertedComp', inplace=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f30ade",
   "metadata": {},
   "source": [
    "### Create bins for the Age column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6297d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the bin edges\n",
    "cut_labels = ['<20', '20-30', '30-40', '40-50', '50-60', '60-70', '70-80', '>80']\n",
    "\n",
    "# define the bins \n",
    "m = df1.Age.max()\n",
    "cut_bins = [0, 20, 30, 40, 50, 60, 70, 80, m]\n",
    "\n",
    "# create a new column which contains the new labels\n",
    "df1['Age_Bins'] = pd.cut(df1['Age'], bins=cut_bins, labels=cut_labels)\n",
    "\n",
    "# change the type of the newly created column\n",
    "df1['Age_Bins'] = df1['Age_Bins'].astype('object')\n",
    "\n",
    "# drop the WorkWeekHrs column\n",
    "df1.drop(columns = 'Age', inplace=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff817994",
   "metadata": {},
   "source": [
    "### Remove the rows that contain mostly missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e323f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only the rows with at least 10 non-NA values\n",
    "df1.dropna(thresh=10)\n",
    "\n",
    "# check the result\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7b99f9",
   "metadata": {},
   "source": [
    "## Create features and target\n",
    "\n",
    "Create a dataframe (X) with the features and a pandas series (y) that contains the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf816df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy of the pre-processed dataframe\n",
    "df2 = df1.copy()\n",
    "\n",
    "# create the predictors dataframe\n",
    "X = df2.drop(columns = 'JobSat')\n",
    "\n",
    "# create the labels\n",
    "y = df2['JobSat']\n",
    "\n",
    "# check for success\n",
    "print(X.info(), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c049e8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# format all the fields as strings in the feature matrix\n",
    "X = X.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a45ce76",
   "metadata": {},
   "source": [
    "## Sample data\n",
    "\n",
    "We will use $30 \\%$ data for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0d97b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data in train and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# summarize the data\n",
    "print('Train', X_train.shape, y_train.shape)\n",
    "print('Test', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a115bc",
   "metadata": {},
   "source": [
    "## Impute missing values\n",
    "\n",
    "Now that we have test and train data, we can impute missing values on the training set, and use the trained imputer to fill in the test dataset. I will use the KNN imputer from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4945f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance of the imputer\n",
    "#imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "# fit the imputer on the dataset\n",
    "#X_train_trans = pd.DataFrame(imputer.fit_transform(X_train), columns = X_train.columns)\n",
    "\n",
    "# check for success\n",
    "#X_train_trans.isna().any()\n",
    "from sklearn.impute import SimpleImputer\n",
    "def impute_predictors(X_train, X_test):\n",
    "    imputer = SimpleImputer(strategy='constant', fill_value='missing')\n",
    "    imputer.fit(X_train)\n",
    "    X_train_trans = pd.DataFrame(imputer.transform(X_train), columns=X_train.columns)\n",
    "    X_test_trans = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)\n",
    "    return X_train_trans, X_test_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa411ff",
   "metadata": {},
   "source": [
    "## Encode the data\n",
    "\n",
    "The best practice when encoding variables is to fit the encoding on the training dataset, then apply it to the train and test datasets.\n",
    "\n",
    "The function below named prepare_inputs() takes the input data for the train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19108de7",
   "metadata": {},
   "source": [
    "Regarding the output data, the target, since it is already encoded as an integer with values from 0 to 5, no other encoding steps are needed at this point.\n",
    "\n",
    "Alternative would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c6ae2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare target\n",
    "def encode_targets(y_train, y_test):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(y_train)\n",
    "    y_train_enc = le.transform(y_train)\n",
    "    y_test_enc = le.transform(y_test)\n",
    "    return y_train_enc, y_test_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97eb6d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the high cardinality columns\n",
    "def encode_predictors(X_train, X_test):\n",
    "    enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    enc.fit(X_train)\n",
    "    X_train_enc = pd.DataFrame(enc.transform(X_train))\n",
    "    X_test_enc = pd.DataFrame(enc.transform(X_test))\n",
    "    return X_train_enc, X_test_enc\n",
    "\n",
    "# the high cardinality encoded features\n",
    "X_train_multi_enc, X_test_multi_enc = encode_predictors(X_train_cat_imp[multi_cols], \n",
    "                                                        X_test_cat_imp[multi_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57de381b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance of the custom transformer\n",
    "#multi_encoder = uc.MultiColumnsEncoder(feature_names=multi_cols)\n",
    "\n",
    "# fit and transform the training set\n",
    "#df_temp = multi_encoder.fit_transform(X_train[multi_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57f05c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the binarizer on the train set\n",
    "mlb_plat = mlb.fit(X_train['PlatformWorkedWith'])\n",
    "\n",
    "# transform the corresponding column in the train set\n",
    "mlb_plat_train =  mlb_plat.transform(X_train['PlatformWorkedWith'])\n",
    "\n",
    "# put the outcome in pandas dataframe form\n",
    "temp_plat_train = pd.DataFrame(mlb_plat_train, columns = mlb_plat.classes_,\n",
    "                         index = X_train.index)\n",
    "\n",
    "# list the three most popular platforms to retain\n",
    "platform_keep = list(temp_plat_train.sum().sort_values(ascending=False).head(3).index)\n",
    "\n",
    "# combine the two dataframes and drop the initial column\n",
    "X_train = pd.concat([X_train, temp_plat_train[platform_keep]],\n",
    "                    axis=1).drop(columns = ['PlatformWorkedWith'])\n",
    "\n",
    "# apply the same transformations to the test set\n",
    "mlb_plat_test =  mlb_plat.transform(X_test['PlatformWorkedWith'])\n",
    "\n",
    "# put the outcome in pandas dataframe form\n",
    "temp_plat_test = pd.DataFrame(mlb_plat_test, columns = mlb_plat.classes_,\n",
    "                              index = X_test.index)\n",
    "\n",
    "# combine the two dataframes and drop the initial column\n",
    "X_test = pd.concat([X_test, temp_plat_test[platform_keep]], \n",
    "                   axis=1).drop(columns = ['PlatformWorkedWith'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d47cc4",
   "metadata": {},
   "source": [
    "## Baseline model: K NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9934c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance of the classifier\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# fit the classifier\n",
    "knn_clf.fit(X_train_fs, y_train)\n",
    "\n",
    "# predict output values\n",
    "y_pred = knn_clf.predict(X_test_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c3bf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print evaluation metrics and results\n",
    "\n",
    "result1 = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(result1)\n",
    "\n",
    "result2 = classification_report(y_test, y_pred)\n",
    "print('\\nClassification Report:')\n",
    "print (result2)\n",
    "\n",
    "result3 = accuracy_score(y_test,y_pred)  \n",
    "print('Accuracy: %.3f' %result3)\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8cd09a",
   "metadata": {},
   "source": [
    "## Several other algorithms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f664a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# create classifier instance\n",
    "svm_clf = SVC(gamma=\"auto\", random_state=42)\n",
    "# fit the model\n",
    "svm_clf.fit(X_train_fs, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0f5392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on the test set\n",
    "y_pred = svm_clf.predict(X_test_fs)\n",
    "\n",
    "# test one value\n",
    "y_test.iloc[20],  y_pred[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae437bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_digit_scores = svm_clf.decision_function(X_test_fs)\n",
    "some_digit_scores[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd7f7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(some_digit_scores[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acae03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376bba3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173c0f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(svm_clf, X_test_fs, y_test, cv=10, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0d8b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print evaluation metrics and results\n",
    "\n",
    "result1 = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(result1)\n",
    "\n",
    "result2 = classification_report(y_test, y_pred, zero_division=0)\n",
    "print('\\nClassification Report:')\n",
    "print (result2)\n",
    "\n",
    "result3 = accuracy_score(y_test,y_pred)  \n",
    "print('Accuracy: %.3f' %result3)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b45d132",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "ovr_clf = OneVsRestClassifier(SVC(gamma=\"auto\", random_state=42))\n",
    "ovr_clf.fit(X_train_fs, y_train)\n",
    "y_pred = ovr_clf.predict(X_test_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac945a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(result1)\n",
    "\n",
    "result2 = classification_report(y_test, y_pred, zero_division=0)\n",
    "print('\\nClassification Report:')\n",
    "print (result2)\n",
    "\n",
    "result3 = accuracy_score(y_test,y_pred)  \n",
    "print('Accuracy: %.3f' %result3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f0b71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Always scale the input. The most convenient way is to use a pipeline.\n",
    "sgd_clf = make_pipeline(StandardScaler(with_mean=False),\n",
    "                        SGDClassifier(max_iter=1000, tol=1e-3))\n",
    "sgd_clf.fit(X_train_fs, y_train)\n",
    "y_pred = sgd_clf.predict(X_test_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3033a0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(result1)\n",
    "\n",
    "result2 = classification_report(y_test, y_pred, zero_division=0)\n",
    "print('\\nClassification Report:')\n",
    "print (result2)\n",
    "\n",
    "result3 = accuracy_score(y_test,y_pred)  \n",
    "print('Accuracy: %.3f' %result3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d44922",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [DecisionTreeClassifier, KNeighborsClassifier, GaussianNB, SVC, \n",
    "              RandomForestClassifier, SGDClassifier]:\n",
    "    make_pipeline(StandardScaler(),model())\n",
    "    classifier = model()\n",
    "    kfold = model_selection.KFold(n_splits=10)\n",
    "    classifier.fit(X_train_fs.toarray(), y_train)\n",
    "    s = model_selection.cross_val_score(classifier, X_test_fs.toarray(),y_test, cv=kfold)\n",
    "    #result2 = classification_report(y_test, y_pred, zero_division=0)\n",
    "    #s = model_selection.cross_val_score(cls, X, y, cv=kfold)\n",
    "    print(f\"{model.__name__:22}  CV_Mean:\" f\"{s.mean():.3f} CV_STD: {s.std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633392f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(objective=\"multi:softprob\", random_state=42)\n",
    "\n",
    "params = {\n",
    "    \"colsample_bytree\": uniform(0.7, 0.3),\n",
    "    \"gamma\": uniform(0, 0.5),\n",
    "    \"learning_rate\": uniform(0.03, 0.3), # default 0.1 \n",
    "    \"max_depth\": randint(2, 6), # default 3\n",
    "    \"n_estimators\": randint(100, 150), # default 100\n",
    "    \"subsample\": uniform(0.6, 0.4)\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(xgb_model, param_distributions=params, random_state=42, \n",
    "                            n_iter=200, cv=3, verbose=1, n_jobs=1, return_train_score=True)\n",
    "\n",
    "search.fit(X_train_fs, y_train)\n",
    "\n",
    "#report_best_scores(search.cv_results_, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e065f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "search.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5400b90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60865dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from stack\n",
    "clf_xgb = xgb.XGBClassifier(objective = 'binary:logistic')\n",
    "param_dist = {'n_estimators': stats.randint(150, 1000),\n",
    "              'learning_rate': stats.uniform(0.01, 0.59),\n",
    "              'subsample': stats.uniform(0.3, 0.6),\n",
    "              'max_depth': [3, 4, 5, 6, 7, 8, 9],\n",
    "              'colsample_bytree': stats.uniform(0.5, 0.4),\n",
    "              'min_child_weight': [1, 2, 3, 4]\n",
    "             }\n",
    "\n",
    "numFolds = 5\n",
    "kfold_5 = cross_validation.KFold(n = len(X), shuffle = True, n_folds = numFolds)\n",
    "\n",
    "clf = RandomizedSearchCV(clf_xgb, \n",
    "                         param_distributions = param_dist,\n",
    "                         cv = kfold_5,  \n",
    "                         n_iter = 5, # you want 5 here not 25 if I understand you correctly \n",
    "                         scoring = 'roc_auc', \n",
    "                         error_score = 0, \n",
    "                         verbose = 3, \n",
    "                         n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbdc5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "scores = []\n",
    "\n",
    "for train_index, test_index in kfold.split(X_train_fs):   \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    xgb_model = xgb.XGBClassifier(objective=\"multi:softprob\", random_state=42)\n",
    "    xgb_model.fit(X_train_fs, y_train)\n",
    "    \n",
    "    y_pred = xgb_model.predict(X_test_fs)\n",
    "    \n",
    "    scores.append(mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "display_scores(np.sqrt(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9856f647",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = RandomForestClassifier()\n",
    "kfold = model_selection.KFold(n_splits=10)\n",
    "s = model_selection.cross_val_score(cls, X,y, cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575e4e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_rf = RandomForestClassifier()\n",
    "kfold = model_selection.KFold(n_splits=10)\n",
    "cls_rf.fit(X_train, y_train)\n",
    "y_pred = cls_rf.predict(X_test)\n",
    "s = model_selection.cross_val_score(cls_rf, X_test,y_test, cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07becbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4736c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Always scale the input. The most convenient way is to use a pipeline.\n",
    "sgd_clf = make_pipeline(StandardScaler(),SGDClassifier(max_iter=1000, tol=1e-3))\n",
    "sgd_clf.fit(X1_train, y1_train)\n",
    "y1_pred = sgd_clf.predict(X1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482491d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess, split and process data\n",
    "#preproc_df2 = uf.preprocess_data(df2)\n",
    "X2_train, y2_train, X2_test, y2_test = uf.process_data(preproc_df2, 'JobSat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c864feb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [DecisionTreeClassifier, KNeighborsClassifier, GaussianNB, SVC, \n",
    "              RandomForestClassifier, SGDClassifier]:\n",
    "    make_pipeline(StandardScaler(),model())\n",
    "    classifier = model()\n",
    "    kfold = model_selection.KFold(n_splits=10)\n",
    "    classifier.fit(X2, y2)\n",
    "    s = model_selection.cross_val_score(classifier, X2,y2, cv=kfold)\n",
    "    #result2 = classification_report(y_test, y_pred, zero_division=0)\n",
    "    #s = model_selection.cross_val_score(cls, X, y, cv=kfold)\n",
    "    print(f\"{model.__name__:22}  CV_Mean:\" f\"{s.mean():.3f} CV_STD: {s.std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec7cd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Always scale the input. The most convenient way is to use a pipeline.\n",
    "sgd_clf = make_pipeline(StandardScaler(),SGDClassifier(max_iter=1000, tol=1e-3))\n",
    "sgd_clf.fit(X2_train, y2_train)\n",
    "y2_pred = sgd_clf.predict(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ea29f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf94439",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02c01ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import local modules \n",
    "import utils_functions as uf \n",
    "import utils_classes as uc\n",
    "import local_maps as lm\n",
    "\n",
    "# forces the interpreter to re-load the module\n",
    "importlib.reload(uf);\n",
    "\n",
    "# create a path string\n",
    "mypath = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99969d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_cols = ['PlatformWorkedWith', 'CollabToolsWorkedWith']\n",
    "num_cols = ['ConvertedComp', 'WorkWeekHrs', 'YearsCode']\n",
    "uni_cols = ['OrgSize', 'UndergradMajor', 'PurchaseWhat', \n",
    "            'OpSys', 'Learn', 'Overtime', 'OnboardGood', \n",
    "            'DevOps', 'DevOpsImpt', 'EdLevel', 'EdImpt', 'JobSeek']\n",
    "all_keep = ['Linux', 'Windows', 'Docker', 'Github', 'Slack', 'Jira']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad38d307",
   "metadata": {},
   "outputs": [],
   "source": [
    "## refactor code: processing data\n",
    "\n",
    "# the steps in the categorical pipeline for columns of low cardinality\n",
    "uni_cat_pipeline = Pipeline( steps = [( 'unicat_selector', uc.FeatureSelector(uni_cols) ),\n",
    "                                  ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "                                  ( 'ordinal_encoder', OrdinalEncoder() ) ] )\n",
    "\n",
    "# the steps in the categorical pipeline for columns of high cardinality\n",
    "multi_cat_pipeline = Pipeline( steps = [( 'multicat_selector', uc.FeatureSelector(multi_cols) ),\n",
    "                                  ( 'multi_encoder', uc.MultiColumnsEncoder(multi_cols) ) ] )\n",
    "\n",
    "# the steps in the numerical pipeline     \n",
    "num_pipeline = Pipeline( steps = [ ('num_selector', uc.FeatureSelector(num_cols) ),\n",
    "                                  ('imputer', KNNImputer(n_neighbors=5) ),\n",
    "                                  ( 'std_scaler', StandardScaler() ) ] )\n",
    "\n",
    "# combine the numerical and the categorical pipelines\n",
    "full_pipeline = FeatureUnion( transformer_list = [ ( 'unicat_pipeline', uni_cat_pipeline ), \n",
    "                                                  ( 'multicat_pipeline', multi_cat_pipeline ) ,\n",
    "                                                 ( 'numerical_pipeline', num_pipeline )] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acbc92e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload the pre-processed data\n",
    "dfp = pd.read_csv(mypath+'/data/survey20_pprocessed.csv', index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13da903d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy of the dataset\n",
    "df = dfp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40463fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (7260, 17) (7260,)\n",
      "Test (3112, 17) (3112,)\n"
     ]
    }
   ],
   "source": [
    "# create the predictors dataframe\n",
    "X = df.drop(columns = 'JobSat')\n",
    "\n",
    "# create the labels\n",
    "y = df['JobSat']\n",
    "\n",
    "# split the data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# summarize the data\n",
    "print('Train', X_train.shape, y_train.shape)\n",
    "print('Test', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "988a181d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the full pipeline as a step in another pipeline with an estimator as the final step\n",
    "full_pipeline_kn = Pipeline( steps = [( 'full_pipeline', full_pipeline),\n",
    "                                  ('model', KNeighborsClassifier(n_neighbors = 5))])\n",
    "\n",
    "# call fit on the pipeline\n",
    "full_pipeline_kn.fit( X_train, y_train )\n",
    "\n",
    "# predict with the pipeline\n",
    "y_pred_kn = full_pipeline_kn.predict( X_test ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71318f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate performance metrics on the train set\n",
    "perf_train_kn = pd.Series(uf.get_perf_metrics(full_pipeline_kn,\n",
    "                                              X_train, y_train), \n",
    "                       index = lm.metrics_list)\n",
    "\n",
    "# evaluate performance metrics on the test set\n",
    "perf_test_kn = pd.Series(uf.get_perf_metrics(full_pipeline_kn,\n",
    "                                             X_test, y_test), \n",
    "                         index = lm.metrics_list)\n",
    "\n",
    "# combine performance metrics for the baseline model\n",
    "perf_model_kn = pd.DataFrame.from_dict({'train': perf_train_kn,\n",
    "                                        'test': perf_test_kn}).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22f2bff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance metrics comparison for KNeighbors:\n",
      "            train   test\n",
      "accuracy   0.580  0.364\n",
      "precision  0.554  0.315\n",
      "recall     0.536  0.307\n",
      "f1         0.543  0.309\n",
      "\n",
      "KNeighbors Confusion Matrix for Test Set:\n",
      "[[ 56  28  18  82  74]\n",
      " [ 35 143  41 138 129]\n",
      " [ 13  79  54 124 113]\n",
      " [ 49 155  84 393 240]\n",
      " [ 58 144  69 306 487]]\n",
      "\n",
      "KNeighbors Classification Report for Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.27      0.22      0.24       258\n",
      "           2       0.26      0.29      0.28       486\n",
      "           3       0.20      0.14      0.17       383\n",
      "           4       0.38      0.43      0.40       921\n",
      "           5       0.47      0.46      0.46      1064\n",
      "\n",
      "    accuracy                           0.36      3112\n",
      "   macro avg       0.31      0.31      0.31      3112\n",
      "weighted avg       0.36      0.36      0.36      3112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print evaluation metrics and results\n",
    "\n",
    "print('Performance metrics comparison for KNeighbors:\\n', perf_model_kn)\n",
    "\n",
    "result1_kn = confusion_matrix(y_test, y_pred_kn)\n",
    "print('\\nKNeighbors Confusion Matrix for Test Set:')\n",
    "print(result1_kn)\n",
    "\n",
    "result2_kn = classification_report(y_test, y_pred_kn)\n",
    "print('\\nKNeighbors Classification Report for Test Set:')\n",
    "print (result2_kn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3278c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from pandas import read_csv\n",
    "from pandas import set_option\n",
    "#from pandas.tools.plotting import scatter_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#allows printing of all data in cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c1054a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c31354bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = full_pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b1dcc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = full_pipeline.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f1c87aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR 0.404132 0.012873 \n",
      "LDA 0.403306 0.012896 \n",
      "KNN 0.357438 0.009372 \n",
      "CART 0.516667 0.001185 \n",
      "NB 0.380028 0.011876 \n",
      "SVM 0.405372 0.007257 \n"
     ]
    }
   ],
   "source": [
    "#evaluation - baselines\n",
    "num_folds = 5\n",
    "#seed = 7\n",
    "scoring = 'accuracy'\n",
    "models = []\n",
    "\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=num_folds, random_state=None)\n",
    "    cv_results = cross_val_score(model, x_train, y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s %f %f \" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "49909ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compare algorithms\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Comparison of non-ensemble methods')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9aa4272",
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = [1, 3, 5, 7, 9, 15, 19, 21]\n",
    "param_grid = dict(n_neighbors=neighbors)\n",
    "model = KNeighborsClassifier()\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
